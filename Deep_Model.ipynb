{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Drink Quality by Reviews"
      ],
      "metadata": {
        "id": "WTkQ8n1FsVJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examine the correlation between \"Rating\" and \"Review\" to determine if the quality of a drink can be predicted based on it's reviews."
      ],
      "metadata": {
        "id": "3QLwH_X0TL_-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1THLhLXDOmz",
        "outputId": "e209f358-eda2-4e99-9f66-195ff1b4a45e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting import-ipynb\n",
            "  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from import-ipynb) (5.7.1)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.8/dist-packages (from import-ipynb) (7.9.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (4.8.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (5.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (57.4.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (0.2.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->import-ipynb) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.8/dist-packages (from nbformat->import-ipynb) (5.1.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->import-ipynb) (2.16.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->IPython->import-ipynb) (0.8.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.19.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (22.2.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (5.10.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import-ipynb) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import-ipynb) (1.15.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core->nbformat->import-ipynb) (2.6.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->IPython->import-ipynb) (0.7.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->import-ipynb) (3.11.0)\n",
            "Installing collected packages: jedi, import-ipynb\n",
            "Successfully installed import-ipynb-0.1.4 jedi-0.18.2\n"
          ]
        }
      ],
      "source": [
        "!pip install import-ipynb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/MyDrive/ML-Project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XZesjC4DUcU",
        "outputId": "e7a42356-f72a-48f2-9374-1a0e09b4b6ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/ML-Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import random\n",
        "import import_ipynb\n",
        "import utils\n",
        "\n",
        "\n",
        "# to get reproducible results:\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC_ZMjWvDYoj",
        "outputId": "0725dbbb-fe79-45b7-a058-b34c3fd91424"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "importing Jupyter notebook from utils.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "metadata": {
        "id": "CoLyV47NLEas"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing the Dataset"
      ],
      "metadata": {
        "id": "kJTb2CCVK6Gw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read dataset file\n",
        "df = pd.read_csv('dataset.csv', sep=',')"
      ],
      "metadata": {
        "id": "KKBmGAx6Dn7_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace column names with shorter, more readable names\n",
        "df.columns = ['Num', 'Brand', 'Name', 'Date', 'Recommend', 'Helpful', 'Rating', 'Weight', 'Review Title', 'Review']\n",
        "df.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "mg_ZwGcTEClT",
        "outputId": "81866d31-0867-4218-9a31-4479da8fcb5d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Num        Brand                                       Name  \\\n",
              "1263  1264         Gmax     Gmax g144105 gm44 full face red wine m   \n",
              "227    228     Heineken     Heineken174 Lager - 6pk / 12oz Bottles   \n",
              "2142  2143       Carmex  Carmex Lip Balm Original Jar - 12 PK, 12.   \n",
              "450    451     Jim Beam      Jim Beam Black Bourbon Whiskey, 50 mL   \n",
              "1403  1404  Great Value  Great Value Original Crescent Rolls, 8 oz   \n",
              "\n",
              "                      Date Recommend  Helpful  Rating   Weight  \\\n",
              "1263  2017-01-09T22:25:24Z       NaN      NaN     4.0      NaN   \n",
              "227   2017-09-20T01:18:35Z      True      NaN     5.0  1.0 lbs   \n",
              "2142  2017-09-23T02:53:08Z      True      NaN     5.0      NaN   \n",
              "450   2017-09-20T01:18:35Z       NaN      NaN     5.0      NaN   \n",
              "1403  2017-09-02T07:55:36Z      True      0.0     5.0      NaN   \n",
              "\n",
              "                   Review Title  \\\n",
              "1263                        NaN   \n",
              "227                 Great beer!   \n",
              "2142         Small and compact!   \n",
              "450        My favorite bourbon!   \n",
              "1403  Just as good as Pillsbury   \n",
              "\n",
              "                                                 Review  \n",
              "1263                                       easy process  \n",
              "227   I bought this, best price and great convenienc...  \n",
              "2142  The lip balm is so smooth, doesn't have a weir...  \n",
              "450                          Exceptionally good flavor!  \n",
              "1403         Just as good as Pillsbury but better price  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93f30f0e-0125-4d3a-97f8-1d065157ecaf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Num</th>\n",
              "      <th>Brand</th>\n",
              "      <th>Name</th>\n",
              "      <th>Date</th>\n",
              "      <th>Recommend</th>\n",
              "      <th>Helpful</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Review Title</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1263</th>\n",
              "      <td>1264</td>\n",
              "      <td>Gmax</td>\n",
              "      <td>Gmax g144105 gm44 full face red wine m</td>\n",
              "      <td>2017-01-09T22:25:24Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>easy process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>228</td>\n",
              "      <td>Heineken</td>\n",
              "      <td>Heineken174 Lager - 6pk / 12oz Bottles</td>\n",
              "      <td>2017-09-20T01:18:35Z</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>Great beer!</td>\n",
              "      <td>I bought this, best price and great convenienc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2142</th>\n",
              "      <td>2143</td>\n",
              "      <td>Carmex</td>\n",
              "      <td>Carmex Lip Balm Original Jar - 12 PK, 12.</td>\n",
              "      <td>2017-09-23T02:53:08Z</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Small and compact!</td>\n",
              "      <td>The lip balm is so smooth, doesn't have a weir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>451</td>\n",
              "      <td>Jim Beam</td>\n",
              "      <td>Jim Beam Black Bourbon Whiskey, 50 mL</td>\n",
              "      <td>2017-09-20T01:18:35Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>My favorite bourbon!</td>\n",
              "      <td>Exceptionally good flavor!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1403</th>\n",
              "      <td>1404</td>\n",
              "      <td>Great Value</td>\n",
              "      <td>Great Value Original Crescent Rolls, 8 oz</td>\n",
              "      <td>2017-09-02T07:55:36Z</td>\n",
              "      <td>True</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just as good as Pillsbury</td>\n",
              "      <td>Just as good as Pillsbury but better price</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93f30f0e-0125-4d3a-97f8-1d065157ecaf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-93f30f0e-0125-4d3a-97f8-1d065157ecaf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-93f30f0e-0125-4d3a-97f8-1d065157ecaf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove useless columns\n",
        "df.drop(\"Num\", axis=1, inplace=True)\n",
        "df.drop(\"Date\", axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "2AiS9linDA-b"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reindex rows\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "5H4vyxXCbgt2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "outputId": "6eea6fa1-5003-4ec3-cef8-6db3879dd429"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Brand                                               Name  \\\n",
              "0             Gallo         Ecco Domani174 Pinot Grigio - 750ml Bottle   \n",
              "1   Fresh Craft Co.   Fresh Craft174 Mango Citrus - 4pk / 250ml Bottle   \n",
              "2      1000 Stories           1000 Stories174 Zinfandel - 750ml Bottle   \n",
              "3      1000 Stories           1000 Stories174 Zinfandel - 750ml Bottle   \n",
              "4      Wine Cube153            Pink Moscato - 3l Bottle - Wine Cube153   \n",
              "5         Beck's Na  Beck's174 Non Alcoholic Beer - 6pk / 12oz Bottles   \n",
              "6             Gallo                Apothic174 Red Blend - 750ml Bottle   \n",
              "7             Gallo                Apothic174 Red Blend - 750ml Bottle   \n",
              "8  California Roots        California Roots Moscato White Wine - 750ml   \n",
              "9   Charles Charles        Charles Charles174 Red Blend - 750ml Bottle   \n",
              "\n",
              "  Recommend  Helpful  Rating    Weight                          Review Title  \\\n",
              "0      True      1.0     5.0   1.0 lbs                My Favorite White Wine   \n",
              "1      True      NaN     5.0  2.45 lbs                                 Yum!!   \n",
              "2      True      NaN     5.0  3.09 lbs                       A New Favorite!   \n",
              "3      True      NaN     5.0  3.09 lbs  Bold, Flavorful, Aromatic, Delicious   \n",
              "4      True      1.0     5.0   1.0 lbs  Yum! Plus, Environmentally Friendly!   \n",
              "5      True      NaN     5.0   1.0 lbs                           Great Taste   \n",
              "6       NaN      1.0     3.0   1.0 lbs                      Simply Wonderful   \n",
              "7       NaN      1.0     2.0   1.0 lbs                          A Sweet Red.   \n",
              "8      True      0.0     5.0  2.65 lbs                                   NaN   \n",
              "9      True      NaN     5.0   1.0 lbs           Charles & Charles Red Blend   \n",
              "\n",
              "                                              Review  \n",
              "0      This a fantastic white wine for any occasion!  \n",
              "1   Tart, not sweet...very refreshing and delicious!  \n",
              "2  I was given this wine so it was a delightful s...  \n",
              "3  This is a phenomenal wine and my new favorite ...  \n",
              "4  4 750ml bottles for the price of two With way ...  \n",
              "5  I LOVE Becks NA. It tastes just like a regular...  \n",
              "6  This wine has a wonderful but strong aroma its...  \n",
              "7  I would give one more star if it came clean on...  \n",
              "8                      Delicious and very affordable  \n",
              "9  This is a very smooth red with Aromas of cocoa...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f0b2c78-2739-41da-853f-24ae39d1b050\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Brand</th>\n",
              "      <th>Name</th>\n",
              "      <th>Recommend</th>\n",
              "      <th>Helpful</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Review Title</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Gallo</td>\n",
              "      <td>Ecco Domani174 Pinot Grigio - 750ml Bottle</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>My Favorite White Wine</td>\n",
              "      <td>This a fantastic white wine for any occasion!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fresh Craft Co.</td>\n",
              "      <td>Fresh Craft174 Mango Citrus - 4pk / 250ml Bottle</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.45 lbs</td>\n",
              "      <td>Yum!!</td>\n",
              "      <td>Tart, not sweet...very refreshing and delicious!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000 Stories</td>\n",
              "      <td>1000 Stories174 Zinfandel - 750ml Bottle</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.09 lbs</td>\n",
              "      <td>A New Favorite!</td>\n",
              "      <td>I was given this wine so it was a delightful s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000 Stories</td>\n",
              "      <td>1000 Stories174 Zinfandel - 750ml Bottle</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.09 lbs</td>\n",
              "      <td>Bold, Flavorful, Aromatic, Delicious</td>\n",
              "      <td>This is a phenomenal wine and my new favorite ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Wine Cube153</td>\n",
              "      <td>Pink Moscato - 3l Bottle - Wine Cube153</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>Yum! Plus, Environmentally Friendly!</td>\n",
              "      <td>4 750ml bottles for the price of two With way ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Beck's Na</td>\n",
              "      <td>Beck's174 Non Alcoholic Beer - 6pk / 12oz Bottles</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>Great Taste</td>\n",
              "      <td>I LOVE Becks NA. It tastes just like a regular...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Gallo</td>\n",
              "      <td>Apothic174 Red Blend - 750ml Bottle</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>Simply Wonderful</td>\n",
              "      <td>This wine has a wonderful but strong aroma its...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Gallo</td>\n",
              "      <td>Apothic174 Red Blend - 750ml Bottle</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>A Sweet Red.</td>\n",
              "      <td>I would give one more star if it came clean on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>California Roots</td>\n",
              "      <td>California Roots Moscato White Wine - 750ml</td>\n",
              "      <td>True</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.65 lbs</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Delicious and very affordable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Charles Charles</td>\n",
              "      <td>Charles Charles174 Red Blend - 750ml Bottle</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>Charles &amp; Charles Red Blend</td>\n",
              "      <td>This is a very smooth red with Aromas of cocoa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f0b2c78-2739-41da-853f-24ae39d1b050')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f0b2c78-2739-41da-853f-24ae39d1b050 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f0b2c78-2739-41da-853f-24ae39d1b050');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check for total amount of null values in each column\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "Q7ZAX3-RGAOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "374e6004-2cbf-465e-fea6-7dc10b8b2911"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brand             65\n",
            "Name               0\n",
            "Recommend        979\n",
            "Helpful         2264\n",
            "Rating           445\n",
            "Weight          1894\n",
            "Review Title      44\n",
            "Review             1\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove all rows that have no ratings or recommendations\n",
        "df = df.dropna(subset=['Rating'])\n",
        "df = df.dropna(subset=['Recommend'])\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "E9Pkbdj-IVA_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "381a0f8f-69fb-4015-ad2b-c4a80a55fc1e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Brand              0\n",
              "Name               0\n",
              "Recommend          0\n",
              "Helpful         1170\n",
              "Rating             0\n",
              "Weight          1392\n",
              "Review Title      10\n",
              "Review             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the all possible ratings from 1 to 5 are used\n",
        "np.unique(df['Rating'])"
      ],
      "metadata": {
        "id": "yJIJNlkkKqkV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fbbf8a3-942a-448c-86fc-6bb91938157f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 2., 3., 4., 5.])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "FOC26UJ1BgCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53aa5cd3-1566-4470-919d-07afbe750b2f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1748 entries, 0 to 2815\n",
            "Data columns (total 8 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Brand         1748 non-null   object \n",
            " 1   Name          1748 non-null   object \n",
            " 2   Recommend     1748 non-null   object \n",
            " 3   Helpful       578 non-null    float64\n",
            " 4   Rating        1748 non-null   float64\n",
            " 5   Weight        356 non-null    object \n",
            " 6   Review Title  1738 non-null   object \n",
            " 7   Review        1748 non-null   object \n",
            "dtypes: float64(2), object(6)\n",
            "memory usage: 122.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change data type of \"Rating\" from float to integer\n",
        "df['Rating'] = df['Rating'].astype(int)\n",
        "\n",
        "# change data type of \"Recommend\" from object to integer\n",
        "# \"True\" = 1, \"False\" = 0\n",
        "df[\"Recommend\"] = df[\"Recommend\"].astype(int)\n",
        "\n",
        "# check data types again\n",
        "df.info()"
      ],
      "metadata": {
        "id": "55B7BhBBL4VK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f3c74fd-8f80-4565-9747-c0293e5c12e6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1748 entries, 0 to 2815\n",
            "Data columns (total 8 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Brand         1748 non-null   object \n",
            " 1   Name          1748 non-null   object \n",
            " 2   Recommend     1748 non-null   int64  \n",
            " 3   Helpful       578 non-null    float64\n",
            " 4   Rating        1748 non-null   int64  \n",
            " 5   Weight        356 non-null    object \n",
            " 6   Review Title  1738 non-null   object \n",
            " 7   Review        1748 non-null   object \n",
            "dtypes: float64(1), int64(2), object(5)\n",
            "memory usage: 122.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect correlation between numeric features\n",
        "df.corr()"
      ],
      "metadata": {
        "id": "72OEXXdrb6EF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "46ec9c81-f8f4-485a-8447-79098089d349"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Recommend   Helpful    Rating\n",
              "Recommend   1.000000  0.042670  0.767292\n",
              "Helpful     0.042670  1.000000  0.024891\n",
              "Rating      0.767292  0.024891  1.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d779fad-d7df-4048-a7f8-df1803b5792c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Recommend</th>\n",
              "      <th>Helpful</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Recommend</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.042670</td>\n",
              "      <td>0.767292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Helpful</th>\n",
              "      <td>0.042670</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.024891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Rating</th>\n",
              "      <td>0.767292</td>\n",
              "      <td>0.024891</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d779fad-d7df-4048-a7f8-df1803b5792c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d779fad-d7df-4048-a7f8-df1803b5792c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d779fad-d7df-4048-a7f8-df1803b5792c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- There is a weak positive correlation between recommend and helpful. Reviews that were voted helpful tend to be about alcohol that reviewers recommend to others.\n",
        "- There is a strong positive correlation between recommend and rating. The higher the rating/quality of the alcohol, then then the more likely that the reviewer would recommend it.\n",
        "- There is a very weak positive correlation between helpful and rating. Alcohol that was voted helpful tend to have slightly higher ratings than reviews not considered helpful."
      ],
      "metadata": {
        "id": "hJSUEBotcmi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check for duplicated reviews\n",
        "df['Review'].duplicated().sum()"
      ],
      "metadata": {
        "id": "Y4Ggih8XF42P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfe0aa3a-ed4e-44ef-e4ee-56bf491d7120"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove duplicated reviews\n",
        "df['Review'].drop_duplicates()"
      ],
      "metadata": {
        "id": "U1QKOX4uF-UU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9015e180-0c11-4eb9-cce6-acee006e812f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0           This a fantastic white wine for any occasion!\n",
              "1        Tart, not sweet...very refreshing and delicious!\n",
              "2       I was given this wine so it was a delightful s...\n",
              "3       This is a phenomenal wine and my new favorite ...\n",
              "4       4 750ml bottles for the price of two With way ...\n",
              "                              ...                        \n",
              "2811    My kids love them. So no complaints but I'm su...\n",
              "2812    Easy and quick to serve, brings a smile to the...\n",
              "2813                         Worked great kids loved them\n",
              "2814    Walmart used to carry a Swiss water decaf coff...\n",
              "2815    Great decaf coffee using Swiss water process. ...\n",
              "Name: Review, Length: 1735, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clean text in reviews with natural language toolkit\n",
        "!pip install nltk\n",
        "import nltk\n",
        "\n",
        "# define stopwords to remove\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stopwords = set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "id": "PupCwDbIoOpi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a163ee97-e6de-4a0f-933e-ecdac4ec9595"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize text with regex before cleaning\n",
        "from nltk import word_tokenize\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "token = TreebankWordDetokenizer()\n",
        "\n",
        "def clean(w):\n",
        "    w = word_tokenize(w.lower()) # turn all token words lowercase\n",
        "    w = [token for token in w if token not in stopwords and token.isalpha()] # remove stopwords and non-words (punctuation, numbers, etc.)\n",
        "    return token.detokenize(w)\n",
        "\n",
        "df[\"Clean_Reviews\"] = df[\"Review\"].apply(clean)"
      ],
      "metadata": {
        "id": "NzYNfnTejmJV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check to make sure the reviews were cleaned correctly\n",
        "df[\"Clean_Reviews\"].sample(10)"
      ],
      "metadata": {
        "id": "-Yj3GOHztCI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c002bb10-7cc2-417b-d7bf-8ddffe5d50cc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1596    prefer purchase store individually whatever ne...\n",
              "477                             best bloody mary mix ever\n",
              "2364    started using carmex cna brand count heal supp...\n",
              "2061    using carmex yrs still always keep jar purse t...\n",
              "2226    started applying four times day honestly great...\n",
              "2373    buy carmex tub becuase mother always wood open...\n",
              "829                                              favorite\n",
              "1980    use many year really work dry lips light burn ...\n",
              "1994    always go back carmex original lip balm jar li...\n",
              "2585    using carmex original lip balm jar since child...\n",
              "Name: Clean_Reviews, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network Algorithm - Deep Model"
      ],
      "metadata": {
        "id": "eyTXVRRGf-t8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "UST9kQW_f-t9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset 40% test, 60% train\n",
        "y = df[\"Rating\"].values\n",
        "words = df[\"Clean_Reviews\"].values\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(words, y, test_size=0.4, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "77iLLy7jf-t9"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# examine a random dictionary entry\n",
        "print(\"Review:\", x_train[2])\n",
        "print(\"Rating:\", y_train[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d02049a4-d334-4429-a0fe-8687580f6473",
        "id": "LICtu_WMf-t9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: price incredible delivery service better could hoped\n",
            "Rating: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize the reviews to vectorize each word as an integer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# limit vocabularly index to the most common 5000 words\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "# create vocab index based on word frequency\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "# apply limited vocab to train and test\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_test = tokenizer.texts_to_sequences(x_test)"
      ],
      "metadata": {
        "id": "qT9XBoq9f-t9"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# examine a random dictionary entry\n",
        "print(\"Encoded Review:\", x_train[2])\n",
        "print(\"Rating:\", y_train[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be589811-9350-4432-beec-37ed66596ca2",
        "id": "jPQjl2bFf-t9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Review: [50, 717, 427, 953, 58, 90, 954]\n",
            "Rating: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# re-vectorize reviews into sparse 2D nummpy array, with many zeros in the data\n",
        "# convert the reviews into a matrix, one review per row and one column per word\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "\n",
        "num_words=5000\n",
        "x_train = vectorize_sequences(x_train, dimension=num_words)\n",
        "x_test = vectorize_sequences(x_test, dimension=num_words)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a39886ea-d56e-45a7-91d9-6be0854b7cc4",
        "id": "fv22yQfNf-t9"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1048, 5000)\n",
            "(700, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train[:15])\n",
        "print(y_test[:15])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61b83dad-3f8f-428f-f959-290f4caedd38",
        "id": "IODJZEVXf-t9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 5 5 5 5 5 1 5 5 5 5 5 5 5 5]\n",
            "[4 5 4 5 4 5 4 4 5 5 5 5 5 5 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "cnt = Counter(list(y_train))\n",
        "num_classes = 5\n",
        "cnt.most_common(num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c87ebff-b8e6-42f0-ec3b-0662162d7291",
        "id": "dTivtGxJf-t9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(5, 900), (4, 90), (3, 24), (1, 23), (2, 11)]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_labels = sorted(set([i[0] for i in cnt.most_common(num_classes)]))\n",
        "selected_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db3cbf6c-199a-4769-cd20-27ff558de43b",
        "id": "M45nAzhkf-t-"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_mask = [True if l in selected_labels else False for l in y_train]\n",
        "x_train = x_train[train_mask, :]\n",
        "y_train = y_train[train_mask]\n",
        "y_train = np.array([selected_labels.index(i) for i in y_train]) # reindex\n",
        "\n",
        "test_mask = [True if l in selected_labels else False for l in y_test]\n",
        "x_test= x_test[test_mask, :]\n",
        "y_test = y_test[test_mask]\n",
        "y_test = np.array([selected_labels.index(i) for i in y_test]) # reindex\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b38efbdc-b2b5-4edc-f631-df6a6c30f9b2",
        "id": "r5u5Z66Pf-t-"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1048, 5000)\n",
            "(700, 5000)\n",
            "(1048,)\n",
            "(700,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split training data into 40% train and 60% dev\n",
        "x_train, x_dev, y_train, y_dev = train_test_split(x_train, y_train, test_size=0.4, random_state=42)\n",
        "print(y_train.shape)\n",
        "print(x_train.shape)\n",
        "print(x_dev.shape)\n",
        "print(y_dev.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1505dd07-453a-415c-d3ea-dbc28f52905d",
        "id": "7x-audOvf-t-"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(628,)\n",
            "(628, 5000)\n",
            "(420, 5000)\n",
            "(420,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert numpy array into PyTorch format\n",
        "\n",
        "# 1) define function\n",
        "def np2iter(x, y, shuffle=True):\n",
        "  x = torch.tensor(x, dtype=torch.float)\n",
        "  y = torch.tensor(y, dtype=torch.long)\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  print(\"----------------------\")\n",
        "\n",
        "  ds = torch.utils.data.TensorDataset(x, y)\n",
        "  return torch.utils.data.DataLoader(ds, batch_size=32, shuffle=shuffle)\n",
        "\n",
        "# 2) convert data\n",
        "train_iter = np2iter(x_train, y_train, shuffle=True) # DO shuffle train\n",
        "dev_iter =  np2iter(x_dev, y_dev, shuffle=False) # do NOT shuffle dev or test\n",
        "test_iter =  np2iter(x_test, y_test, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "018aff8c-19ac-4245-9ab8-e3c12be5cf7d",
        "id": "qZTbVwmtf-t-"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([628, 5000])\n",
            "torch.Size([628])\n",
            "----------------------\n",
            "torch.Size([420, 5000])\n",
            "torch.Size([420])\n",
            "----------------------\n",
            "torch.Size([700, 5000])\n",
            "torch.Size([700])\n",
            "----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining accuracy\n",
        "def val_acc(y_pred, y_test): # define accuracy\n",
        "  y_pred = np.argmax(y_pred, axis=1)\n",
        "  return accuracy_score(y_pred=y_pred, y_true=y_test)"
      ],
      "metadata": {
        "id": "Uy56nWszf-t-"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "RySLkWAMLnbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define deep model\n",
        "num_words = 5000\n",
        "\n",
        "class DeepModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DeepModel, self).__init__()\n",
        "    # nn.sequential executes the following layers one by one, from linear layer to rectified layer unit\n",
        "    self.layer = nn.Sequential(nn.Linear(in_features=num_words, out_features=30), \n",
        "                                nn.Dropout(p=0.33),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Linear(in_features=30, out_features=30),\n",
        "                                nn.Dropout(p=0.33),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Linear(in_features=30, out_features=5))\n",
        "\n",
        "    \n",
        "  # feed the model the input and apply the linear layer to get the output\n",
        "  def forward(self, x):\n",
        "    return self.layer(x)"
      ],
      "metadata": {
        "id": "YKDbXb4-g3tH"
      },
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_model = DeepModel()\n",
        "classification_model = classification_model.cuda()"
      ],
      "metadata": {
        "id": "5U5BYKJAhFYC"
      },
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = utils.train(model=classification_model,\n",
        "                            loss=nn.CrossEntropyLoss(),\n",
        "                            val_metrics={\"cls\": nn.CrossEntropyLoss(), \"acc\": val_acc}, \n",
        "                            optimizer=torch.optim.SGD(classification_model.parameters(), lr=0.01),\n",
        "                            train_ds=train_iter, \n",
        "                            dev_ds=dev_iter,\n",
        "                            num_epochs=200,\n",
        "                            early_stopper=utils.EarlyStopper(metric_name=\"cls\", patience=5))"
      ],
      "metadata": {
        "id": "2l319rxEL8aY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b107f7bf-4b4b-4fc7-d7fa-6f610afcc8b2"
      },
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========\n",
            "epoch 1 train loss: 1.6034 val_cls: 1.5146 val_acc: 0.0262\n",
            "tensor(1.5146) None\n",
            "=========\n",
            "epoch 2 train loss: 1.4575 val_cls: 1.3704 val_acc: 0.8810\n",
            "tensor(1.3704) tensor(1.5146)\n",
            "=========\n",
            "epoch 3 train loss: 1.3275 val_cls: 1.2400 val_acc: 0.8810\n",
            "tensor(1.2400) tensor(1.3704)\n",
            "=========\n",
            "epoch 4 train loss: 1.2085 val_cls: 1.1209 val_acc: 0.8810\n",
            "tensor(1.1209) tensor(1.2400)\n",
            "=========\n",
            "epoch 5 train loss: 1.1060 val_cls: 1.0160 val_acc: 0.8810\n",
            "tensor(1.0160) tensor(1.1209)\n",
            "=========\n",
            "epoch 6 train loss: 1.0186 val_cls: 0.9244 val_acc: 0.8810\n",
            "tensor(0.9244) tensor(1.0160)\n",
            "=========\n",
            "epoch 7 train loss: 0.9436 val_cls: 0.8454 val_acc: 0.8810\n",
            "tensor(0.8454) tensor(0.9244)\n",
            "=========\n",
            "epoch 8 train loss: 0.8788 val_cls: 0.7795 val_acc: 0.8810\n",
            "tensor(0.7795) tensor(0.8454)\n",
            "=========\n",
            "epoch 9 train loss: 0.8186 val_cls: 0.7243 val_acc: 0.8810\n",
            "tensor(0.7243) tensor(0.7795)\n",
            "=========\n",
            "epoch 10 train loss: 0.7705 val_cls: 0.6806 val_acc: 0.8810\n",
            "tensor(0.6806) tensor(0.7243)\n",
            "=========\n",
            "epoch 11 train loss: 0.7474 val_cls: 0.6461 val_acc: 0.8810\n",
            "tensor(0.6461) tensor(0.6806)\n",
            "=========\n",
            "epoch 12 train loss: 0.7127 val_cls: 0.6192 val_acc: 0.8810\n",
            "tensor(0.6192) tensor(0.6461)\n",
            "=========\n",
            "epoch 13 train loss: 0.6994 val_cls: 0.5979 val_acc: 0.8810\n",
            "tensor(0.5979) tensor(0.6192)\n",
            "=========\n",
            "epoch 14 train loss: 0.6914 val_cls: 0.5814 val_acc: 0.8810\n",
            "tensor(0.5814) tensor(0.5979)\n",
            "=========\n",
            "epoch 15 train loss: 0.6749 val_cls: 0.5687 val_acc: 0.8810\n",
            "tensor(0.5687) tensor(0.5814)\n",
            "=========\n",
            "epoch 16 train loss: 0.6508 val_cls: 0.5573 val_acc: 0.8810\n",
            "tensor(0.5573) tensor(0.5687)\n",
            "=========\n",
            "epoch 17 train loss: 0.6556 val_cls: 0.5478 val_acc: 0.8810\n",
            "tensor(0.5478) tensor(0.5573)\n",
            "=========\n",
            "epoch 18 train loss: 0.6412 val_cls: 0.5403 val_acc: 0.8810\n",
            "tensor(0.5403) tensor(0.5478)\n",
            "=========\n",
            "epoch 19 train loss: 0.6512 val_cls: 0.5343 val_acc: 0.8810\n",
            "tensor(0.5343) tensor(0.5403)\n",
            "=========\n",
            "epoch 20 train loss: 0.6288 val_cls: 0.5292 val_acc: 0.8810\n",
            "tensor(0.5292) tensor(0.5343)\n",
            "=========\n",
            "epoch 21 train loss: 0.6409 val_cls: 0.5256 val_acc: 0.8810\n",
            "tensor(0.5256) tensor(0.5292)\n",
            "=========\n",
            "epoch 22 train loss: 0.6361 val_cls: 0.5224 val_acc: 0.8810\n",
            "tensor(0.5224) tensor(0.5256)\n",
            "=========\n",
            "epoch 23 train loss: 0.6391 val_cls: 0.5200 val_acc: 0.8810\n",
            "tensor(0.5200) tensor(0.5224)\n",
            "=========\n",
            "epoch 24 train loss: 0.6332 val_cls: 0.5172 val_acc: 0.8810\n",
            "tensor(0.5172) tensor(0.5200)\n",
            "=========\n",
            "epoch 25 train loss: 0.6329 val_cls: 0.5148 val_acc: 0.8810\n",
            "tensor(0.5148) tensor(0.5172)\n",
            "=========\n",
            "epoch 26 train loss: 0.6386 val_cls: 0.5127 val_acc: 0.8810\n",
            "tensor(0.5127) tensor(0.5148)\n",
            "=========\n",
            "epoch 27 train loss: 0.6197 val_cls: 0.5104 val_acc: 0.8810\n",
            "tensor(0.5104) tensor(0.5127)\n",
            "=========\n",
            "epoch 28 train loss: 0.6226 val_cls: 0.5086 val_acc: 0.8810\n",
            "tensor(0.5086) tensor(0.5104)\n",
            "=========\n",
            "epoch 29 train loss: 0.6225 val_cls: 0.5069 val_acc: 0.8810\n",
            "tensor(0.5069) tensor(0.5086)\n",
            "=========\n",
            "epoch 30 train loss: 0.6251 val_cls: 0.5056 val_acc: 0.8810\n",
            "tensor(0.5056) tensor(0.5069)\n",
            "=========\n",
            "epoch 31 train loss: 0.6245 val_cls: 0.5040 val_acc: 0.8810\n",
            "tensor(0.5040) tensor(0.5056)\n",
            "=========\n",
            "epoch 32 train loss: 0.6217 val_cls: 0.5027 val_acc: 0.8810\n",
            "tensor(0.5027) tensor(0.5040)\n",
            "=========\n",
            "epoch 33 train loss: 0.6167 val_cls: 0.5014 val_acc: 0.8810\n",
            "tensor(0.5014) tensor(0.5027)\n",
            "=========\n",
            "epoch 34 train loss: 0.6104 val_cls: 0.5000 val_acc: 0.8810\n",
            "tensor(0.5000) tensor(0.5014)\n",
            "=========\n",
            "epoch 35 train loss: 0.6127 val_cls: 0.4988 val_acc: 0.8810\n",
            "tensor(0.4988) tensor(0.5000)\n",
            "=========\n",
            "epoch 36 train loss: 0.6246 val_cls: 0.4978 val_acc: 0.8810\n",
            "tensor(0.4978) tensor(0.4988)\n",
            "=========\n",
            "epoch 37 train loss: 0.6084 val_cls: 0.4965 val_acc: 0.8810\n",
            "tensor(0.4965) tensor(0.4978)\n",
            "=========\n",
            "epoch 38 train loss: 0.6080 val_cls: 0.4957 val_acc: 0.8810\n",
            "tensor(0.4957) tensor(0.4965)\n",
            "=========\n",
            "epoch 39 train loss: 0.5994 val_cls: 0.4943 val_acc: 0.8810\n",
            "tensor(0.4943) tensor(0.4957)\n",
            "=========\n",
            "epoch 40 train loss: 0.5972 val_cls: 0.4933 val_acc: 0.8810\n",
            "tensor(0.4933) tensor(0.4943)\n",
            "=========\n",
            "epoch 41 train loss: 0.6044 val_cls: 0.4927 val_acc: 0.8810\n",
            "tensor(0.4927) tensor(0.4933)\n",
            "=========\n",
            "epoch 42 train loss: 0.6013 val_cls: 0.4918 val_acc: 0.8810\n",
            "tensor(0.4918) tensor(0.4927)\n",
            "=========\n",
            "epoch 43 train loss: 0.5883 val_cls: 0.4906 val_acc: 0.8810\n",
            "tensor(0.4906) tensor(0.4918)\n",
            "=========\n",
            "epoch 44 train loss: 0.5904 val_cls: 0.4894 val_acc: 0.8810\n",
            "tensor(0.4894) tensor(0.4906)\n",
            "=========\n",
            "epoch 45 train loss: 0.5853 val_cls: 0.4888 val_acc: 0.8810\n",
            "tensor(0.4888) tensor(0.4894)\n",
            "=========\n",
            "epoch 46 train loss: 0.5930 val_cls: 0.4881 val_acc: 0.8810\n",
            "tensor(0.4881) tensor(0.4888)\n",
            "=========\n",
            "epoch 47 train loss: 0.5903 val_cls: 0.4871 val_acc: 0.8810\n",
            "tensor(0.4871) tensor(0.4881)\n",
            "=========\n",
            "epoch 48 train loss: 0.5933 val_cls: 0.4865 val_acc: 0.8810\n",
            "tensor(0.4865) tensor(0.4871)\n",
            "=========\n",
            "epoch 49 train loss: 0.5960 val_cls: 0.4858 val_acc: 0.8810\n",
            "tensor(0.4858) tensor(0.4865)\n",
            "=========\n",
            "epoch 50 train loss: 0.5931 val_cls: 0.4853 val_acc: 0.8810\n",
            "tensor(0.4853) tensor(0.4858)\n",
            "=========\n",
            "epoch 51 train loss: 0.5929 val_cls: 0.4847 val_acc: 0.8810\n",
            "tensor(0.4847) tensor(0.4853)\n",
            "=========\n",
            "epoch 52 train loss: 0.5874 val_cls: 0.4841 val_acc: 0.8810\n",
            "tensor(0.4841) tensor(0.4847)\n",
            "=========\n",
            "epoch 53 train loss: 0.5853 val_cls: 0.4834 val_acc: 0.8810\n",
            "tensor(0.4834) tensor(0.4841)\n",
            "=========\n",
            "epoch 54 train loss: 0.5820 val_cls: 0.4825 val_acc: 0.8810\n",
            "tensor(0.4825) tensor(0.4834)\n",
            "=========\n",
            "epoch 55 train loss: 0.5729 val_cls: 0.4818 val_acc: 0.8810\n",
            "tensor(0.4818) tensor(0.4825)\n",
            "=========\n",
            "epoch 56 train loss: 0.5869 val_cls: 0.4812 val_acc: 0.8810\n",
            "tensor(0.4812) tensor(0.4818)\n",
            "=========\n",
            "epoch 57 train loss: 0.5794 val_cls: 0.4803 val_acc: 0.8810\n",
            "tensor(0.4803) tensor(0.4812)\n",
            "=========\n",
            "epoch 58 train loss: 0.5815 val_cls: 0.4796 val_acc: 0.8810\n",
            "tensor(0.4796) tensor(0.4803)\n",
            "=========\n",
            "epoch 59 train loss: 0.5693 val_cls: 0.4786 val_acc: 0.8810\n",
            "tensor(0.4786) tensor(0.4796)\n",
            "=========\n",
            "epoch 60 train loss: 0.5781 val_cls: 0.4780 val_acc: 0.8810\n",
            "tensor(0.4780) tensor(0.4786)\n",
            "=========\n",
            "epoch 61 train loss: 0.5863 val_cls: 0.4776 val_acc: 0.8810\n",
            "tensor(0.4776) tensor(0.4780)\n",
            "=========\n",
            "epoch 62 train loss: 0.5818 val_cls: 0.4771 val_acc: 0.8810\n",
            "tensor(0.4771) tensor(0.4776)\n",
            "=========\n",
            "epoch 63 train loss: 0.5766 val_cls: 0.4770 val_acc: 0.8810\n",
            "tensor(0.4770) tensor(0.4771)\n",
            "=========\n",
            "epoch 64 train loss: 0.5769 val_cls: 0.4766 val_acc: 0.8810\n",
            "tensor(0.4766) tensor(0.4770)\n",
            "=========\n",
            "epoch 65 train loss: 0.5768 val_cls: 0.4756 val_acc: 0.8810\n",
            "tensor(0.4756) tensor(0.4766)\n",
            "=========\n",
            "epoch 66 train loss: 0.5664 val_cls: 0.4749 val_acc: 0.8810\n",
            "tensor(0.4749) tensor(0.4756)\n",
            "=========\n",
            "epoch 67 train loss: 0.5760 val_cls: 0.4746 val_acc: 0.8810\n",
            "tensor(0.4746) tensor(0.4749)\n",
            "=========\n",
            "epoch 68 train loss: 0.5716 val_cls: 0.4739 val_acc: 0.8810\n",
            "tensor(0.4739) tensor(0.4746)\n",
            "=========\n",
            "epoch 69 train loss: 0.5711 val_cls: 0.4737 val_acc: 0.8810\n",
            "tensor(0.4737) tensor(0.4739)\n",
            "=========\n",
            "epoch 70 train loss: 0.5666 val_cls: 0.4730 val_acc: 0.8810\n",
            "tensor(0.4730) tensor(0.4737)\n",
            "=========\n",
            "epoch 71 train loss: 0.5672 val_cls: 0.4727 val_acc: 0.8810\n",
            "tensor(0.4727) tensor(0.4730)\n",
            "=========\n",
            "epoch 72 train loss: 0.5597 val_cls: 0.4722 val_acc: 0.8810\n",
            "tensor(0.4722) tensor(0.4727)\n",
            "=========\n",
            "epoch 73 train loss: 0.5731 val_cls: 0.4719 val_acc: 0.8810\n",
            "tensor(0.4719) tensor(0.4722)\n",
            "=========\n",
            "epoch 74 train loss: 0.5686 val_cls: 0.4713 val_acc: 0.8810\n",
            "tensor(0.4713) tensor(0.4719)\n",
            "=========\n",
            "epoch 75 train loss: 0.5832 val_cls: 0.4710 val_acc: 0.8810\n",
            "tensor(0.4710) tensor(0.4713)\n",
            "=========\n",
            "epoch 76 train loss: 0.5608 val_cls: 0.4706 val_acc: 0.8810\n",
            "tensor(0.4706) tensor(0.4710)\n",
            "=========\n",
            "epoch 77 train loss: 0.5632 val_cls: 0.4701 val_acc: 0.8810\n",
            "tensor(0.4701) tensor(0.4706)\n",
            "=========\n",
            "epoch 78 train loss: 0.5638 val_cls: 0.4695 val_acc: 0.8810\n",
            "tensor(0.4695) tensor(0.4701)\n",
            "=========\n",
            "epoch 79 train loss: 0.5617 val_cls: 0.4689 val_acc: 0.8810\n",
            "tensor(0.4689) tensor(0.4695)\n",
            "=========\n",
            "epoch 80 train loss: 0.5556 val_cls: 0.4683 val_acc: 0.8810\n",
            "tensor(0.4683) tensor(0.4689)\n",
            "=========\n",
            "epoch 81 train loss: 0.5515 val_cls: 0.4677 val_acc: 0.8810\n",
            "tensor(0.4677) tensor(0.4683)\n",
            "=========\n",
            "epoch 82 train loss: 0.5533 val_cls: 0.4672 val_acc: 0.8810\n",
            "tensor(0.4672) tensor(0.4677)\n",
            "=========\n",
            "epoch 83 train loss: 0.5530 val_cls: 0.4666 val_acc: 0.8810\n",
            "tensor(0.4666) tensor(0.4672)\n",
            "=========\n",
            "epoch 84 train loss: 0.5511 val_cls: 0.4661 val_acc: 0.8810\n",
            "tensor(0.4661) tensor(0.4666)\n",
            "=========\n",
            "epoch 85 train loss: 0.5586 val_cls: 0.4657 val_acc: 0.8810\n",
            "tensor(0.4657) tensor(0.4661)\n",
            "=========\n",
            "epoch 86 train loss: 0.5431 val_cls: 0.4651 val_acc: 0.8810\n",
            "tensor(0.4651) tensor(0.4657)\n",
            "=========\n",
            "epoch 87 train loss: 0.5558 val_cls: 0.4649 val_acc: 0.8810\n",
            "tensor(0.4649) tensor(0.4651)\n",
            "=========\n",
            "epoch 88 train loss: 0.5404 val_cls: 0.4641 val_acc: 0.8810\n",
            "tensor(0.4641) tensor(0.4649)\n",
            "=========\n",
            "epoch 89 train loss: 0.5391 val_cls: 0.4637 val_acc: 0.8810\n",
            "tensor(0.4637) tensor(0.4641)\n",
            "=========\n",
            "epoch 90 train loss: 0.5437 val_cls: 0.4632 val_acc: 0.8810\n",
            "tensor(0.4632) tensor(0.4637)\n",
            "=========\n",
            "epoch 91 train loss: 0.5395 val_cls: 0.4626 val_acc: 0.8810\n",
            "tensor(0.4626) tensor(0.4632)\n",
            "=========\n",
            "epoch 92 train loss: 0.5473 val_cls: 0.4621 val_acc: 0.8810\n",
            "tensor(0.4621) tensor(0.4626)\n",
            "=========\n",
            "epoch 93 train loss: 0.5443 val_cls: 0.4618 val_acc: 0.8810\n",
            "tensor(0.4618) tensor(0.4621)\n",
            "=========\n",
            "epoch 94 train loss: 0.5451 val_cls: 0.4614 val_acc: 0.8810\n",
            "tensor(0.4614) tensor(0.4618)\n",
            "=========\n",
            "epoch 95 train loss: 0.5432 val_cls: 0.4610 val_acc: 0.8810\n",
            "tensor(0.4610) tensor(0.4614)\n",
            "=========\n",
            "epoch 96 train loss: 0.5311 val_cls: 0.4603 val_acc: 0.8810\n",
            "tensor(0.4603) tensor(0.4610)\n",
            "=========\n",
            "epoch 97 train loss: 0.5381 val_cls: 0.4598 val_acc: 0.8810\n",
            "tensor(0.4598) tensor(0.4603)\n",
            "=========\n",
            "epoch 98 train loss: 0.5357 val_cls: 0.4594 val_acc: 0.8810\n",
            "tensor(0.4594) tensor(0.4598)\n",
            "=========\n",
            "epoch 99 train loss: 0.5295 val_cls: 0.4589 val_acc: 0.8810\n",
            "tensor(0.4589) tensor(0.4594)\n",
            "=========\n",
            "epoch 100 train loss: 0.5253 val_cls: 0.4583 val_acc: 0.8810\n",
            "tensor(0.4583) tensor(0.4589)\n",
            "=========\n",
            "epoch 101 train loss: 0.5244 val_cls: 0.4578 val_acc: 0.8810\n",
            "tensor(0.4578) tensor(0.4583)\n",
            "=========\n",
            "epoch 102 train loss: 0.5329 val_cls: 0.4573 val_acc: 0.8810\n",
            "tensor(0.4573) tensor(0.4578)\n",
            "=========\n",
            "epoch 103 train loss: 0.5314 val_cls: 0.4570 val_acc: 0.8810\n",
            "tensor(0.4570) tensor(0.4573)\n",
            "=========\n",
            "epoch 104 train loss: 0.5328 val_cls: 0.4566 val_acc: 0.8810\n",
            "tensor(0.4566) tensor(0.4570)\n",
            "=========\n",
            "epoch 105 train loss: 0.5308 val_cls: 0.4562 val_acc: 0.8810\n",
            "tensor(0.4562) tensor(0.4566)\n",
            "=========\n",
            "epoch 106 train loss: 0.5225 val_cls: 0.4559 val_acc: 0.8810\n",
            "tensor(0.4559) tensor(0.4562)\n",
            "=========\n",
            "epoch 107 train loss: 0.5285 val_cls: 0.4555 val_acc: 0.8810\n",
            "tensor(0.4555) tensor(0.4559)\n",
            "=========\n",
            "epoch 108 train loss: 0.5201 val_cls: 0.4549 val_acc: 0.8810\n",
            "tensor(0.4549) tensor(0.4555)\n",
            "=========\n",
            "epoch 109 train loss: 0.5132 val_cls: 0.4541 val_acc: 0.8810\n",
            "tensor(0.4541) tensor(0.4549)\n",
            "=========\n",
            "epoch 110 train loss: 0.5161 val_cls: 0.4537 val_acc: 0.8810\n",
            "tensor(0.4537) tensor(0.4541)\n",
            "=========\n",
            "epoch 111 train loss: 0.5128 val_cls: 0.4531 val_acc: 0.8810\n",
            "tensor(0.4531) tensor(0.4537)\n",
            "=========\n",
            "epoch 112 train loss: 0.5132 val_cls: 0.4528 val_acc: 0.8810\n",
            "tensor(0.4528) tensor(0.4531)\n",
            "=========\n",
            "epoch 113 train loss: 0.5096 val_cls: 0.4524 val_acc: 0.8810\n",
            "tensor(0.4524) tensor(0.4528)\n",
            "=========\n",
            "epoch 114 train loss: 0.5080 val_cls: 0.4520 val_acc: 0.8810\n",
            "tensor(0.4520) tensor(0.4524)\n",
            "=========\n",
            "epoch 115 train loss: 0.5068 val_cls: 0.4516 val_acc: 0.8810\n",
            "tensor(0.4516) tensor(0.4520)\n",
            "=========\n",
            "epoch 116 train loss: 0.5032 val_cls: 0.4510 val_acc: 0.8810\n",
            "tensor(0.4510) tensor(0.4516)\n",
            "=========\n",
            "epoch 117 train loss: 0.5029 val_cls: 0.4507 val_acc: 0.8810\n",
            "tensor(0.4507) tensor(0.4510)\n",
            "=========\n",
            "epoch 118 train loss: 0.5061 val_cls: 0.4502 val_acc: 0.8810\n",
            "tensor(0.4502) tensor(0.4507)\n",
            "=========\n",
            "epoch 119 train loss: 0.4953 val_cls: 0.4497 val_acc: 0.8810\n",
            "tensor(0.4497) tensor(0.4502)\n",
            "=========\n",
            "epoch 120 train loss: 0.4979 val_cls: 0.4494 val_acc: 0.8810\n",
            "tensor(0.4494) tensor(0.4497)\n",
            "=========\n",
            "epoch 121 train loss: 0.4959 val_cls: 0.4491 val_acc: 0.8810\n",
            "tensor(0.4491) tensor(0.4494)\n",
            "=========\n",
            "epoch 122 train loss: 0.5002 val_cls: 0.4487 val_acc: 0.8810\n",
            "tensor(0.4487) tensor(0.4491)\n",
            "=========\n",
            "epoch 123 train loss: 0.4847 val_cls: 0.4480 val_acc: 0.8810\n",
            "tensor(0.4480) tensor(0.4487)\n",
            "=========\n",
            "epoch 124 train loss: 0.4977 val_cls: 0.4478 val_acc: 0.8810\n",
            "tensor(0.4478) tensor(0.4480)\n",
            "=========\n",
            "epoch 125 train loss: 0.4874 val_cls: 0.4473 val_acc: 0.8810\n",
            "tensor(0.4473) tensor(0.4478)\n",
            "=========\n",
            "epoch 126 train loss: 0.4840 val_cls: 0.4470 val_acc: 0.8810\n",
            "tensor(0.4470) tensor(0.4473)\n",
            "=========\n",
            "epoch 127 train loss: 0.4927 val_cls: 0.4468 val_acc: 0.8810\n",
            "tensor(0.4468) tensor(0.4470)\n",
            "=========\n",
            "epoch 128 train loss: 0.4856 val_cls: 0.4464 val_acc: 0.8810\n",
            "tensor(0.4464) tensor(0.4468)\n",
            "=========\n",
            "epoch 129 train loss: 0.4944 val_cls: 0.4462 val_acc: 0.8810\n",
            "tensor(0.4462) tensor(0.4464)\n",
            "=========\n",
            "epoch 130 train loss: 0.4836 val_cls: 0.4458 val_acc: 0.8810\n",
            "tensor(0.4458) tensor(0.4462)\n",
            "=========\n",
            "epoch 131 train loss: 0.4777 val_cls: 0.4453 val_acc: 0.8810\n",
            "tensor(0.4453) tensor(0.4458)\n",
            "=========\n",
            "epoch 132 train loss: 0.4823 val_cls: 0.4450 val_acc: 0.8810\n",
            "tensor(0.4450) tensor(0.4453)\n",
            "=========\n",
            "epoch 133 train loss: 0.4774 val_cls: 0.4446 val_acc: 0.8810\n",
            "tensor(0.4446) tensor(0.4450)\n",
            "=========\n",
            "epoch 134 train loss: 0.4779 val_cls: 0.4443 val_acc: 0.8810\n",
            "tensor(0.4443) tensor(0.4446)\n",
            "=========\n",
            "epoch 135 train loss: 0.4687 val_cls: 0.4440 val_acc: 0.8810\n",
            "tensor(0.4440) tensor(0.4443)\n",
            "=========\n",
            "epoch 136 train loss: 0.4817 val_cls: 0.4438 val_acc: 0.8810\n",
            "tensor(0.4438) tensor(0.4440)\n",
            "=========\n",
            "epoch 137 train loss: 0.4756 val_cls: 0.4434 val_acc: 0.8810\n",
            "tensor(0.4434) tensor(0.4438)\n",
            "=========\n",
            "epoch 138 train loss: 0.4793 val_cls: 0.4432 val_acc: 0.8810\n",
            "tensor(0.4432) tensor(0.4434)\n",
            "=========\n",
            "epoch 139 train loss: 0.4589 val_cls: 0.4429 val_acc: 0.8810\n",
            "tensor(0.4429) tensor(0.4432)\n",
            "=========\n",
            "epoch 140 train loss: 0.4699 val_cls: 0.4426 val_acc: 0.8810\n",
            "tensor(0.4426) tensor(0.4429)\n",
            "=========\n",
            "epoch 141 train loss: 0.4632 val_cls: 0.4423 val_acc: 0.8810\n",
            "tensor(0.4423) tensor(0.4426)\n",
            "=========\n",
            "epoch 142 train loss: 0.4753 val_cls: 0.4421 val_acc: 0.8810\n",
            "tensor(0.4421) tensor(0.4423)\n",
            "=========\n",
            "epoch 143 train loss: 0.4600 val_cls: 0.4419 val_acc: 0.8810\n",
            "tensor(0.4419) tensor(0.4421)\n",
            "=========\n",
            "epoch 144 train loss: 0.4602 val_cls: 0.4417 val_acc: 0.8810\n",
            "tensor(0.4417) tensor(0.4419)\n",
            "=========\n",
            "epoch 145 train loss: 0.4617 val_cls: 0.4416 val_acc: 0.8810\n",
            "tensor(0.4416) tensor(0.4417)\n",
            "=========\n",
            "epoch 146 train loss: 0.4532 val_cls: 0.4416 val_acc: 0.8810\n",
            "tensor(0.4416) tensor(0.4416)\n",
            "=========\n",
            "epoch 147 train loss: 0.4500 val_cls: 0.4415 val_acc: 0.8810\n",
            "tensor(0.4415) tensor(0.4416)\n",
            "=========\n",
            "epoch 148 train loss: 0.4440 val_cls: 0.4414 val_acc: 0.8810\n",
            "tensor(0.4414) tensor(0.4415)\n",
            "=========\n",
            "epoch 149 train loss: 0.4539 val_cls: 0.4412 val_acc: 0.8810\n",
            "tensor(0.4412) tensor(0.4414)\n",
            "=========\n",
            "epoch 150 train loss: 0.4493 val_cls: 0.4411 val_acc: 0.8810\n",
            "tensor(0.4411) tensor(0.4412)\n",
            "=========\n",
            "epoch 151 train loss: 0.4410 val_cls: 0.4410 val_acc: 0.8810\n",
            "tensor(0.4410) tensor(0.4411)\n",
            "=========\n",
            "epoch 152 train loss: 0.4429 val_cls: 0.4409 val_acc: 0.8810\n",
            "tensor(0.4409) tensor(0.4410)\n",
            "=========\n",
            "epoch 153 train loss: 0.4336 val_cls: 0.4408 val_acc: 0.8810\n",
            "tensor(0.4408) tensor(0.4409)\n",
            "=========\n",
            "epoch 154 train loss: 0.4406 val_cls: 0.4408 val_acc: 0.8810\n",
            "tensor(0.4408) tensor(0.4408)\n",
            "=========\n",
            "epoch 155 train loss: 0.4378 val_cls: 0.4408 val_acc: 0.8810\n",
            "tensor(0.4408) tensor(0.4408)\n",
            "=========\n",
            "epoch 156 train loss: 0.4471 val_cls: 0.4408 val_acc: 0.8810\n",
            "tensor(0.4408) tensor(0.4408)\n",
            "=========\n",
            "epoch 157 train loss: 0.4356 val_cls: 0.4408 val_acc: 0.8810\n",
            "tensor(0.4408) tensor(0.4408)\n",
            "=========\n",
            "epoch 158 train loss: 0.4355 val_cls: 0.4408 val_acc: 0.8810\n",
            "tensor(0.4408) tensor(0.4408)\n",
            "=========\n",
            "epoch 159 train loss: 0.4293 val_cls: 0.4407 val_acc: 0.8810\n",
            "tensor(0.4407) tensor(0.4408)\n",
            "=========\n",
            "epoch 160 train loss: 0.4272 val_cls: 0.4408 val_acc: 0.8810\n",
            "tensor(0.4408) tensor(0.4407)\n",
            "=========\n",
            "epoch 161 train loss: 0.4177 val_cls: 0.4408 val_acc: 0.8810\n",
            "tensor(0.4408) tensor(0.4407)\n",
            "=========\n",
            "epoch 162 train loss: 0.4294 val_cls: 0.4411 val_acc: 0.8810\n",
            "tensor(0.4411) tensor(0.4407)\n",
            "=========\n",
            "epoch 163 train loss: 0.4256 val_cls: 0.4410 val_acc: 0.8810\n",
            "tensor(0.4410) tensor(0.4407)\n",
            "=========\n",
            "epoch 164 train loss: 0.4243 val_cls: 0.4410 val_acc: 0.8810\n",
            "tensor(0.4410) tensor(0.4407)\n",
            "EARLY STOPPING \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "qO0xooOmL_3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history[\"train_loss\"], label='train');\n",
        "plt.plot(history[\"val_cls\"], label='val');\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "YIp9yuw_1KsA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "d0297188-5a5e-4717-c747-4a24af90c493"
      },
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f475087baf0>"
            ]
          },
          "metadata": {},
          "execution_count": 292
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history[\"val_acc\"]);\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('ACC');"
      ],
      "metadata": {
        "id": "LpiIB4WwKK2S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b2d35a01-10e3-472d-b4c1-6e9c8304fbda"
      },
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "predictions = utils.test(classification_model, test_iter)\n",
        "predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_true = y_test, y_pred = predictions))\n",
        "print(\"MSE:\", mse(y_true = y_test, y_pred = predictions))\n",
        "print(\"MAE:\", mae(y_true = y_test, y_pred = predictions))"
      ],
      "metadata": {
        "id": "d_iaeA9ce5GM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "716013c1-5441-4f29-d2a3-8cf069ca3fec"
      },
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8585714285714285\n",
            "MSE: 0.5714285714285714\n",
            "MAE: 0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# examine accuracy of predictions for test set\n",
        "pred = utils.test(classification_model, test_iter)\n",
        "# find the most likely rating for the specific review by finding the column with the highest score in each row of the matrix\n",
        "conv_pred = np.argmax(pred, axis=1)\n",
        "\n",
        "# print classification report\n",
        "print(classification_report(y_pred=conv_pred, y_true=y_test))"
      ],
      "metadata": {
        "id": "lIL_BJZgKXmm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdf09282-fe66-4ea1-aae2-3ddfa00b03d8"
      },
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        13\n",
            "           1       0.00      0.00      0.00         8\n",
            "           2       0.00      0.00      0.00        14\n",
            "           3       0.00      0.00      0.00        64\n",
            "           4       0.86      1.00      0.92       601\n",
            "\n",
            "    accuracy                           0.86       700\n",
            "   macro avg       0.17      0.20      0.18       700\n",
            "weighted avg       0.74      0.86      0.79       700\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y_test, conv_pred);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "D6MiVGlR_Hct",
        "outputId": "5272b906-94da-4b84-8b23-758c6f665cec"
      },
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}