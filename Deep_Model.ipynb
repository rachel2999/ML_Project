{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Drink Quality by Reviews"
      ],
      "metadata": {
        "id": "WTkQ8n1FsVJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examine the correlation between \"Rating\" and \"Review\" to determine if the quality of a drink can be predicted based on it's reviews."
      ],
      "metadata": {
        "id": "3QLwH_X0TL_-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1THLhLXDOmz",
        "outputId": "cae7d386-6365-4d9b-881c-8d13d093df6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting import-ipynb\n",
            "  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.8/dist-packages (from import-ipynb) (7.9.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from import-ipynb) (5.7.1)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (5.7.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (57.4.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (2.0.10)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (0.7.5)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.8/dist-packages (from nbformat->import-ipynb) (5.1.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->import-ipynb) (2.16.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->import-ipynb) (4.3.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->IPython->import-ipynb) (0.8.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (22.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.19.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (5.10.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import-ipynb) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import-ipynb) (1.15.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core->nbformat->import-ipynb) (2.6.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->IPython->import-ipynb) (0.7.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->import-ipynb) (3.11.0)\n",
            "Installing collected packages: jedi, import-ipynb\n",
            "Successfully installed import-ipynb-0.1.4 jedi-0.18.2\n"
          ]
        }
      ],
      "source": [
        "!pip install import-ipynb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/MyDrive/ML-Project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XZesjC4DUcU",
        "outputId": "88195687-b1aa-4610-d64f-b6a47070f2a4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/ML-Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import random\n",
        "import import_ipynb\n",
        "import utils\n",
        "\n",
        "\n",
        "# to get reproducible results:\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC_ZMjWvDYoj",
        "outputId": "153fc0bb-32aa-4239-b784-5a6cdada09c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "importing Jupyter notebook from utils.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "metadata": {
        "id": "CoLyV47NLEas"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing the Dataset"
      ],
      "metadata": {
        "id": "kJTb2CCVK6Gw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read dataset file\n",
        "df = pd.read_csv('dataset.csv', sep=',')"
      ],
      "metadata": {
        "id": "KKBmGAx6Dn7_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace column names with shorter, more readable names\n",
        "df.columns = ['Num', 'Brand', 'Name', 'Date', 'Recommend', 'Helpful', 'Rating', 'Weight', 'Review Title', 'Review']\n",
        "df.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "mg_ZwGcTEClT",
        "outputId": "b684e906-7180-42cb-b60e-d6c7597e74b2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Num        Brand                                       Name  \\\n",
              "1263  1264         Gmax     Gmax g144105 gm44 full face red wine m   \n",
              "227    228     Heineken     Heineken174 Lager - 6pk / 12oz Bottles   \n",
              "2142  2143       Carmex  Carmex Lip Balm Original Jar - 12 PK, 12.   \n",
              "450    451     Jim Beam      Jim Beam Black Bourbon Whiskey, 50 mL   \n",
              "1403  1404  Great Value  Great Value Original Crescent Rolls, 8 oz   \n",
              "\n",
              "                      Date Recommend  Helpful  Rating   Weight  \\\n",
              "1263  2017-01-09T22:25:24Z       NaN      NaN     4.0      NaN   \n",
              "227   2017-09-20T01:18:35Z      True      NaN     5.0  1.0 lbs   \n",
              "2142  2017-09-23T02:53:08Z      True      NaN     5.0      NaN   \n",
              "450   2017-09-20T01:18:35Z       NaN      NaN     5.0      NaN   \n",
              "1403  2017-09-02T07:55:36Z      True      0.0     5.0      NaN   \n",
              "\n",
              "                   Review Title  \\\n",
              "1263                        NaN   \n",
              "227                 Great beer!   \n",
              "2142         Small and compact!   \n",
              "450        My favorite bourbon!   \n",
              "1403  Just as good as Pillsbury   \n",
              "\n",
              "                                                 Review  \n",
              "1263                                       easy process  \n",
              "227   I bought this, best price and great convenienc...  \n",
              "2142  The lip balm is so smooth, doesn't have a weir...  \n",
              "450                          Exceptionally good flavor!  \n",
              "1403         Just as good as Pillsbury but better price  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fbcab693-5582-407b-918f-b0350fd97d15\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Num</th>\n",
              "      <th>Brand</th>\n",
              "      <th>Name</th>\n",
              "      <th>Date</th>\n",
              "      <th>Recommend</th>\n",
              "      <th>Helpful</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Review Title</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1263</th>\n",
              "      <td>1264</td>\n",
              "      <td>Gmax</td>\n",
              "      <td>Gmax g144105 gm44 full face red wine m</td>\n",
              "      <td>2017-01-09T22:25:24Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>easy process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>228</td>\n",
              "      <td>Heineken</td>\n",
              "      <td>Heineken174 Lager - 6pk / 12oz Bottles</td>\n",
              "      <td>2017-09-20T01:18:35Z</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>Great beer!</td>\n",
              "      <td>I bought this, best price and great convenienc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2142</th>\n",
              "      <td>2143</td>\n",
              "      <td>Carmex</td>\n",
              "      <td>Carmex Lip Balm Original Jar - 12 PK, 12.</td>\n",
              "      <td>2017-09-23T02:53:08Z</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Small and compact!</td>\n",
              "      <td>The lip balm is so smooth, doesn't have a weir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>451</td>\n",
              "      <td>Jim Beam</td>\n",
              "      <td>Jim Beam Black Bourbon Whiskey, 50 mL</td>\n",
              "      <td>2017-09-20T01:18:35Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>My favorite bourbon!</td>\n",
              "      <td>Exceptionally good flavor!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1403</th>\n",
              "      <td>1404</td>\n",
              "      <td>Great Value</td>\n",
              "      <td>Great Value Original Crescent Rolls, 8 oz</td>\n",
              "      <td>2017-09-02T07:55:36Z</td>\n",
              "      <td>True</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just as good as Pillsbury</td>\n",
              "      <td>Just as good as Pillsbury but better price</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fbcab693-5582-407b-918f-b0350fd97d15')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fbcab693-5582-407b-918f-b0350fd97d15 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fbcab693-5582-407b-918f-b0350fd97d15');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove useless columns\n",
        "df.drop(\"Num\", axis=1, inplace=True)\n",
        "df.drop(\"Date\", axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "2AiS9linDA-b"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reindex rows\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "5H4vyxXCbgt2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "outputId": "bfb8cccf-11e3-4ddf-bc8a-cde7e619c4f1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Brand                                               Name  \\\n",
              "0             Gallo         Ecco Domani174 Pinot Grigio - 750ml Bottle   \n",
              "1   Fresh Craft Co.   Fresh Craft174 Mango Citrus - 4pk / 250ml Bottle   \n",
              "2      1000 Stories           1000 Stories174 Zinfandel - 750ml Bottle   \n",
              "3      1000 Stories           1000 Stories174 Zinfandel - 750ml Bottle   \n",
              "4      Wine Cube153            Pink Moscato - 3l Bottle - Wine Cube153   \n",
              "5         Beck's Na  Beck's174 Non Alcoholic Beer - 6pk / 12oz Bottles   \n",
              "6             Gallo                Apothic174 Red Blend - 750ml Bottle   \n",
              "7             Gallo                Apothic174 Red Blend - 750ml Bottle   \n",
              "8  California Roots        California Roots Moscato White Wine - 750ml   \n",
              "9   Charles Charles        Charles Charles174 Red Blend - 750ml Bottle   \n",
              "\n",
              "  Recommend  Helpful  Rating    Weight                          Review Title  \\\n",
              "0      True      1.0     5.0   1.0 lbs                My Favorite White Wine   \n",
              "1      True      NaN     5.0  2.45 lbs                                 Yum!!   \n",
              "2      True      NaN     5.0  3.09 lbs                       A New Favorite!   \n",
              "3      True      NaN     5.0  3.09 lbs  Bold, Flavorful, Aromatic, Delicious   \n",
              "4      True      1.0     5.0   1.0 lbs  Yum! Plus, Environmentally Friendly!   \n",
              "5      True      NaN     5.0   1.0 lbs                           Great Taste   \n",
              "6       NaN      1.0     3.0   1.0 lbs                      Simply Wonderful   \n",
              "7       NaN      1.0     2.0   1.0 lbs                          A Sweet Red.   \n",
              "8      True      0.0     5.0  2.65 lbs                                   NaN   \n",
              "9      True      NaN     5.0   1.0 lbs           Charles & Charles Red Blend   \n",
              "\n",
              "                                              Review  \n",
              "0      This a fantastic white wine for any occasion!  \n",
              "1   Tart, not sweet...very refreshing and delicious!  \n",
              "2  I was given this wine so it was a delightful s...  \n",
              "3  This is a phenomenal wine and my new favorite ...  \n",
              "4  4 750ml bottles for the price of two With way ...  \n",
              "5  I LOVE Becks NA. It tastes just like a regular...  \n",
              "6  This wine has a wonderful but strong aroma its...  \n",
              "7  I would give one more star if it came clean on...  \n",
              "8                      Delicious and very affordable  \n",
              "9  This is a very smooth red with Aromas of cocoa...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d6c88d1-9b3b-45a7-a01b-81c8df0f7d10\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Brand</th>\n",
              "      <th>Name</th>\n",
              "      <th>Recommend</th>\n",
              "      <th>Helpful</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Review Title</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Gallo</td>\n",
              "      <td>Ecco Domani174 Pinot Grigio - 750ml Bottle</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>My Favorite White Wine</td>\n",
              "      <td>This a fantastic white wine for any occasion!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fresh Craft Co.</td>\n",
              "      <td>Fresh Craft174 Mango Citrus - 4pk / 250ml Bottle</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.45 lbs</td>\n",
              "      <td>Yum!!</td>\n",
              "      <td>Tart, not sweet...very refreshing and delicious!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000 Stories</td>\n",
              "      <td>1000 Stories174 Zinfandel - 750ml Bottle</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.09 lbs</td>\n",
              "      <td>A New Favorite!</td>\n",
              "      <td>I was given this wine so it was a delightful s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000 Stories</td>\n",
              "      <td>1000 Stories174 Zinfandel - 750ml Bottle</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.09 lbs</td>\n",
              "      <td>Bold, Flavorful, Aromatic, Delicious</td>\n",
              "      <td>This is a phenomenal wine and my new favorite ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Wine Cube153</td>\n",
              "      <td>Pink Moscato - 3l Bottle - Wine Cube153</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>Yum! Plus, Environmentally Friendly!</td>\n",
              "      <td>4 750ml bottles for the price of two With way ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Beck's Na</td>\n",
              "      <td>Beck's174 Non Alcoholic Beer - 6pk / 12oz Bottles</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>Great Taste</td>\n",
              "      <td>I LOVE Becks NA. It tastes just like a regular...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Gallo</td>\n",
              "      <td>Apothic174 Red Blend - 750ml Bottle</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>Simply Wonderful</td>\n",
              "      <td>This wine has a wonderful but strong aroma its...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Gallo</td>\n",
              "      <td>Apothic174 Red Blend - 750ml Bottle</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>A Sweet Red.</td>\n",
              "      <td>I would give one more star if it came clean on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>California Roots</td>\n",
              "      <td>California Roots Moscato White Wine - 750ml</td>\n",
              "      <td>True</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.65 lbs</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Delicious and very affordable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Charles Charles</td>\n",
              "      <td>Charles Charles174 Red Blend - 750ml Bottle</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>Charles &amp; Charles Red Blend</td>\n",
              "      <td>This is a very smooth red with Aromas of cocoa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d6c88d1-9b3b-45a7-a01b-81c8df0f7d10')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d6c88d1-9b3b-45a7-a01b-81c8df0f7d10 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d6c88d1-9b3b-45a7-a01b-81c8df0f7d10');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check for total amount of null values in each column\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "Q7ZAX3-RGAOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66c021b9-3aee-41c6-91a7-e29fd3931132"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brand             65\n",
            "Name               0\n",
            "Recommend        979\n",
            "Helpful         2264\n",
            "Rating           445\n",
            "Weight          1894\n",
            "Review Title      44\n",
            "Review             1\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove all rows that have no ratings or recommendations\n",
        "df = df.dropna(subset=['Rating'])\n",
        "df = df.dropna(subset=['Recommend'])\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "E9Pkbdj-IVA_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bca5921d-247c-4611-b1b9-73a1b120b8cc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Brand              0\n",
              "Name               0\n",
              "Recommend          0\n",
              "Helpful         1170\n",
              "Rating             0\n",
              "Weight          1392\n",
              "Review Title      10\n",
              "Review             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the all possible ratings from 1 to 5 are used\n",
        "np.unique(df['Rating'])"
      ],
      "metadata": {
        "id": "yJIJNlkkKqkV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2c73253-6a20-4324-8c5d-1f20fb991fce"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 2., 3., 4., 5.])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "FOC26UJ1BgCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34a7267b-1ce8-4468-cd7e-1c673044e661"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1748 entries, 0 to 2815\n",
            "Data columns (total 8 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Brand         1748 non-null   object \n",
            " 1   Name          1748 non-null   object \n",
            " 2   Recommend     1748 non-null   object \n",
            " 3   Helpful       578 non-null    float64\n",
            " 4   Rating        1748 non-null   float64\n",
            " 5   Weight        356 non-null    object \n",
            " 6   Review Title  1738 non-null   object \n",
            " 7   Review        1748 non-null   object \n",
            "dtypes: float64(2), object(6)\n",
            "memory usage: 122.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change data type of \"Rating\" from float to integer\n",
        "df['Rating'] = df['Rating'].astype(int)\n",
        "\n",
        "# change data type of \"Recommend\" from object to integer\n",
        "# \"True\" = 1, \"False\" = 0\n",
        "df[\"Recommend\"] = df[\"Recommend\"].astype(int)\n",
        "\n",
        "# check data types again\n",
        "df.info()"
      ],
      "metadata": {
        "id": "55B7BhBBL4VK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f823da0d-ab4f-400e-ab16-6f239567d398"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1748 entries, 0 to 2815\n",
            "Data columns (total 8 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Brand         1748 non-null   object \n",
            " 1   Name          1748 non-null   object \n",
            " 2   Recommend     1748 non-null   int64  \n",
            " 3   Helpful       578 non-null    float64\n",
            " 4   Rating        1748 non-null   int64  \n",
            " 5   Weight        356 non-null    object \n",
            " 6   Review Title  1738 non-null   object \n",
            " 7   Review        1748 non-null   object \n",
            "dtypes: float64(1), int64(2), object(5)\n",
            "memory usage: 122.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect correlation between numeric features\n",
        "df.corr()"
      ],
      "metadata": {
        "id": "72OEXXdrb6EF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "de056cbd-ecae-4650-c569-c54e488cdfb7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Recommend   Helpful    Rating\n",
              "Recommend   1.000000  0.042670  0.767292\n",
              "Helpful     0.042670  1.000000  0.024891\n",
              "Rating      0.767292  0.024891  1.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de382b0e-c8ca-4468-8387-45c1b335f20e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Recommend</th>\n",
              "      <th>Helpful</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Recommend</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.042670</td>\n",
              "      <td>0.767292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Helpful</th>\n",
              "      <td>0.042670</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.024891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Rating</th>\n",
              "      <td>0.767292</td>\n",
              "      <td>0.024891</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de382b0e-c8ca-4468-8387-45c1b335f20e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-de382b0e-c8ca-4468-8387-45c1b335f20e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-de382b0e-c8ca-4468-8387-45c1b335f20e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- There is a weak positive correlation between recommend and helpful. Reviews that were voted helpful tend to be about alcohol that reviewers recommend to others.\n",
        "- There is a strong positive correlation between recommend and rating. The higher the rating/quality of the alcohol, then then the more likely that the reviewer would recommend it.\n",
        "- There is a very weak positive correlation between helpful and rating. Alcohol that was voted helpful tend to have slightly higher ratings than reviews not considered helpful."
      ],
      "metadata": {
        "id": "hJSUEBotcmi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check for duplicated reviews\n",
        "df['Review'].duplicated().sum()"
      ],
      "metadata": {
        "id": "Y4Ggih8XF42P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7471f033-2db9-4bfd-88a8-5a0adef0ff3e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove duplicated reviews\n",
        "df['Review'].drop_duplicates()"
      ],
      "metadata": {
        "id": "U1QKOX4uF-UU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f313a600-4920-4e8a-c74b-28a2d31fc1ec"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0           This a fantastic white wine for any occasion!\n",
              "1        Tart, not sweet...very refreshing and delicious!\n",
              "2       I was given this wine so it was a delightful s...\n",
              "3       This is a phenomenal wine and my new favorite ...\n",
              "4       4 750ml bottles for the price of two With way ...\n",
              "                              ...                        \n",
              "2811    My kids love them. So no complaints but I'm su...\n",
              "2812    Easy and quick to serve, brings a smile to the...\n",
              "2813                         Worked great kids loved them\n",
              "2814    Walmart used to carry a Swiss water decaf coff...\n",
              "2815    Great decaf coffee using Swiss water process. ...\n",
              "Name: Review, Length: 1735, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clean text in reviews with natural language toolkit\n",
        "!pip install nltk\n",
        "import nltk\n",
        "\n",
        "# define stopwords to remove\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stopwords = set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "id": "PupCwDbIoOpi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a201a133-2488-4ae7-9b99-e581b01f929b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize text with regex before cleaning\n",
        "from nltk import word_tokenize\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "token = TreebankWordDetokenizer()\n",
        "\n",
        "def clean(w):\n",
        "    w = word_tokenize(w.lower()) # turn all token words lowercase\n",
        "    w = [token for token in w if token not in stopwords and token.isalpha()] # remove stopwords and non-words (punctuation, numbers, etc.)\n",
        "    return token.detokenize(w)\n",
        "\n",
        "df[\"Clean_Reviews\"] = df[\"Review\"].apply(clean)"
      ],
      "metadata": {
        "id": "NzYNfnTejmJV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check to make sure the reviews were cleaned correctly\n",
        "df[\"Clean_Reviews\"].sample(10)"
      ],
      "metadata": {
        "id": "-Yj3GOHztCI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7b8cc98-a5e0-4af0-e80a-f6e3fa345da4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1596    prefer purchase store individually whatever ne...\n",
              "477                             best bloody mary mix ever\n",
              "2364    started using carmex cna brand count heal supp...\n",
              "2061    using carmex yrs still always keep jar purse t...\n",
              "2226    started applying four times day honestly great...\n",
              "2373    buy carmex tub becuase mother always wood open...\n",
              "829                                              favorite\n",
              "1980    use many year really work dry lips light burn ...\n",
              "1994    always go back carmex original lip balm jar li...\n",
              "2585    using carmex original lip balm jar since child...\n",
              "Name: Clean_Reviews, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network Algorithm - Deep Model"
      ],
      "metadata": {
        "id": "eyTXVRRGf-t8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "UST9kQW_f-t9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset 40% test, 60% train\n",
        "y = df[\"Rating\"].values\n",
        "words = df[\"Clean_Reviews\"].values\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(words, y, test_size=0.4, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "77iLLy7jf-t9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# examine a random dictionary entry\n",
        "print(\"Review:\", x_train[2])\n",
        "print(\"Rating:\", y_train[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50c69333-edb0-405e-8f87-57b8de8c3dfa",
        "id": "LICtu_WMf-t9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: price incredible delivery service better could hoped\n",
            "Rating: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize the reviews to vectorize each word as an integer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# limit vocabularly index to the most common 5000 words\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "# create vocab index based on word frequency\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "# apply limited vocab to train and test\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_test = tokenizer.texts_to_sequences(x_test)"
      ],
      "metadata": {
        "id": "qT9XBoq9f-t9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# examine a random dictionary entry\n",
        "print(\"Encoded Review:\", x_train[2])\n",
        "print(\"Rating:\", y_train[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "299aa5d2-f378-46d7-831b-bbfe40d5646f",
        "id": "jPQjl2bFf-t9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Review: [50, 717, 427, 953, 58, 90, 954]\n",
            "Rating: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# re-vectorize reviews into sparse 2D nummpy array, with many zeros in the data\n",
        "# convert the reviews into a matrix, one review per row and one column per word\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "\n",
        "num_words=5000\n",
        "x_train = vectorize_sequences(x_train, dimension=num_words)\n",
        "x_test = vectorize_sequences(x_test, dimension=num_words)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7a3dbba-fbc4-4050-a60c-56ca708b34c3",
        "id": "fv22yQfNf-t9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1048, 5000)\n",
            "(700, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train[:15])\n",
        "print(y_test[:15])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeb7b4da-fca3-4edb-9537-7fdf0fa9c31e",
        "id": "IODJZEVXf-t9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 5 5 5 5 5 1 5 5 5 5 5 5 5 5]\n",
            "[4 5 4 5 4 5 4 4 5 5 5 5 5 5 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "cnt = Counter(list(y_train))\n",
        "num_classes = 5\n",
        "cnt.most_common(num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5e7e514-05e0-4a01-9f42-4e0a6b20fb01",
        "id": "dTivtGxJf-t9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(5, 900), (4, 90), (3, 24), (1, 23), (2, 11)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_labels = sorted(set([i[0] for i in cnt.most_common(num_classes)]))\n",
        "selected_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67e06745-a73e-43f9-a335-6bf9b8dcdda5",
        "id": "M45nAzhkf-t-"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_mask = [True if l in selected_labels else False for l in y_train]\n",
        "x_train = x_train[train_mask, :]\n",
        "y_train = y_train[train_mask]\n",
        "y_train = np.array([selected_labels.index(i) for i in y_train]) # reindex\n",
        "\n",
        "test_mask = [True if l in selected_labels else False for l in y_test]\n",
        "x_test= x_test[test_mask, :]\n",
        "y_test = y_test[test_mask]\n",
        "y_test = np.array([selected_labels.index(i) for i in y_test]) # reindex\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "393dc01c-72fd-4997-f857-2c5e35ac5fc4",
        "id": "r5u5Z66Pf-t-"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1048, 5000)\n",
            "(700, 5000)\n",
            "(1048,)\n",
            "(700,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split training data into 40% train and 60% dev\n",
        "x_train, x_dev, y_train, y_dev = train_test_split(x_train, y_train, test_size=0.4, random_state=42)\n",
        "print(y_train.shape)\n",
        "print(x_train.shape)\n",
        "print(x_dev.shape)\n",
        "print(y_dev.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "354ff338-ec4b-4f6e-809b-66f6045bda10",
        "id": "7x-audOvf-t-"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(628,)\n",
            "(628, 5000)\n",
            "(420, 5000)\n",
            "(420,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert numpy array into PyTorch format\n",
        "\n",
        "# 1) define function\n",
        "def np2iter(x, y, shuffle=True):\n",
        "  x = torch.tensor(x, dtype=torch.float)\n",
        "  y = torch.tensor(y, dtype=torch.long)\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  print(\"----------------------\")\n",
        "\n",
        "  ds = torch.utils.data.TensorDataset(x, y)\n",
        "  return torch.utils.data.DataLoader(ds, batch_size=32, shuffle=shuffle)\n",
        "\n",
        "# 2) convert data\n",
        "train_iter = np2iter(x_train, y_train, shuffle=True) # DO shuffle train\n",
        "dev_iter =  np2iter(x_dev, y_dev, shuffle=False) # do NOT shuffle dev or test\n",
        "test_iter =  np2iter(x_test, y_test, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4796d28e-c53f-4cc5-f88f-8f655fb5ef2c",
        "id": "qZTbVwmtf-t-"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([628, 5000])\n",
            "torch.Size([628])\n",
            "----------------------\n",
            "torch.Size([420, 5000])\n",
            "torch.Size([420])\n",
            "----------------------\n",
            "torch.Size([700, 5000])\n",
            "torch.Size([700])\n",
            "----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining accuracy\n",
        "def val_acc(y_pred, y_test): # define accuracy\n",
        "  y_pred = np.argmax(y_pred, axis=1)\n",
        "  return accuracy_score(y_pred=y_pred, y_true=y_test)"
      ],
      "metadata": {
        "id": "Uy56nWszf-t-"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "RySLkWAMLnbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define deep model\n",
        "num_words = 5000\n",
        "\n",
        "class DeepModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DeepModel, self).__init__()\n",
        "    # nn.sequential executes the following layers one by one, from linear layer to rectified layer unit\n",
        "    self.layer = nn.Sequential(nn.Linear(in_features=num_words, out_features=30), \n",
        "                                nn.Dropout(p=0.33),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Linear(in_features=30, out_features=30),\n",
        "                                nn.Dropout(p=0.33),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Linear(in_features=30, out_features=5))\n",
        "\n",
        "    \n",
        "  # feed the model the input and apply the linear layer to get the output\n",
        "  def forward(self, x):\n",
        "    return self.layer(x)"
      ],
      "metadata": {
        "id": "YKDbXb4-g3tH"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_model = DeepModel()\n",
        "classification_model = classification_model.cuda()"
      ],
      "metadata": {
        "id": "5U5BYKJAhFYC"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = utils.train(model=classification_model,\n",
        "                            loss=nn.CrossEntropyLoss(),\n",
        "                            val_metrics={\"cls\": nn.CrossEntropyLoss(), \"acc\": val_acc}, \n",
        "                            optimizer=torch.optim.SGD(classification_model.parameters(), lr=0.01),\n",
        "                            train_ds=train_iter, \n",
        "                            dev_ds=dev_iter,\n",
        "                            num_epochs=200,\n",
        "                            early_stopper=utils.EarlyStopper(metric_name=\"cls\", patience=5))"
      ],
      "metadata": {
        "id": "2l319rxEL8aY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a0e5fb9-6349-4dc2-b342-eb57f1e5bfba"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========\n",
            "epoch 1 train loss: 1.6326 val_cls: 1.5648 val_acc: 0.0119\n",
            "tensor(1.5648) None\n",
            "=========\n",
            "epoch 2 train loss: 1.5123 val_cls: 1.4429 val_acc: 0.8810\n",
            "tensor(1.4429) tensor(1.5648)\n",
            "=========\n",
            "epoch 3 train loss: 1.4016 val_cls: 1.3294 val_acc: 0.8810\n",
            "tensor(1.3294) tensor(1.4429)\n",
            "=========\n",
            "epoch 4 train loss: 1.2990 val_cls: 1.2266 val_acc: 0.8810\n",
            "tensor(1.2266) tensor(1.3294)\n",
            "=========\n",
            "epoch 5 train loss: 1.2064 val_cls: 1.1323 val_acc: 0.8810\n",
            "tensor(1.1323) tensor(1.2266)\n",
            "=========\n",
            "epoch 6 train loss: 1.1217 val_cls: 1.0467 val_acc: 0.8810\n",
            "tensor(1.0467) tensor(1.1323)\n",
            "=========\n",
            "epoch 7 train loss: 1.0450 val_cls: 0.9695 val_acc: 0.8810\n",
            "tensor(0.9695) tensor(1.0467)\n",
            "=========\n",
            "epoch 8 train loss: 0.9803 val_cls: 0.9008 val_acc: 0.8810\n",
            "tensor(0.9008) tensor(0.9695)\n",
            "=========\n",
            "epoch 9 train loss: 0.9244 val_cls: 0.8411 val_acc: 0.8810\n",
            "tensor(0.8411) tensor(0.9008)\n",
            "=========\n",
            "epoch 10 train loss: 0.8674 val_cls: 0.7876 val_acc: 0.8810\n",
            "tensor(0.7876) tensor(0.8411)\n",
            "=========\n",
            "epoch 11 train loss: 0.8271 val_cls: 0.7417 val_acc: 0.8810\n",
            "tensor(0.7417) tensor(0.7876)\n",
            "=========\n",
            "epoch 12 train loss: 0.7927 val_cls: 0.7030 val_acc: 0.8810\n",
            "tensor(0.7030) tensor(0.7417)\n",
            "=========\n",
            "epoch 13 train loss: 0.7593 val_cls: 0.6704 val_acc: 0.8810\n",
            "tensor(0.6704) tensor(0.7030)\n",
            "=========\n",
            "epoch 14 train loss: 0.7364 val_cls: 0.6430 val_acc: 0.8810\n",
            "tensor(0.6430) tensor(0.6704)\n",
            "=========\n",
            "epoch 15 train loss: 0.7068 val_cls: 0.6199 val_acc: 0.8810\n",
            "tensor(0.6199) tensor(0.6430)\n",
            "=========\n",
            "epoch 16 train loss: 0.6924 val_cls: 0.6013 val_acc: 0.8810\n",
            "tensor(0.6013) tensor(0.6199)\n",
            "=========\n",
            "epoch 17 train loss: 0.6895 val_cls: 0.5867 val_acc: 0.8810\n",
            "tensor(0.5867) tensor(0.6013)\n",
            "=========\n",
            "epoch 18 train loss: 0.6694 val_cls: 0.5740 val_acc: 0.8810\n",
            "tensor(0.5740) tensor(0.5867)\n",
            "=========\n",
            "epoch 19 train loss: 0.6575 val_cls: 0.5630 val_acc: 0.8810\n",
            "tensor(0.5630) tensor(0.5740)\n",
            "=========\n",
            "epoch 20 train loss: 0.6489 val_cls: 0.5541 val_acc: 0.8810\n",
            "tensor(0.5541) tensor(0.5630)\n",
            "=========\n",
            "epoch 21 train loss: 0.6408 val_cls: 0.5461 val_acc: 0.8810\n",
            "tensor(0.5461) tensor(0.5541)\n",
            "=========\n",
            "epoch 22 train loss: 0.6447 val_cls: 0.5404 val_acc: 0.8810\n",
            "tensor(0.5404) tensor(0.5461)\n",
            "=========\n",
            "epoch 23 train loss: 0.6468 val_cls: 0.5362 val_acc: 0.8810\n",
            "tensor(0.5362) tensor(0.5404)\n",
            "=========\n",
            "epoch 24 train loss: 0.6380 val_cls: 0.5316 val_acc: 0.8810\n",
            "tensor(0.5316) tensor(0.5362)\n",
            "=========\n",
            "epoch 25 train loss: 0.6349 val_cls: 0.5279 val_acc: 0.8810\n",
            "tensor(0.5279) tensor(0.5316)\n",
            "=========\n",
            "epoch 26 train loss: 0.6211 val_cls: 0.5240 val_acc: 0.8810\n",
            "tensor(0.5240) tensor(0.5279)\n",
            "=========\n",
            "epoch 27 train loss: 0.6262 val_cls: 0.5210 val_acc: 0.8810\n",
            "tensor(0.5210) tensor(0.5240)\n",
            "=========\n",
            "epoch 28 train loss: 0.6241 val_cls: 0.5185 val_acc: 0.8810\n",
            "tensor(0.5185) tensor(0.5210)\n",
            "=========\n",
            "epoch 29 train loss: 0.6221 val_cls: 0.5163 val_acc: 0.8810\n",
            "tensor(0.5163) tensor(0.5185)\n",
            "=========\n",
            "epoch 30 train loss: 0.6304 val_cls: 0.5143 val_acc: 0.8810\n",
            "tensor(0.5143) tensor(0.5163)\n",
            "=========\n",
            "epoch 31 train loss: 0.6244 val_cls: 0.5127 val_acc: 0.8810\n",
            "tensor(0.5127) tensor(0.5143)\n",
            "=========\n",
            "epoch 32 train loss: 0.6168 val_cls: 0.5109 val_acc: 0.8810\n",
            "tensor(0.5109) tensor(0.5127)\n",
            "=========\n",
            "epoch 33 train loss: 0.6184 val_cls: 0.5093 val_acc: 0.8810\n",
            "tensor(0.5093) tensor(0.5109)\n",
            "=========\n",
            "epoch 34 train loss: 0.6146 val_cls: 0.5077 val_acc: 0.8810\n",
            "tensor(0.5077) tensor(0.5093)\n",
            "=========\n",
            "epoch 35 train loss: 0.6210 val_cls: 0.5063 val_acc: 0.8810\n",
            "tensor(0.5063) tensor(0.5077)\n",
            "=========\n",
            "epoch 36 train loss: 0.6096 val_cls: 0.5049 val_acc: 0.8810\n",
            "tensor(0.5049) tensor(0.5063)\n",
            "=========\n",
            "epoch 37 train loss: 0.6229 val_cls: 0.5038 val_acc: 0.8810\n",
            "tensor(0.5038) tensor(0.5049)\n",
            "=========\n",
            "epoch 38 train loss: 0.6176 val_cls: 0.5029 val_acc: 0.8810\n",
            "tensor(0.5029) tensor(0.5038)\n",
            "=========\n",
            "epoch 39 train loss: 0.6149 val_cls: 0.5018 val_acc: 0.8810\n",
            "tensor(0.5018) tensor(0.5029)\n",
            "=========\n",
            "epoch 40 train loss: 0.6064 val_cls: 0.5008 val_acc: 0.8810\n",
            "tensor(0.5008) tensor(0.5018)\n",
            "=========\n",
            "epoch 41 train loss: 0.6055 val_cls: 0.4998 val_acc: 0.8810\n",
            "tensor(0.4998) tensor(0.5008)\n",
            "=========\n",
            "epoch 42 train loss: 0.6064 val_cls: 0.4990 val_acc: 0.8810\n",
            "tensor(0.4990) tensor(0.4998)\n",
            "=========\n",
            "epoch 43 train loss: 0.6023 val_cls: 0.4979 val_acc: 0.8810\n",
            "tensor(0.4979) tensor(0.4990)\n",
            "=========\n",
            "epoch 44 train loss: 0.6005 val_cls: 0.4971 val_acc: 0.8810\n",
            "tensor(0.4971) tensor(0.4979)\n",
            "=========\n",
            "epoch 45 train loss: 0.5983 val_cls: 0.4963 val_acc: 0.8810\n",
            "tensor(0.4963) tensor(0.4971)\n",
            "=========\n",
            "epoch 46 train loss: 0.6031 val_cls: 0.4956 val_acc: 0.8810\n",
            "tensor(0.4956) tensor(0.4963)\n",
            "=========\n",
            "epoch 47 train loss: 0.6078 val_cls: 0.4947 val_acc: 0.8810\n",
            "tensor(0.4947) tensor(0.4956)\n",
            "=========\n",
            "epoch 48 train loss: 0.6026 val_cls: 0.4940 val_acc: 0.8810\n",
            "tensor(0.4940) tensor(0.4947)\n",
            "=========\n",
            "epoch 49 train loss: 0.6034 val_cls: 0.4933 val_acc: 0.8810\n",
            "tensor(0.4933) tensor(0.4940)\n",
            "=========\n",
            "epoch 50 train loss: 0.5966 val_cls: 0.4926 val_acc: 0.8810\n",
            "tensor(0.4926) tensor(0.4933)\n",
            "=========\n",
            "epoch 51 train loss: 0.6028 val_cls: 0.4919 val_acc: 0.8810\n",
            "tensor(0.4919) tensor(0.4926)\n",
            "=========\n",
            "epoch 52 train loss: 0.5968 val_cls: 0.4913 val_acc: 0.8810\n",
            "tensor(0.4913) tensor(0.4919)\n",
            "=========\n",
            "epoch 53 train loss: 0.6048 val_cls: 0.4909 val_acc: 0.8810\n",
            "tensor(0.4909) tensor(0.4913)\n",
            "=========\n",
            "epoch 54 train loss: 0.5925 val_cls: 0.4905 val_acc: 0.8810\n",
            "tensor(0.4905) tensor(0.4909)\n",
            "=========\n",
            "epoch 55 train loss: 0.5885 val_cls: 0.4897 val_acc: 0.8810\n",
            "tensor(0.4897) tensor(0.4905)\n",
            "=========\n",
            "epoch 56 train loss: 0.5962 val_cls: 0.4892 val_acc: 0.8810\n",
            "tensor(0.4892) tensor(0.4897)\n",
            "=========\n",
            "epoch 57 train loss: 0.5827 val_cls: 0.4885 val_acc: 0.8810\n",
            "tensor(0.4885) tensor(0.4892)\n",
            "=========\n",
            "epoch 58 train loss: 0.5987 val_cls: 0.4878 val_acc: 0.8810\n",
            "tensor(0.4878) tensor(0.4885)\n",
            "=========\n",
            "epoch 59 train loss: 0.5996 val_cls: 0.4876 val_acc: 0.8810\n",
            "tensor(0.4876) tensor(0.4878)\n",
            "=========\n",
            "epoch 60 train loss: 0.5972 val_cls: 0.4873 val_acc: 0.8810\n",
            "tensor(0.4873) tensor(0.4876)\n",
            "=========\n",
            "epoch 61 train loss: 0.5793 val_cls: 0.4865 val_acc: 0.8810\n",
            "tensor(0.4865) tensor(0.4873)\n",
            "=========\n",
            "epoch 62 train loss: 0.5842 val_cls: 0.4858 val_acc: 0.8810\n",
            "tensor(0.4858) tensor(0.4865)\n",
            "=========\n",
            "epoch 63 train loss: 0.5837 val_cls: 0.4851 val_acc: 0.8810\n",
            "tensor(0.4851) tensor(0.4858)\n",
            "=========\n",
            "epoch 64 train loss: 0.5880 val_cls: 0.4846 val_acc: 0.8810\n",
            "tensor(0.4846) tensor(0.4851)\n",
            "=========\n",
            "epoch 65 train loss: 0.5845 val_cls: 0.4841 val_acc: 0.8810\n",
            "tensor(0.4841) tensor(0.4846)\n",
            "=========\n",
            "epoch 66 train loss: 0.5779 val_cls: 0.4832 val_acc: 0.8810\n",
            "tensor(0.4832) tensor(0.4841)\n",
            "=========\n",
            "epoch 67 train loss: 0.5881 val_cls: 0.4830 val_acc: 0.8810\n",
            "tensor(0.4830) tensor(0.4832)\n",
            "=========\n",
            "epoch 68 train loss: 0.5791 val_cls: 0.4822 val_acc: 0.8810\n",
            "tensor(0.4822) tensor(0.4830)\n",
            "=========\n",
            "epoch 69 train loss: 0.5798 val_cls: 0.4817 val_acc: 0.8810\n",
            "tensor(0.4817) tensor(0.4822)\n",
            "=========\n",
            "epoch 70 train loss: 0.5743 val_cls: 0.4810 val_acc: 0.8810\n",
            "tensor(0.4810) tensor(0.4817)\n",
            "=========\n",
            "epoch 71 train loss: 0.5690 val_cls: 0.4802 val_acc: 0.8810\n",
            "tensor(0.4802) tensor(0.4810)\n",
            "=========\n",
            "epoch 72 train loss: 0.5697 val_cls: 0.4795 val_acc: 0.8810\n",
            "tensor(0.4795) tensor(0.4802)\n",
            "=========\n",
            "epoch 73 train loss: 0.5802 val_cls: 0.4790 val_acc: 0.8810\n",
            "tensor(0.4790) tensor(0.4795)\n",
            "=========\n",
            "epoch 74 train loss: 0.5825 val_cls: 0.4787 val_acc: 0.8810\n",
            "tensor(0.4787) tensor(0.4790)\n",
            "=========\n",
            "epoch 75 train loss: 0.5712 val_cls: 0.4781 val_acc: 0.8810\n",
            "tensor(0.4781) tensor(0.4787)\n",
            "=========\n",
            "epoch 76 train loss: 0.5774 val_cls: 0.4777 val_acc: 0.8810\n",
            "tensor(0.4777) tensor(0.4781)\n",
            "=========\n",
            "epoch 77 train loss: 0.5697 val_cls: 0.4773 val_acc: 0.8810\n",
            "tensor(0.4773) tensor(0.4777)\n",
            "=========\n",
            "epoch 78 train loss: 0.5716 val_cls: 0.4767 val_acc: 0.8810\n",
            "tensor(0.4767) tensor(0.4773)\n",
            "=========\n",
            "epoch 79 train loss: 0.5713 val_cls: 0.4763 val_acc: 0.8810\n",
            "tensor(0.4763) tensor(0.4767)\n",
            "=========\n",
            "epoch 80 train loss: 0.5720 val_cls: 0.4758 val_acc: 0.8810\n",
            "tensor(0.4758) tensor(0.4763)\n",
            "=========\n",
            "epoch 81 train loss: 0.5694 val_cls: 0.4756 val_acc: 0.8810\n",
            "tensor(0.4756) tensor(0.4758)\n",
            "=========\n",
            "epoch 82 train loss: 0.5731 val_cls: 0.4751 val_acc: 0.8810\n",
            "tensor(0.4751) tensor(0.4756)\n",
            "=========\n",
            "epoch 83 train loss: 0.5680 val_cls: 0.4747 val_acc: 0.8810\n",
            "tensor(0.4747) tensor(0.4751)\n",
            "=========\n",
            "epoch 84 train loss: 0.5677 val_cls: 0.4745 val_acc: 0.8810\n",
            "tensor(0.4745) tensor(0.4747)\n",
            "=========\n",
            "epoch 85 train loss: 0.5589 val_cls: 0.4736 val_acc: 0.8810\n",
            "tensor(0.4736) tensor(0.4745)\n",
            "=========\n",
            "epoch 86 train loss: 0.5641 val_cls: 0.4730 val_acc: 0.8810\n",
            "tensor(0.4730) tensor(0.4736)\n",
            "=========\n",
            "epoch 87 train loss: 0.5647 val_cls: 0.4725 val_acc: 0.8810\n",
            "tensor(0.4725) tensor(0.4730)\n",
            "=========\n",
            "epoch 88 train loss: 0.5706 val_cls: 0.4724 val_acc: 0.8810\n",
            "tensor(0.4724) tensor(0.4725)\n",
            "=========\n",
            "epoch 89 train loss: 0.5672 val_cls: 0.4721 val_acc: 0.8810\n",
            "tensor(0.4721) tensor(0.4724)\n",
            "=========\n",
            "epoch 90 train loss: 0.5638 val_cls: 0.4716 val_acc: 0.8810\n",
            "tensor(0.4716) tensor(0.4721)\n",
            "=========\n",
            "epoch 91 train loss: 0.5671 val_cls: 0.4712 val_acc: 0.8810\n",
            "tensor(0.4712) tensor(0.4716)\n",
            "=========\n",
            "epoch 92 train loss: 0.5604 val_cls: 0.4707 val_acc: 0.8810\n",
            "tensor(0.4707) tensor(0.4712)\n",
            "=========\n",
            "epoch 93 train loss: 0.5510 val_cls: 0.4700 val_acc: 0.8810\n",
            "tensor(0.4700) tensor(0.4707)\n",
            "=========\n",
            "epoch 94 train loss: 0.5655 val_cls: 0.4694 val_acc: 0.8810\n",
            "tensor(0.4694) tensor(0.4700)\n",
            "=========\n",
            "epoch 95 train loss: 0.5621 val_cls: 0.4691 val_acc: 0.8810\n",
            "tensor(0.4691) tensor(0.4694)\n",
            "=========\n",
            "epoch 96 train loss: 0.5578 val_cls: 0.4686 val_acc: 0.8810\n",
            "tensor(0.4686) tensor(0.4691)\n",
            "=========\n",
            "epoch 97 train loss: 0.5498 val_cls: 0.4679 val_acc: 0.8810\n",
            "tensor(0.4679) tensor(0.4686)\n",
            "=========\n",
            "epoch 98 train loss: 0.5597 val_cls: 0.4675 val_acc: 0.8810\n",
            "tensor(0.4675) tensor(0.4679)\n",
            "=========\n",
            "epoch 99 train loss: 0.5430 val_cls: 0.4666 val_acc: 0.8810\n",
            "tensor(0.4666) tensor(0.4675)\n",
            "=========\n",
            "epoch 100 train loss: 0.5485 val_cls: 0.4661 val_acc: 0.8810\n",
            "tensor(0.4661) tensor(0.4666)\n",
            "=========\n",
            "epoch 101 train loss: 0.5469 val_cls: 0.4656 val_acc: 0.8810\n",
            "tensor(0.4656) tensor(0.4661)\n",
            "=========\n",
            "epoch 102 train loss: 0.5508 val_cls: 0.4651 val_acc: 0.8810\n",
            "tensor(0.4651) tensor(0.4656)\n",
            "=========\n",
            "epoch 103 train loss: 0.5531 val_cls: 0.4647 val_acc: 0.8810\n",
            "tensor(0.4647) tensor(0.4651)\n",
            "=========\n",
            "epoch 104 train loss: 0.5436 val_cls: 0.4640 val_acc: 0.8810\n",
            "tensor(0.4640) tensor(0.4647)\n",
            "=========\n",
            "epoch 105 train loss: 0.5483 val_cls: 0.4636 val_acc: 0.8810\n",
            "tensor(0.4636) tensor(0.4640)\n",
            "=========\n",
            "epoch 106 train loss: 0.5346 val_cls: 0.4628 val_acc: 0.8810\n",
            "tensor(0.4628) tensor(0.4636)\n",
            "=========\n",
            "epoch 107 train loss: 0.5400 val_cls: 0.4624 val_acc: 0.8810\n",
            "tensor(0.4624) tensor(0.4628)\n",
            "=========\n",
            "epoch 108 train loss: 0.5367 val_cls: 0.4619 val_acc: 0.8810\n",
            "tensor(0.4619) tensor(0.4624)\n",
            "=========\n",
            "epoch 109 train loss: 0.5241 val_cls: 0.4611 val_acc: 0.8810\n",
            "tensor(0.4611) tensor(0.4619)\n",
            "=========\n",
            "epoch 110 train loss: 0.5346 val_cls: 0.4606 val_acc: 0.8810\n",
            "tensor(0.4606) tensor(0.4611)\n",
            "=========\n",
            "epoch 111 train loss: 0.5309 val_cls: 0.4601 val_acc: 0.8810\n",
            "tensor(0.4601) tensor(0.4606)\n",
            "=========\n",
            "epoch 112 train loss: 0.5335 val_cls: 0.4594 val_acc: 0.8810\n",
            "tensor(0.4594) tensor(0.4601)\n",
            "=========\n",
            "epoch 113 train loss: 0.5297 val_cls: 0.4590 val_acc: 0.8810\n",
            "tensor(0.4590) tensor(0.4594)\n",
            "=========\n",
            "epoch 114 train loss: 0.5259 val_cls: 0.4584 val_acc: 0.8810\n",
            "tensor(0.4584) tensor(0.4590)\n",
            "=========\n",
            "epoch 115 train loss: 0.5228 val_cls: 0.4578 val_acc: 0.8810\n",
            "tensor(0.4578) tensor(0.4584)\n",
            "=========\n",
            "epoch 116 train loss: 0.5253 val_cls: 0.4572 val_acc: 0.8810\n",
            "tensor(0.4572) tensor(0.4578)\n",
            "=========\n",
            "epoch 117 train loss: 0.5343 val_cls: 0.4570 val_acc: 0.8810\n",
            "tensor(0.4570) tensor(0.4572)\n",
            "=========\n",
            "epoch 118 train loss: 0.5205 val_cls: 0.4563 val_acc: 0.8810\n",
            "tensor(0.4563) tensor(0.4570)\n",
            "=========\n",
            "epoch 119 train loss: 0.5302 val_cls: 0.4560 val_acc: 0.8810\n",
            "tensor(0.4560) tensor(0.4563)\n",
            "=========\n",
            "epoch 120 train loss: 0.5151 val_cls: 0.4555 val_acc: 0.8810\n",
            "tensor(0.4555) tensor(0.4560)\n",
            "=========\n",
            "epoch 121 train loss: 0.5187 val_cls: 0.4551 val_acc: 0.8810\n",
            "tensor(0.4551) tensor(0.4555)\n",
            "=========\n",
            "epoch 122 train loss: 0.5153 val_cls: 0.4545 val_acc: 0.8810\n",
            "tensor(0.4545) tensor(0.4551)\n",
            "=========\n",
            "epoch 123 train loss: 0.5073 val_cls: 0.4539 val_acc: 0.8810\n",
            "tensor(0.4539) tensor(0.4545)\n",
            "=========\n",
            "epoch 124 train loss: 0.5065 val_cls: 0.4533 val_acc: 0.8810\n",
            "tensor(0.4533) tensor(0.4539)\n",
            "=========\n",
            "epoch 125 train loss: 0.5155 val_cls: 0.4529 val_acc: 0.8810\n",
            "tensor(0.4529) tensor(0.4533)\n",
            "=========\n",
            "epoch 126 train loss: 0.5180 val_cls: 0.4526 val_acc: 0.8810\n",
            "tensor(0.4526) tensor(0.4529)\n",
            "=========\n",
            "epoch 127 train loss: 0.5154 val_cls: 0.4522 val_acc: 0.8810\n",
            "tensor(0.4522) tensor(0.4526)\n",
            "=========\n",
            "epoch 128 train loss: 0.5151 val_cls: 0.4518 val_acc: 0.8810\n",
            "tensor(0.4518) tensor(0.4522)\n",
            "=========\n",
            "epoch 129 train loss: 0.5079 val_cls: 0.4515 val_acc: 0.8810\n",
            "tensor(0.4515) tensor(0.4518)\n",
            "=========\n",
            "epoch 130 train loss: 0.5047 val_cls: 0.4512 val_acc: 0.8810\n",
            "tensor(0.4512) tensor(0.4515)\n",
            "=========\n",
            "epoch 131 train loss: 0.5030 val_cls: 0.4506 val_acc: 0.8810\n",
            "tensor(0.4506) tensor(0.4512)\n",
            "=========\n",
            "epoch 132 train loss: 0.5013 val_cls: 0.4500 val_acc: 0.8810\n",
            "tensor(0.4500) tensor(0.4506)\n",
            "=========\n",
            "epoch 133 train loss: 0.4965 val_cls: 0.4496 val_acc: 0.8810\n",
            "tensor(0.4496) tensor(0.4500)\n",
            "=========\n",
            "epoch 134 train loss: 0.5015 val_cls: 0.4492 val_acc: 0.8810\n",
            "tensor(0.4492) tensor(0.4496)\n",
            "=========\n",
            "epoch 135 train loss: 0.4916 val_cls: 0.4489 val_acc: 0.8810\n",
            "tensor(0.4489) tensor(0.4492)\n",
            "=========\n",
            "epoch 136 train loss: 0.4969 val_cls: 0.4486 val_acc: 0.8810\n",
            "tensor(0.4486) tensor(0.4489)\n",
            "=========\n",
            "epoch 137 train loss: 0.4848 val_cls: 0.4481 val_acc: 0.8810\n",
            "tensor(0.4481) tensor(0.4486)\n",
            "=========\n",
            "epoch 138 train loss: 0.4893 val_cls: 0.4477 val_acc: 0.8810\n",
            "tensor(0.4477) tensor(0.4481)\n",
            "=========\n",
            "epoch 139 train loss: 0.4914 val_cls: 0.4473 val_acc: 0.8810\n",
            "tensor(0.4473) tensor(0.4477)\n",
            "=========\n",
            "epoch 140 train loss: 0.4885 val_cls: 0.4468 val_acc: 0.8810\n",
            "tensor(0.4468) tensor(0.4473)\n",
            "=========\n",
            "epoch 141 train loss: 0.4877 val_cls: 0.4467 val_acc: 0.8810\n",
            "tensor(0.4467) tensor(0.4468)\n",
            "=========\n",
            "epoch 142 train loss: 0.4776 val_cls: 0.4460 val_acc: 0.8810\n",
            "tensor(0.4460) tensor(0.4467)\n",
            "=========\n",
            "epoch 143 train loss: 0.4809 val_cls: 0.4457 val_acc: 0.8810\n",
            "tensor(0.4457) tensor(0.4460)\n",
            "=========\n",
            "epoch 144 train loss: 0.4825 val_cls: 0.4454 val_acc: 0.8810\n",
            "tensor(0.4454) tensor(0.4457)\n",
            "=========\n",
            "epoch 145 train loss: 0.4770 val_cls: 0.4451 val_acc: 0.8810\n",
            "tensor(0.4451) tensor(0.4454)\n",
            "=========\n",
            "epoch 146 train loss: 0.4720 val_cls: 0.4447 val_acc: 0.8810\n",
            "tensor(0.4447) tensor(0.4451)\n",
            "=========\n",
            "epoch 147 train loss: 0.4750 val_cls: 0.4445 val_acc: 0.8810\n",
            "tensor(0.4445) tensor(0.4447)\n",
            "=========\n",
            "epoch 148 train loss: 0.4689 val_cls: 0.4440 val_acc: 0.8810\n",
            "tensor(0.4440) tensor(0.4445)\n",
            "=========\n",
            "epoch 149 train loss: 0.4645 val_cls: 0.4437 val_acc: 0.8810\n",
            "tensor(0.4437) tensor(0.4440)\n",
            "=========\n",
            "epoch 150 train loss: 0.4660 val_cls: 0.4434 val_acc: 0.8810\n",
            "tensor(0.4434) tensor(0.4437)\n",
            "=========\n",
            "epoch 151 train loss: 0.4725 val_cls: 0.4431 val_acc: 0.8810\n",
            "tensor(0.4431) tensor(0.4434)\n",
            "=========\n",
            "epoch 152 train loss: 0.4651 val_cls: 0.4429 val_acc: 0.8810\n",
            "tensor(0.4429) tensor(0.4431)\n",
            "=========\n",
            "epoch 153 train loss: 0.4664 val_cls: 0.4426 val_acc: 0.8810\n",
            "tensor(0.4426) tensor(0.4429)\n",
            "=========\n",
            "epoch 154 train loss: 0.4616 val_cls: 0.4425 val_acc: 0.8810\n",
            "tensor(0.4425) tensor(0.4426)\n",
            "=========\n",
            "epoch 155 train loss: 0.4629 val_cls: 0.4423 val_acc: 0.8810\n",
            "tensor(0.4423) tensor(0.4425)\n",
            "=========\n",
            "epoch 156 train loss: 0.4582 val_cls: 0.4422 val_acc: 0.8810\n",
            "tensor(0.4422) tensor(0.4423)\n",
            "=========\n",
            "epoch 157 train loss: 0.4526 val_cls: 0.4419 val_acc: 0.8810\n",
            "tensor(0.4419) tensor(0.4422)\n",
            "=========\n",
            "epoch 158 train loss: 0.4517 val_cls: 0.4418 val_acc: 0.8810\n",
            "tensor(0.4418) tensor(0.4419)\n",
            "=========\n",
            "epoch 159 train loss: 0.4570 val_cls: 0.4417 val_acc: 0.8810\n",
            "tensor(0.4417) tensor(0.4418)\n",
            "=========\n",
            "epoch 160 train loss: 0.4525 val_cls: 0.4415 val_acc: 0.8810\n",
            "tensor(0.4415) tensor(0.4417)\n",
            "=========\n",
            "epoch 161 train loss: 0.4570 val_cls: 0.4413 val_acc: 0.8810\n",
            "tensor(0.4413) tensor(0.4415)\n",
            "=========\n",
            "epoch 162 train loss: 0.4480 val_cls: 0.4413 val_acc: 0.8810\n",
            "tensor(0.4413) tensor(0.4413)\n",
            "=========\n",
            "epoch 163 train loss: 0.4456 val_cls: 0.4412 val_acc: 0.8810\n",
            "tensor(0.4412) tensor(0.4413)\n",
            "=========\n",
            "epoch 164 train loss: 0.4416 val_cls: 0.4411 val_acc: 0.8810\n",
            "tensor(0.4411) tensor(0.4412)\n",
            "=========\n",
            "epoch 165 train loss: 0.4429 val_cls: 0.4410 val_acc: 0.8810\n",
            "tensor(0.4410) tensor(0.4411)\n",
            "=========\n",
            "epoch 166 train loss: 0.4349 val_cls: 0.4410 val_acc: 0.8810\n",
            "tensor(0.4410) tensor(0.4410)\n",
            "=========\n",
            "epoch 167 train loss: 0.4430 val_cls: 0.4408 val_acc: 0.8810\n",
            "tensor(0.4408) tensor(0.4410)\n",
            "=========\n",
            "epoch 168 train loss: 0.4382 val_cls: 0.4408 val_acc: 0.8810\n",
            "tensor(0.4408) tensor(0.4408)\n",
            "=========\n",
            "epoch 169 train loss: 0.4398 val_cls: 0.4406 val_acc: 0.8810\n",
            "tensor(0.4406) tensor(0.4408)\n",
            "=========\n",
            "epoch 170 train loss: 0.4318 val_cls: 0.4408 val_acc: 0.8810\n",
            "tensor(0.4408) tensor(0.4406)\n",
            "=========\n",
            "epoch 171 train loss: 0.4402 val_cls: 0.4408 val_acc: 0.8810\n",
            "tensor(0.4408) tensor(0.4406)\n",
            "=========\n",
            "epoch 172 train loss: 0.4326 val_cls: 0.4408 val_acc: 0.8810\n",
            "tensor(0.4408) tensor(0.4406)\n",
            "=========\n",
            "epoch 173 train loss: 0.4325 val_cls: 0.4406 val_acc: 0.8810\n",
            "tensor(0.4406) tensor(0.4406)\n",
            "=========\n",
            "epoch 174 train loss: 0.4321 val_cls: 0.4407 val_acc: 0.8810\n",
            "tensor(0.4407) tensor(0.4406)\n",
            "=========\n",
            "epoch 175 train loss: 0.4223 val_cls: 0.4408 val_acc: 0.8810\n",
            "tensor(0.4408) tensor(0.4406)\n",
            "=========\n",
            "epoch 176 train loss: 0.4357 val_cls: 0.4408 val_acc: 0.8810\n",
            "tensor(0.4408) tensor(0.4406)\n",
            "=========\n",
            "epoch 177 train loss: 0.4146 val_cls: 0.4409 val_acc: 0.8810\n",
            "tensor(0.4409) tensor(0.4406)\n",
            "=========\n",
            "epoch 178 train loss: 0.4236 val_cls: 0.4411 val_acc: 0.8810\n",
            "tensor(0.4411) tensor(0.4406)\n",
            "EARLY STOPPING \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "qO0xooOmL_3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history[\"train_loss\"], label='train');\n",
        "plt.plot(history[\"val_cls\"], label='val');\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "YIp9yuw_1KsA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "60b0552f-ef48-4ce0-b1fe-4c0be78ffe49"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fba2d42d6a0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history[\"val_acc\"]);\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('ACC');"
      ],
      "metadata": {
        "id": "LpiIB4WwKK2S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a3703c29-5544-4e43-ef04-c9653c829b8a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "predictions = utils.test(classification_model, test_iter)\n",
        "predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_true = y_test, y_pred = predictions))\n",
        "print(\"F1_Score:\", f1_score(y_pred=predictions, y_true=y_test, average='macro'))\n",
        "print(\" \")\n",
        "print(\"MSE:\", mse(y_true = y_test, y_pred = predictions))\n",
        "print(\"MAE:\", mae(y_true = y_test, y_pred = predictions))"
      ],
      "metadata": {
        "id": "d_iaeA9ce5GM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3ebc0b8-2cf1-4603-c989-07fd665a5144"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8585714285714285\n",
            "F1_Score: 0.18478093774019982\n",
            " \n",
            "MSE: 0.5714285714285714\n",
            "MAE: 0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# examine accuracy of predictions for test set\n",
        "pred = utils.test(classification_model, test_iter)\n",
        "# find the most likely rating for the specific review by finding the column with the highest score in each row of the matrix\n",
        "conv_pred = np.argmax(pred, axis=1)\n",
        "\n",
        "# print classification report\n",
        "print(classification_report(y_pred=conv_pred, y_true=y_test))"
      ],
      "metadata": {
        "id": "lIL_BJZgKXmm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ece58c07-7754-42ef-e803-3ab3f94fa41d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        13\n",
            "           1       0.00      0.00      0.00         8\n",
            "           2       0.00      0.00      0.00        14\n",
            "           3       0.00      0.00      0.00        64\n",
            "           4       0.86      1.00      0.92       601\n",
            "\n",
            "    accuracy                           0.86       700\n",
            "   macro avg       0.17      0.20      0.18       700\n",
            "weighted avg       0.74      0.86      0.79       700\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y_test, conv_pred);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "D6MiVGlR_Hct",
        "outputId": "13546091-dd59-4a13-a7e8-28a33faba161"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test if model is more accurate than a dummy model\n",
        "from sklearn.dummy import DummyClassifier\n",
        "dummy1 = DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy2 = DummyClassifier(strategy=\"stratified\")"
      ],
      "metadata": {
        "id": "yI9P8aDb6F2u"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# most_frequent - returns most frequent class label\n",
        "dummy1.fit(x_train, y_train)\n",
        "dummy1.score(x_train, y_train)"
      ],
      "metadata": {
        "id": "TPy0KjEq6IH1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f748716-35c3-4d10-c6f7-21ee84fe3b41"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8439490445859873"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stratified - returns random samples from a distribution based on prior probabilities\n",
        "dummy2.fit(x_train, y_train)\n",
        "dummy2.score(x_train, y_train)"
      ],
      "metadata": {
        "id": "jlU6d7MD6PPB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91e7d74f-f63d-4e2e-fdaa-b6905bcd427a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7070063694267515"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ]
}