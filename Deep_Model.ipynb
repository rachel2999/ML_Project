{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Drink Quality by Reviews"
      ],
      "metadata": {
        "id": "WTkQ8n1FsVJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examine the correlation between \"Rating\" and \"Review\" to determine if the quality of a drink can be predicted based on it's reviews."
      ],
      "metadata": {
        "id": "3QLwH_X0TL_-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1THLhLXDOmz",
        "outputId": "66557b5f-3881-41d6-837d-55ed123ad467"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting import-ipynb\n",
            "  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.8/dist-packages (from import-ipynb) (7.9.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from import-ipynb) (5.7.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (5.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (4.4.2)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (2.0.10)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->import-ipynb) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->import-ipynb) (2.16.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.8/dist-packages (from nbformat->import-ipynb) (5.1.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->IPython->import-ipynb) (0.8.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (5.10.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.19.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (22.2.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import-ipynb) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import-ipynb) (0.2.5)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core->nbformat->import-ipynb) (2.6.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->IPython->import-ipynb) (0.7.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->import-ipynb) (3.11.0)\n",
            "Installing collected packages: jedi, import-ipynb\n",
            "Successfully installed import-ipynb-0.1.4 jedi-0.18.2\n"
          ]
        }
      ],
      "source": [
        "!pip install import-ipynb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/MyDrive/ML-Project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XZesjC4DUcU",
        "outputId": "f68f2d3d-97d2-4692-b1e7-6b1e09276794"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/ML-Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import random\n",
        "import import_ipynb\n",
        "import utils\n",
        "\n",
        "\n",
        "# to get reproducible results:\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC_ZMjWvDYoj",
        "outputId": "1319aea3-2ecc-4874-d38d-d41e07db1866"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "importing Jupyter notebook from utils.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "metadata": {
        "id": "CoLyV47NLEas"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing the Dataset"
      ],
      "metadata": {
        "id": "kJTb2CCVK6Gw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read dataset file\n",
        "df = pd.read_csv('dataset.csv', sep=',')"
      ],
      "metadata": {
        "id": "KKBmGAx6Dn7_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace column names with shorter, more readable names\n",
        "df.columns = ['Num', 'Brand', 'Name', 'Date', 'Recommend', 'Helpful', 'Rating', 'Weight', 'Review Title', 'Review']\n",
        "df.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "mg_ZwGcTEClT",
        "outputId": "1fc96013-c2d4-4a8f-c85e-5790748accf2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Num        Brand                                       Name  \\\n",
              "1263  1264         Gmax     Gmax g144105 gm44 full face red wine m   \n",
              "227    228     Heineken     Heineken174 Lager - 6pk / 12oz Bottles   \n",
              "2142  2143       Carmex  Carmex Lip Balm Original Jar - 12 PK, 12.   \n",
              "450    451     Jim Beam      Jim Beam Black Bourbon Whiskey, 50 mL   \n",
              "1403  1404  Great Value  Great Value Original Crescent Rolls, 8 oz   \n",
              "\n",
              "                      Date Recommend  Helpful  Rating   Weight  \\\n",
              "1263  2017-01-09T22:25:24Z       NaN      NaN     4.0      NaN   \n",
              "227   2017-09-20T01:18:35Z      True      NaN     5.0  1.0 lbs   \n",
              "2142  2017-09-23T02:53:08Z      True      NaN     5.0      NaN   \n",
              "450   2017-09-20T01:18:35Z       NaN      NaN     5.0      NaN   \n",
              "1403  2017-09-02T07:55:36Z      True      0.0     5.0      NaN   \n",
              "\n",
              "                   Review Title  \\\n",
              "1263                        NaN   \n",
              "227                 Great beer!   \n",
              "2142         Small and compact!   \n",
              "450        My favorite bourbon!   \n",
              "1403  Just as good as Pillsbury   \n",
              "\n",
              "                                                 Review  \n",
              "1263                                       easy process  \n",
              "227   I bought this, best price and great convenienc...  \n",
              "2142  The lip balm is so smooth, doesn't have a weir...  \n",
              "450                          Exceptionally good flavor!  \n",
              "1403         Just as good as Pillsbury but better price  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20227fd1-b1a0-4eeb-915f-7289a38809b1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Num</th>\n",
              "      <th>Brand</th>\n",
              "      <th>Name</th>\n",
              "      <th>Date</th>\n",
              "      <th>Recommend</th>\n",
              "      <th>Helpful</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Review Title</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1263</th>\n",
              "      <td>1264</td>\n",
              "      <td>Gmax</td>\n",
              "      <td>Gmax g144105 gm44 full face red wine m</td>\n",
              "      <td>2017-01-09T22:25:24Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>easy process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>228</td>\n",
              "      <td>Heineken</td>\n",
              "      <td>Heineken174 Lager - 6pk / 12oz Bottles</td>\n",
              "      <td>2017-09-20T01:18:35Z</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>Great beer!</td>\n",
              "      <td>I bought this, best price and great convenienc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2142</th>\n",
              "      <td>2143</td>\n",
              "      <td>Carmex</td>\n",
              "      <td>Carmex Lip Balm Original Jar - 12 PK, 12.</td>\n",
              "      <td>2017-09-23T02:53:08Z</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Small and compact!</td>\n",
              "      <td>The lip balm is so smooth, doesn't have a weir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>451</td>\n",
              "      <td>Jim Beam</td>\n",
              "      <td>Jim Beam Black Bourbon Whiskey, 50 mL</td>\n",
              "      <td>2017-09-20T01:18:35Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>My favorite bourbon!</td>\n",
              "      <td>Exceptionally good flavor!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1403</th>\n",
              "      <td>1404</td>\n",
              "      <td>Great Value</td>\n",
              "      <td>Great Value Original Crescent Rolls, 8 oz</td>\n",
              "      <td>2017-09-02T07:55:36Z</td>\n",
              "      <td>True</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just as good as Pillsbury</td>\n",
              "      <td>Just as good as Pillsbury but better price</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20227fd1-b1a0-4eeb-915f-7289a38809b1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-20227fd1-b1a0-4eeb-915f-7289a38809b1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-20227fd1-b1a0-4eeb-915f-7289a38809b1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove useless columns\n",
        "df.drop(\"Num\", axis=1, inplace=True)\n",
        "df.drop(\"Date\", axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "2AiS9linDA-b"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reindex rows\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "5H4vyxXCbgt2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "outputId": "58256621-2115-4744-ac46-fb307d098c62"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Brand                                               Name  \\\n",
              "0             Gallo         Ecco Domani174 Pinot Grigio - 750ml Bottle   \n",
              "1   Fresh Craft Co.   Fresh Craft174 Mango Citrus - 4pk / 250ml Bottle   \n",
              "2      1000 Stories           1000 Stories174 Zinfandel - 750ml Bottle   \n",
              "3      1000 Stories           1000 Stories174 Zinfandel - 750ml Bottle   \n",
              "4      Wine Cube153            Pink Moscato - 3l Bottle - Wine Cube153   \n",
              "5         Beck's Na  Beck's174 Non Alcoholic Beer - 6pk / 12oz Bottles   \n",
              "6             Gallo                Apothic174 Red Blend - 750ml Bottle   \n",
              "7             Gallo                Apothic174 Red Blend - 750ml Bottle   \n",
              "8  California Roots        California Roots Moscato White Wine - 750ml   \n",
              "9   Charles Charles        Charles Charles174 Red Blend - 750ml Bottle   \n",
              "\n",
              "  Recommend  Helpful  Rating    Weight                          Review Title  \\\n",
              "0      True      1.0     5.0   1.0 lbs                My Favorite White Wine   \n",
              "1      True      NaN     5.0  2.45 lbs                                 Yum!!   \n",
              "2      True      NaN     5.0  3.09 lbs                       A New Favorite!   \n",
              "3      True      NaN     5.0  3.09 lbs  Bold, Flavorful, Aromatic, Delicious   \n",
              "4      True      1.0     5.0   1.0 lbs  Yum! Plus, Environmentally Friendly!   \n",
              "5      True      NaN     5.0   1.0 lbs                           Great Taste   \n",
              "6       NaN      1.0     3.0   1.0 lbs                      Simply Wonderful   \n",
              "7       NaN      1.0     2.0   1.0 lbs                          A Sweet Red.   \n",
              "8      True      0.0     5.0  2.65 lbs                                   NaN   \n",
              "9      True      NaN     5.0   1.0 lbs           Charles & Charles Red Blend   \n",
              "\n",
              "                                              Review  \n",
              "0      This a fantastic white wine for any occasion!  \n",
              "1   Tart, not sweet...very refreshing and delicious!  \n",
              "2  I was given this wine so it was a delightful s...  \n",
              "3  This is a phenomenal wine and my new favorite ...  \n",
              "4  4 750ml bottles for the price of two With way ...  \n",
              "5  I LOVE Becks NA. It tastes just like a regular...  \n",
              "6  This wine has a wonderful but strong aroma its...  \n",
              "7  I would give one more star if it came clean on...  \n",
              "8                      Delicious and very affordable  \n",
              "9  This is a very smooth red with Aromas of cocoa...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0a25c415-8327-4577-a04e-4bb40d292f2e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Brand</th>\n",
              "      <th>Name</th>\n",
              "      <th>Recommend</th>\n",
              "      <th>Helpful</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Review Title</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Gallo</td>\n",
              "      <td>Ecco Domani174 Pinot Grigio - 750ml Bottle</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>My Favorite White Wine</td>\n",
              "      <td>This a fantastic white wine for any occasion!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fresh Craft Co.</td>\n",
              "      <td>Fresh Craft174 Mango Citrus - 4pk / 250ml Bottle</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.45 lbs</td>\n",
              "      <td>Yum!!</td>\n",
              "      <td>Tart, not sweet...very refreshing and delicious!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000 Stories</td>\n",
              "      <td>1000 Stories174 Zinfandel - 750ml Bottle</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.09 lbs</td>\n",
              "      <td>A New Favorite!</td>\n",
              "      <td>I was given this wine so it was a delightful s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000 Stories</td>\n",
              "      <td>1000 Stories174 Zinfandel - 750ml Bottle</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.09 lbs</td>\n",
              "      <td>Bold, Flavorful, Aromatic, Delicious</td>\n",
              "      <td>This is a phenomenal wine and my new favorite ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Wine Cube153</td>\n",
              "      <td>Pink Moscato - 3l Bottle - Wine Cube153</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>Yum! Plus, Environmentally Friendly!</td>\n",
              "      <td>4 750ml bottles for the price of two With way ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Beck's Na</td>\n",
              "      <td>Beck's174 Non Alcoholic Beer - 6pk / 12oz Bottles</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>Great Taste</td>\n",
              "      <td>I LOVE Becks NA. It tastes just like a regular...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Gallo</td>\n",
              "      <td>Apothic174 Red Blend - 750ml Bottle</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>Simply Wonderful</td>\n",
              "      <td>This wine has a wonderful but strong aroma its...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Gallo</td>\n",
              "      <td>Apothic174 Red Blend - 750ml Bottle</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>A Sweet Red.</td>\n",
              "      <td>I would give one more star if it came clean on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>California Roots</td>\n",
              "      <td>California Roots Moscato White Wine - 750ml</td>\n",
              "      <td>True</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.65 lbs</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Delicious and very affordable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Charles Charles</td>\n",
              "      <td>Charles Charles174 Red Blend - 750ml Bottle</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>Charles &amp; Charles Red Blend</td>\n",
              "      <td>This is a very smooth red with Aromas of cocoa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a25c415-8327-4577-a04e-4bb40d292f2e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0a25c415-8327-4577-a04e-4bb40d292f2e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0a25c415-8327-4577-a04e-4bb40d292f2e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check for total amount of null values in each column\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "Q7ZAX3-RGAOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bab664b6-0e42-468f-a6e6-1ff959e943fd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brand             65\n",
            "Name               0\n",
            "Recommend        979\n",
            "Helpful         2264\n",
            "Rating           445\n",
            "Weight          1894\n",
            "Review Title      44\n",
            "Review             1\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove all rows that have no ratings or recommendations\n",
        "df = df.dropna(subset=['Rating'])\n",
        "df = df.dropna(subset=['Recommend'])\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "E9Pkbdj-IVA_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50f5c42d-e08a-483f-e500-667954bbc05e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Brand              0\n",
              "Name               0\n",
              "Recommend          0\n",
              "Helpful         1170\n",
              "Rating             0\n",
              "Weight          1392\n",
              "Review Title      10\n",
              "Review             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the all possible ratings from 1 to 5 are used\n",
        "np.unique(df['Rating'])"
      ],
      "metadata": {
        "id": "yJIJNlkkKqkV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e7d6f66-c0fd-4a6c-d784-cee67091ca0d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 2., 3., 4., 5.])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "FOC26UJ1BgCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c854c2a5-0dda-4089-8e0b-a10bf020de1d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1748 entries, 0 to 2815\n",
            "Data columns (total 8 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Brand         1748 non-null   object \n",
            " 1   Name          1748 non-null   object \n",
            " 2   Recommend     1748 non-null   object \n",
            " 3   Helpful       578 non-null    float64\n",
            " 4   Rating        1748 non-null   float64\n",
            " 5   Weight        356 non-null    object \n",
            " 6   Review Title  1738 non-null   object \n",
            " 7   Review        1748 non-null   object \n",
            "dtypes: float64(2), object(6)\n",
            "memory usage: 122.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change data type of \"Rating\" from float to integer\n",
        "df['Rating'] = df['Rating'].astype(int)\n",
        "\n",
        "# change data type of \"Recommend\" from object to integer\n",
        "# \"True\" = 1, \"False\" = 0\n",
        "df[\"Recommend\"] = df[\"Recommend\"].astype(int)\n",
        "\n",
        "# check data types again\n",
        "df.info()"
      ],
      "metadata": {
        "id": "55B7BhBBL4VK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94ea1177-674d-4225-e48c-f7d03e0f3a33"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1748 entries, 0 to 2815\n",
            "Data columns (total 8 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Brand         1748 non-null   object \n",
            " 1   Name          1748 non-null   object \n",
            " 2   Recommend     1748 non-null   int64  \n",
            " 3   Helpful       578 non-null    float64\n",
            " 4   Rating        1748 non-null   int64  \n",
            " 5   Weight        356 non-null    object \n",
            " 6   Review Title  1738 non-null   object \n",
            " 7   Review        1748 non-null   object \n",
            "dtypes: float64(1), int64(2), object(5)\n",
            "memory usage: 122.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect correlation between numeric features\n",
        "df.corr()"
      ],
      "metadata": {
        "id": "72OEXXdrb6EF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "89a19970-f0c0-463b-807e-1b219a837925"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Recommend   Helpful    Rating\n",
              "Recommend   1.000000  0.042670  0.767292\n",
              "Helpful     0.042670  1.000000  0.024891\n",
              "Rating      0.767292  0.024891  1.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-03924f24-d376-43a2-8143-34c6296e251e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Recommend</th>\n",
              "      <th>Helpful</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Recommend</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.042670</td>\n",
              "      <td>0.767292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Helpful</th>\n",
              "      <td>0.042670</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.024891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Rating</th>\n",
              "      <td>0.767292</td>\n",
              "      <td>0.024891</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03924f24-d376-43a2-8143-34c6296e251e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-03924f24-d376-43a2-8143-34c6296e251e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-03924f24-d376-43a2-8143-34c6296e251e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- There is a weak positive correlation between recommend and helpful. Reviews that were voted helpful tend to be about alcohol that reviewers recommend to others.\n",
        "- There is a strong positive correlation between recommend and rating. The higher the rating/quality of the alcohol, then then the more likely that the reviewer would recommend it.\n",
        "- There is a very weak positive correlation between helpful and rating. Alcohol that was voted helpful tend to have slightly higher ratings than reviews not considered helpful."
      ],
      "metadata": {
        "id": "hJSUEBotcmi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check for duplicated reviews\n",
        "df['Review'].duplicated().sum()"
      ],
      "metadata": {
        "id": "Y4Ggih8XF42P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8498278-bb26-4636-ab14-1c28f697c7d2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove duplicated reviews\n",
        "df['Review'].drop_duplicates()"
      ],
      "metadata": {
        "id": "U1QKOX4uF-UU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c35ecbbc-28a4-402f-9620-cc947bd97154"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0           This a fantastic white wine for any occasion!\n",
              "1        Tart, not sweet...very refreshing and delicious!\n",
              "2       I was given this wine so it was a delightful s...\n",
              "3       This is a phenomenal wine and my new favorite ...\n",
              "4       4 750ml bottles for the price of two With way ...\n",
              "                              ...                        \n",
              "2811    My kids love them. So no complaints but I'm su...\n",
              "2812    Easy and quick to serve, brings a smile to the...\n",
              "2813                         Worked great kids loved them\n",
              "2814    Walmart used to carry a Swiss water decaf coff...\n",
              "2815    Great decaf coffee using Swiss water process. ...\n",
              "Name: Review, Length: 1735, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clean text in reviews with natural language toolkit\n",
        "!pip install nltk\n",
        "import nltk\n",
        "\n",
        "# define stopwords to remove\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stopwords = set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "id": "PupCwDbIoOpi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3ca7e58-5ed7-4961-d64b-9e6a4a34c196"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize text with regex before cleaning\n",
        "from nltk import word_tokenize\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "token = TreebankWordDetokenizer()\n",
        "\n",
        "def clean(w):\n",
        "    w = word_tokenize(w.lower()) # turn all token words lowercase\n",
        "    w = [token for token in w if token not in stopwords and token.isalpha()] # remove stopwords and non-words (punctuation, numbers, etc.)\n",
        "    return token.detokenize(w)\n",
        "\n",
        "df[\"Clean_Reviews\"] = df[\"Review\"].apply(clean)"
      ],
      "metadata": {
        "id": "NzYNfnTejmJV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check to make sure the reviews were cleaned correctly\n",
        "df[\"Clean_Reviews\"].sample(10)"
      ],
      "metadata": {
        "id": "-Yj3GOHztCI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69f43ce6-d732-46df-f995-fe9c0e8ee2cd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1596    prefer purchase store individually whatever ne...\n",
              "477                             best bloody mary mix ever\n",
              "2364    started using carmex cna brand count heal supp...\n",
              "2061    using carmex yrs still always keep jar purse t...\n",
              "2226    started applying four times day honestly great...\n",
              "2373    buy carmex tub becuase mother always wood open...\n",
              "829                                              favorite\n",
              "1980    use many year really work dry lips light burn ...\n",
              "1994    always go back carmex original lip balm jar li...\n",
              "2585    using carmex original lip balm jar since child...\n",
              "Name: Clean_Reviews, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network Algorithm - Deep Model"
      ],
      "metadata": {
        "id": "eyTXVRRGf-t8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "UST9kQW_f-t9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset 40% test, 60% train\n",
        "y = df[\"Rating\"].values\n",
        "words = df[\"Clean_Reviews\"].values\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(words, y, test_size=0.4, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "77iLLy7jf-t9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# examine a random dictionary entry\n",
        "print(\"Review:\", x_train[2])\n",
        "print(\"Rating:\", y_train[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b89e3d8-9b93-4392-ee31-330f8d7df197",
        "id": "LICtu_WMf-t9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: price incredible delivery service better could hoped\n",
            "Rating: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize the reviews to vectorize each word as an integer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# limit vocabularly index to the most common 10,000 words\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "# create vocab index based on word frequency\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "# apply limited vocab to train and test\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_test = tokenizer.texts_to_sequences(x_test)"
      ],
      "metadata": {
        "id": "qT9XBoq9f-t9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# examine a random dictionary entry\n",
        "print(\"Encoded Review:\", x_train[2])\n",
        "print(\"Rating:\", y_train[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce0ad5b5-69fc-405d-9ade-1548bee2a650",
        "id": "jPQjl2bFf-t9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Review: [50, 717, 427, 953, 58, 90, 954]\n",
            "Rating: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# re-vectorize reviews into sparse 2D nummpy array, with many zeros in the data\n",
        "# convert the reviews into a matrix, one review per row and one column per word\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "\n",
        "num_words=10000\n",
        "x_train = vectorize_sequences(x_train, dimension=num_words)\n",
        "x_test = vectorize_sequences(x_test, dimension=num_words)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6753255d-5e92-4eae-8f15-b22b23010552",
        "id": "fv22yQfNf-t9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1048, 10000)\n",
            "(700, 10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train[:15])\n",
        "print(y_test[:15])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "482bfc2e-a8f7-404f-fe57-96a424b958c1",
        "id": "IODJZEVXf-t9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 5 5 5 5 5 1 5 5 5 5 5 5 5 5]\n",
            "[4 5 4 5 4 5 4 4 5 5 5 5 5 5 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "cnt = Counter(list(y_train))\n",
        "num_classes = 5\n",
        "cnt.most_common(num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee821cae-4a33-46e8-9d08-21025bf2280b",
        "id": "dTivtGxJf-t9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(5, 900), (4, 90), (3, 24), (1, 23), (2, 11)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_labels = sorted(set([i[0] for i in cnt.most_common(num_classes)]))\n",
        "selected_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8db130da-79b0-402f-d4b8-38b279e95182",
        "id": "M45nAzhkf-t-"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_mask = [True if l in selected_labels else False for l in y_train]\n",
        "x_train = x_train[train_mask, :]\n",
        "y_train = y_train[train_mask]\n",
        "y_train = np.array([selected_labels.index(i) for i in y_train]) # reindex\n",
        "\n",
        "test_mask = [True if l in selected_labels else False for l in y_test]\n",
        "x_test= x_test[test_mask, :]\n",
        "y_test = y_test[test_mask]\n",
        "y_test = np.array([selected_labels.index(i) for i in y_test]) # reindex\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2849efe-5877-41be-9ddc-1dd29beb23b8",
        "id": "r5u5Z66Pf-t-"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1048, 10000)\n",
            "(700, 10000)\n",
            "(1048,)\n",
            "(700,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split training data into 40% train and 60% dev\n",
        "x_train, x_dev, y_train, y_dev = train_test_split(x_train, y_train, test_size=0.4, random_state=42)\n",
        "print(y_train.shape)\n",
        "print(x_train.shape)\n",
        "print(x_dev.shape)\n",
        "print(y_dev.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9b0282b-8fcf-4def-f8e1-dd49550babfd",
        "id": "7x-audOvf-t-"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(628,)\n",
            "(628, 10000)\n",
            "(420, 10000)\n",
            "(420,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert numpy array into PyTorch format\n",
        "\n",
        "# 1) define function\n",
        "def np2iter(x, y, shuffle=True):\n",
        "  x = torch.tensor(x, dtype=torch.float)\n",
        "  y = torch.tensor(y, dtype=torch.long)\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  print(\"----------------------\")\n",
        "\n",
        "  ds = torch.utils.data.TensorDataset(x, y)\n",
        "  return torch.utils.data.DataLoader(ds, batch_size=32, shuffle=shuffle)\n",
        "\n",
        "# 2) convert data\n",
        "train_iter = np2iter(x_train, y_train, shuffle=True) # DO shuffle train\n",
        "dev_iter =  np2iter(x_dev, y_dev, shuffle=False) # do NOT shuffle dev or test\n",
        "test_iter =  np2iter(x_test, y_test, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c08485c-86fe-4244-8091-2bb2f1cddbd4",
        "id": "qZTbVwmtf-t-"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([628, 10000])\n",
            "torch.Size([628])\n",
            "----------------------\n",
            "torch.Size([420, 10000])\n",
            "torch.Size([420])\n",
            "----------------------\n",
            "torch.Size([700, 10000])\n",
            "torch.Size([700])\n",
            "----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining accuracy\n",
        "def val_acc(y_pred, y_test): # define accuracy\n",
        "  y_pred = np.argmax(y_pred, axis=1)\n",
        "  return accuracy_score(y_pred=y_pred, y_true=y_test)"
      ],
      "metadata": {
        "id": "Uy56nWszf-t-"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "RySLkWAMLnbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define deep model\n",
        "num_words = 10000\n",
        "\n",
        "class DeepModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DeepModel, self).__init__()\n",
        "    # nn.sequential executes the following layers one by one, from linear layer to rectified layer unit\n",
        "    self.layer = nn.Sequential(nn.Linear(in_features=num_words, out_features=30), \n",
        "                                nn.Dropout(p=0.33),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Linear(in_features=30, out_features=30),\n",
        "                                nn.Dropout(p=0.33),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Linear(in_features=30, out_features=5))\n",
        "\n",
        "    \n",
        "  # feed the model the input and apply the linear layer to get the output\n",
        "  def forward(self, x):\n",
        "    return self.layer(x)"
      ],
      "metadata": {
        "id": "YKDbXb4-g3tH"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_model = DeepModel()\n",
        "classification_model = classification_model.cuda()"
      ],
      "metadata": {
        "id": "5U5BYKJAhFYC"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = utils.train(model=classification_model,\n",
        "                            loss=nn.CrossEntropyLoss(),\n",
        "                            val_metrics={\"cls\": nn.CrossEntropyLoss(), \"acc\": val_acc}, \n",
        "                            optimizer=torch.optim.SGD(classification_model.parameters(), lr=0.01),\n",
        "                            train_ds=train_iter, \n",
        "                            dev_ds=dev_iter,\n",
        "                            num_epochs=150,\n",
        "                            early_stopper=utils.EarlyStopper(metric_name=\"cls\", patience=3))"
      ],
      "metadata": {
        "id": "2l319rxEL8aY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a69151c3-b9bc-4f78-fc3e-446cf9efdb4c"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========\n",
            "epoch 1 train loss: 1.5396 val_cls: 1.4512 val_acc: 0.8810\n",
            "tensor(1.4512) None\n",
            "=========\n",
            "epoch 2 train loss: 1.4001 val_cls: 1.3079 val_acc: 0.8810\n",
            "tensor(1.3079) tensor(1.4512)\n",
            "=========\n",
            "epoch 3 train loss: 1.2707 val_cls: 1.1733 val_acc: 0.8810\n",
            "tensor(1.1733) tensor(1.3079)\n",
            "=========\n",
            "epoch 4 train loss: 1.1563 val_cls: 1.0510 val_acc: 0.8810\n",
            "tensor(1.0510) tensor(1.1733)\n",
            "=========\n",
            "epoch 5 train loss: 1.0389 val_cls: 0.9408 val_acc: 0.8810\n",
            "tensor(0.9408) tensor(1.0510)\n",
            "=========\n",
            "epoch 6 train loss: 0.9451 val_cls: 0.8458 val_acc: 0.8810\n",
            "tensor(0.8458) tensor(0.9408)\n",
            "=========\n",
            "epoch 7 train loss: 0.8735 val_cls: 0.7686 val_acc: 0.8810\n",
            "tensor(0.7686) tensor(0.8458)\n",
            "=========\n",
            "epoch 8 train loss: 0.8127 val_cls: 0.7066 val_acc: 0.8810\n",
            "tensor(0.7066) tensor(0.7686)\n",
            "=========\n",
            "epoch 9 train loss: 0.7692 val_cls: 0.6595 val_acc: 0.8810\n",
            "tensor(0.6595) tensor(0.7066)\n",
            "=========\n",
            "epoch 10 train loss: 0.7315 val_cls: 0.6234 val_acc: 0.8810\n",
            "tensor(0.6234) tensor(0.6595)\n",
            "=========\n",
            "epoch 11 train loss: 0.6972 val_cls: 0.5953 val_acc: 0.8810\n",
            "tensor(0.5953) tensor(0.6234)\n",
            "=========\n",
            "epoch 12 train loss: 0.6874 val_cls: 0.5756 val_acc: 0.8810\n",
            "tensor(0.5756) tensor(0.5953)\n",
            "=========\n",
            "epoch 13 train loss: 0.6750 val_cls: 0.5599 val_acc: 0.8810\n",
            "tensor(0.5599) tensor(0.5756)\n",
            "=========\n",
            "epoch 14 train loss: 0.6500 val_cls: 0.5468 val_acc: 0.8810\n",
            "tensor(0.5468) tensor(0.5599)\n",
            "=========\n",
            "epoch 15 train loss: 0.6439 val_cls: 0.5374 val_acc: 0.8810\n",
            "tensor(0.5374) tensor(0.5468)\n",
            "=========\n",
            "epoch 16 train loss: 0.6395 val_cls: 0.5298 val_acc: 0.8810\n",
            "tensor(0.5298) tensor(0.5374)\n",
            "=========\n",
            "epoch 17 train loss: 0.6286 val_cls: 0.5236 val_acc: 0.8810\n",
            "tensor(0.5236) tensor(0.5298)\n",
            "=========\n",
            "epoch 18 train loss: 0.6393 val_cls: 0.5193 val_acc: 0.8810\n",
            "tensor(0.5193) tensor(0.5236)\n",
            "=========\n",
            "epoch 19 train loss: 0.6301 val_cls: 0.5154 val_acc: 0.8810\n",
            "tensor(0.5154) tensor(0.5193)\n",
            "=========\n",
            "epoch 20 train loss: 0.6275 val_cls: 0.5118 val_acc: 0.8810\n",
            "tensor(0.5118) tensor(0.5154)\n",
            "=========\n",
            "epoch 21 train loss: 0.6138 val_cls: 0.5083 val_acc: 0.8810\n",
            "tensor(0.5083) tensor(0.5118)\n",
            "=========\n",
            "epoch 22 train loss: 0.6135 val_cls: 0.5056 val_acc: 0.8810\n",
            "tensor(0.5056) tensor(0.5083)\n",
            "=========\n",
            "epoch 23 train loss: 0.6168 val_cls: 0.5035 val_acc: 0.8810\n",
            "tensor(0.5035) tensor(0.5056)\n",
            "=========\n",
            "epoch 24 train loss: 0.6230 val_cls: 0.5015 val_acc: 0.8810\n",
            "tensor(0.5015) tensor(0.5035)\n",
            "=========\n",
            "epoch 25 train loss: 0.6075 val_cls: 0.4998 val_acc: 0.8810\n",
            "tensor(0.4998) tensor(0.5015)\n",
            "=========\n",
            "epoch 26 train loss: 0.6116 val_cls: 0.4981 val_acc: 0.8810\n",
            "tensor(0.4981) tensor(0.4998)\n",
            "=========\n",
            "epoch 27 train loss: 0.6126 val_cls: 0.4968 val_acc: 0.8810\n",
            "tensor(0.4968) tensor(0.4981)\n",
            "=========\n",
            "epoch 28 train loss: 0.6177 val_cls: 0.4957 val_acc: 0.8810\n",
            "tensor(0.4957) tensor(0.4968)\n",
            "=========\n",
            "epoch 29 train loss: 0.5955 val_cls: 0.4942 val_acc: 0.8810\n",
            "tensor(0.4942) tensor(0.4957)\n",
            "=========\n",
            "epoch 30 train loss: 0.6119 val_cls: 0.4936 val_acc: 0.8810\n",
            "tensor(0.4936) tensor(0.4942)\n",
            "=========\n",
            "epoch 31 train loss: 0.5971 val_cls: 0.4924 val_acc: 0.8810\n",
            "tensor(0.4924) tensor(0.4936)\n",
            "=========\n",
            "epoch 32 train loss: 0.6038 val_cls: 0.4915 val_acc: 0.8810\n",
            "tensor(0.4915) tensor(0.4924)\n",
            "=========\n",
            "epoch 33 train loss: 0.6010 val_cls: 0.4908 val_acc: 0.8810\n",
            "tensor(0.4908) tensor(0.4915)\n",
            "=========\n",
            "epoch 34 train loss: 0.6069 val_cls: 0.4898 val_acc: 0.8810\n",
            "tensor(0.4898) tensor(0.4908)\n",
            "=========\n",
            "epoch 35 train loss: 0.6004 val_cls: 0.4888 val_acc: 0.8810\n",
            "tensor(0.4888) tensor(0.4898)\n",
            "=========\n",
            "epoch 36 train loss: 0.6003 val_cls: 0.4880 val_acc: 0.8810\n",
            "tensor(0.4880) tensor(0.4888)\n",
            "=========\n",
            "epoch 37 train loss: 0.6030 val_cls: 0.4872 val_acc: 0.8810\n",
            "tensor(0.4872) tensor(0.4880)\n",
            "=========\n",
            "epoch 38 train loss: 0.5876 val_cls: 0.4860 val_acc: 0.8810\n",
            "tensor(0.4860) tensor(0.4872)\n",
            "=========\n",
            "epoch 39 train loss: 0.6006 val_cls: 0.4851 val_acc: 0.8810\n",
            "tensor(0.4851) tensor(0.4860)\n",
            "=========\n",
            "epoch 40 train loss: 0.5933 val_cls: 0.4843 val_acc: 0.8810\n",
            "tensor(0.4843) tensor(0.4851)\n",
            "=========\n",
            "epoch 41 train loss: 0.5918 val_cls: 0.4835 val_acc: 0.8810\n",
            "tensor(0.4835) tensor(0.4843)\n",
            "=========\n",
            "epoch 42 train loss: 0.5915 val_cls: 0.4830 val_acc: 0.8810\n",
            "tensor(0.4830) tensor(0.4835)\n",
            "=========\n",
            "epoch 43 train loss: 0.6019 val_cls: 0.4827 val_acc: 0.8810\n",
            "tensor(0.4827) tensor(0.4830)\n",
            "=========\n",
            "epoch 44 train loss: 0.5738 val_cls: 0.4816 val_acc: 0.8810\n",
            "tensor(0.4816) tensor(0.4827)\n",
            "=========\n",
            "epoch 45 train loss: 0.5899 val_cls: 0.4810 val_acc: 0.8810\n",
            "tensor(0.4810) tensor(0.4816)\n",
            "=========\n",
            "epoch 46 train loss: 0.5784 val_cls: 0.4799 val_acc: 0.8810\n",
            "tensor(0.4799) tensor(0.4810)\n",
            "=========\n",
            "epoch 47 train loss: 0.5812 val_cls: 0.4794 val_acc: 0.8810\n",
            "tensor(0.4794) tensor(0.4799)\n",
            "=========\n",
            "epoch 48 train loss: 0.5801 val_cls: 0.4786 val_acc: 0.8810\n",
            "tensor(0.4786) tensor(0.4794)\n",
            "=========\n",
            "epoch 49 train loss: 0.5801 val_cls: 0.4779 val_acc: 0.8810\n",
            "tensor(0.4779) tensor(0.4786)\n",
            "=========\n",
            "epoch 50 train loss: 0.5802 val_cls: 0.4772 val_acc: 0.8810\n",
            "tensor(0.4772) tensor(0.4779)\n",
            "=========\n",
            "epoch 51 train loss: 0.5811 val_cls: 0.4763 val_acc: 0.8810\n",
            "tensor(0.4763) tensor(0.4772)\n",
            "=========\n",
            "epoch 52 train loss: 0.5804 val_cls: 0.4756 val_acc: 0.8810\n",
            "tensor(0.4756) tensor(0.4763)\n",
            "=========\n",
            "epoch 53 train loss: 0.5843 val_cls: 0.4752 val_acc: 0.8810\n",
            "tensor(0.4752) tensor(0.4756)\n",
            "=========\n",
            "epoch 54 train loss: 0.5722 val_cls: 0.4743 val_acc: 0.8810\n",
            "tensor(0.4743) tensor(0.4752)\n",
            "=========\n",
            "epoch 55 train loss: 0.5687 val_cls: 0.4734 val_acc: 0.8810\n",
            "tensor(0.4734) tensor(0.4743)\n",
            "=========\n",
            "epoch 56 train loss: 0.5688 val_cls: 0.4728 val_acc: 0.8810\n",
            "tensor(0.4728) tensor(0.4734)\n",
            "=========\n",
            "epoch 57 train loss: 0.5687 val_cls: 0.4724 val_acc: 0.8810\n",
            "tensor(0.4724) tensor(0.4728)\n",
            "=========\n",
            "epoch 58 train loss: 0.5679 val_cls: 0.4718 val_acc: 0.8810\n",
            "tensor(0.4718) tensor(0.4724)\n",
            "=========\n",
            "epoch 59 train loss: 0.5791 val_cls: 0.4716 val_acc: 0.8810\n",
            "tensor(0.4716) tensor(0.4718)\n",
            "=========\n",
            "epoch 60 train loss: 0.5840 val_cls: 0.4711 val_acc: 0.8810\n",
            "tensor(0.4711) tensor(0.4716)\n",
            "=========\n",
            "epoch 61 train loss: 0.5604 val_cls: 0.4704 val_acc: 0.8810\n",
            "tensor(0.4704) tensor(0.4711)\n",
            "=========\n",
            "epoch 62 train loss: 0.5599 val_cls: 0.4698 val_acc: 0.8810\n",
            "tensor(0.4698) tensor(0.4704)\n",
            "=========\n",
            "epoch 63 train loss: 0.5761 val_cls: 0.4692 val_acc: 0.8810\n",
            "tensor(0.4692) tensor(0.4698)\n",
            "=========\n",
            "epoch 64 train loss: 0.5665 val_cls: 0.4686 val_acc: 0.8810\n",
            "tensor(0.4686) tensor(0.4692)\n",
            "=========\n",
            "epoch 65 train loss: 0.5752 val_cls: 0.4686 val_acc: 0.8810\n",
            "tensor(0.4686) tensor(0.4686)\n",
            "=========\n",
            "epoch 66 train loss: 0.5647 val_cls: 0.4685 val_acc: 0.8810\n",
            "tensor(0.4685) tensor(0.4686)\n",
            "=========\n",
            "epoch 67 train loss: 0.5520 val_cls: 0.4677 val_acc: 0.8810\n",
            "tensor(0.4677) tensor(0.4685)\n",
            "=========\n",
            "epoch 68 train loss: 0.5561 val_cls: 0.4671 val_acc: 0.8810\n",
            "tensor(0.4671) tensor(0.4677)\n",
            "=========\n",
            "epoch 69 train loss: 0.5597 val_cls: 0.4666 val_acc: 0.8810\n",
            "tensor(0.4666) tensor(0.4671)\n",
            "=========\n",
            "epoch 70 train loss: 0.5572 val_cls: 0.4658 val_acc: 0.8810\n",
            "tensor(0.4658) tensor(0.4666)\n",
            "=========\n",
            "epoch 71 train loss: 0.5551 val_cls: 0.4654 val_acc: 0.8810\n",
            "tensor(0.4654) tensor(0.4658)\n",
            "=========\n",
            "epoch 72 train loss: 0.5595 val_cls: 0.4651 val_acc: 0.8810\n",
            "tensor(0.4651) tensor(0.4654)\n",
            "=========\n",
            "epoch 73 train loss: 0.5491 val_cls: 0.4644 val_acc: 0.8810\n",
            "tensor(0.4644) tensor(0.4651)\n",
            "=========\n",
            "epoch 74 train loss: 0.5530 val_cls: 0.4638 val_acc: 0.8810\n",
            "tensor(0.4638) tensor(0.4644)\n",
            "=========\n",
            "epoch 75 train loss: 0.5491 val_cls: 0.4633 val_acc: 0.8810\n",
            "tensor(0.4633) tensor(0.4638)\n",
            "=========\n",
            "epoch 76 train loss: 0.5477 val_cls: 0.4627 val_acc: 0.8810\n",
            "tensor(0.4627) tensor(0.4633)\n",
            "=========\n",
            "epoch 77 train loss: 0.5433 val_cls: 0.4622 val_acc: 0.8810\n",
            "tensor(0.4622) tensor(0.4627)\n",
            "=========\n",
            "epoch 78 train loss: 0.5433 val_cls: 0.4615 val_acc: 0.8810\n",
            "tensor(0.4615) tensor(0.4622)\n",
            "=========\n",
            "epoch 79 train loss: 0.5501 val_cls: 0.4609 val_acc: 0.8810\n",
            "tensor(0.4609) tensor(0.4615)\n",
            "=========\n",
            "epoch 80 train loss: 0.5412 val_cls: 0.4604 val_acc: 0.8810\n",
            "tensor(0.4604) tensor(0.4609)\n",
            "=========\n",
            "epoch 81 train loss: 0.5411 val_cls: 0.4597 val_acc: 0.8810\n",
            "tensor(0.4597) tensor(0.4604)\n",
            "=========\n",
            "epoch 82 train loss: 0.5448 val_cls: 0.4593 val_acc: 0.8810\n",
            "tensor(0.4593) tensor(0.4597)\n",
            "=========\n",
            "epoch 83 train loss: 0.5324 val_cls: 0.4587 val_acc: 0.8810\n",
            "tensor(0.4587) tensor(0.4593)\n",
            "=========\n",
            "epoch 84 train loss: 0.5468 val_cls: 0.4586 val_acc: 0.8810\n",
            "tensor(0.4586) tensor(0.4587)\n",
            "=========\n",
            "epoch 85 train loss: 0.5305 val_cls: 0.4579 val_acc: 0.8810\n",
            "tensor(0.4579) tensor(0.4586)\n",
            "=========\n",
            "epoch 86 train loss: 0.5391 val_cls: 0.4576 val_acc: 0.8810\n",
            "tensor(0.4576) tensor(0.4579)\n",
            "=========\n",
            "epoch 87 train loss: 0.5356 val_cls: 0.4572 val_acc: 0.8810\n",
            "tensor(0.4572) tensor(0.4576)\n",
            "=========\n",
            "epoch 88 train loss: 0.5329 val_cls: 0.4568 val_acc: 0.8810\n",
            "tensor(0.4568) tensor(0.4572)\n",
            "=========\n",
            "epoch 89 train loss: 0.5350 val_cls: 0.4563 val_acc: 0.8810\n",
            "tensor(0.4563) tensor(0.4568)\n",
            "=========\n",
            "epoch 90 train loss: 0.5187 val_cls: 0.4557 val_acc: 0.8810\n",
            "tensor(0.4557) tensor(0.4563)\n",
            "=========\n",
            "epoch 91 train loss: 0.5311 val_cls: 0.4551 val_acc: 0.8810\n",
            "tensor(0.4551) tensor(0.4557)\n",
            "=========\n",
            "epoch 92 train loss: 0.5260 val_cls: 0.4547 val_acc: 0.8810\n",
            "tensor(0.4547) tensor(0.4551)\n",
            "=========\n",
            "epoch 93 train loss: 0.5220 val_cls: 0.4541 val_acc: 0.8810\n",
            "tensor(0.4541) tensor(0.4547)\n",
            "=========\n",
            "epoch 94 train loss: 0.5262 val_cls: 0.4534 val_acc: 0.8810\n",
            "tensor(0.4534) tensor(0.4541)\n",
            "=========\n",
            "epoch 95 train loss: 0.5181 val_cls: 0.4531 val_acc: 0.8810\n",
            "tensor(0.4531) tensor(0.4534)\n",
            "=========\n",
            "epoch 96 train loss: 0.5167 val_cls: 0.4526 val_acc: 0.8810\n",
            "tensor(0.4526) tensor(0.4531)\n",
            "=========\n",
            "epoch 97 train loss: 0.5292 val_cls: 0.4522 val_acc: 0.8810\n",
            "tensor(0.4522) tensor(0.4526)\n",
            "=========\n",
            "epoch 98 train loss: 0.5175 val_cls: 0.4517 val_acc: 0.8810\n",
            "tensor(0.4517) tensor(0.4522)\n",
            "=========\n",
            "epoch 99 train loss: 0.5142 val_cls: 0.4513 val_acc: 0.8810\n",
            "tensor(0.4513) tensor(0.4517)\n",
            "=========\n",
            "epoch 100 train loss: 0.5107 val_cls: 0.4508 val_acc: 0.8810\n",
            "tensor(0.4508) tensor(0.4513)\n",
            "=========\n",
            "epoch 101 train loss: 0.5102 val_cls: 0.4502 val_acc: 0.8810\n",
            "tensor(0.4502) tensor(0.4508)\n",
            "=========\n",
            "epoch 102 train loss: 0.5153 val_cls: 0.4499 val_acc: 0.8810\n",
            "tensor(0.4499) tensor(0.4502)\n",
            "=========\n",
            "epoch 103 train loss: 0.5208 val_cls: 0.4496 val_acc: 0.8810\n",
            "tensor(0.4496) tensor(0.4499)\n",
            "=========\n",
            "epoch 104 train loss: 0.5008 val_cls: 0.4489 val_acc: 0.8810\n",
            "tensor(0.4489) tensor(0.4496)\n",
            "=========\n",
            "epoch 105 train loss: 0.5046 val_cls: 0.4486 val_acc: 0.8810\n",
            "tensor(0.4486) tensor(0.4489)\n",
            "=========\n",
            "epoch 106 train loss: 0.5089 val_cls: 0.4483 val_acc: 0.8810\n",
            "tensor(0.4483) tensor(0.4486)\n",
            "=========\n",
            "epoch 107 train loss: 0.4998 val_cls: 0.4478 val_acc: 0.8810\n",
            "tensor(0.4478) tensor(0.4483)\n",
            "=========\n",
            "epoch 108 train loss: 0.5042 val_cls: 0.4473 val_acc: 0.8810\n",
            "tensor(0.4473) tensor(0.4478)\n",
            "=========\n",
            "epoch 109 train loss: 0.4896 val_cls: 0.4465 val_acc: 0.8810\n",
            "tensor(0.4465) tensor(0.4473)\n",
            "=========\n",
            "epoch 110 train loss: 0.5057 val_cls: 0.4462 val_acc: 0.8810\n",
            "tensor(0.4462) tensor(0.4465)\n",
            "=========\n",
            "epoch 111 train loss: 0.5008 val_cls: 0.4457 val_acc: 0.8810\n",
            "tensor(0.4457) tensor(0.4462)\n",
            "=========\n",
            "epoch 112 train loss: 0.4966 val_cls: 0.4452 val_acc: 0.8810\n",
            "tensor(0.4452) tensor(0.4457)\n",
            "=========\n",
            "epoch 113 train loss: 0.4989 val_cls: 0.4448 val_acc: 0.8810\n",
            "tensor(0.4448) tensor(0.4452)\n",
            "=========\n",
            "epoch 114 train loss: 0.4999 val_cls: 0.4445 val_acc: 0.8810\n",
            "tensor(0.4445) tensor(0.4448)\n",
            "=========\n",
            "epoch 115 train loss: 0.4915 val_cls: 0.4443 val_acc: 0.8810\n",
            "tensor(0.4443) tensor(0.4445)\n",
            "=========\n",
            "epoch 116 train loss: 0.4847 val_cls: 0.4438 val_acc: 0.8810\n",
            "tensor(0.4438) tensor(0.4443)\n",
            "=========\n",
            "epoch 117 train loss: 0.4773 val_cls: 0.4432 val_acc: 0.8810\n",
            "tensor(0.4432) tensor(0.4438)\n",
            "=========\n",
            "epoch 118 train loss: 0.4803 val_cls: 0.4427 val_acc: 0.8810\n",
            "tensor(0.4427) tensor(0.4432)\n",
            "=========\n",
            "epoch 119 train loss: 0.4768 val_cls: 0.4425 val_acc: 0.8810\n",
            "tensor(0.4425) tensor(0.4427)\n",
            "=========\n",
            "epoch 120 train loss: 0.4755 val_cls: 0.4422 val_acc: 0.8810\n",
            "tensor(0.4422) tensor(0.4425)\n",
            "=========\n",
            "epoch 121 train loss: 0.4819 val_cls: 0.4419 val_acc: 0.8810\n",
            "tensor(0.4419) tensor(0.4422)\n",
            "=========\n",
            "epoch 122 train loss: 0.4804 val_cls: 0.4416 val_acc: 0.8810\n",
            "tensor(0.4416) tensor(0.4419)\n",
            "=========\n",
            "epoch 123 train loss: 0.4702 val_cls: 0.4414 val_acc: 0.8810\n",
            "tensor(0.4414) tensor(0.4416)\n",
            "=========\n",
            "epoch 124 train loss: 0.4685 val_cls: 0.4409 val_acc: 0.8810\n",
            "tensor(0.4409) tensor(0.4414)\n",
            "=========\n",
            "epoch 125 train loss: 0.4654 val_cls: 0.4406 val_acc: 0.8810\n",
            "tensor(0.4406) tensor(0.4409)\n",
            "=========\n",
            "epoch 126 train loss: 0.4629 val_cls: 0.4403 val_acc: 0.8810\n",
            "tensor(0.4403) tensor(0.4406)\n",
            "=========\n",
            "epoch 127 train loss: 0.4714 val_cls: 0.4402 val_acc: 0.8810\n",
            "tensor(0.4402) tensor(0.4403)\n",
            "=========\n",
            "epoch 128 train loss: 0.4551 val_cls: 0.4399 val_acc: 0.8810\n",
            "tensor(0.4399) tensor(0.4402)\n",
            "=========\n",
            "epoch 129 train loss: 0.4651 val_cls: 0.4398 val_acc: 0.8810\n",
            "tensor(0.4398) tensor(0.4399)\n",
            "=========\n",
            "epoch 130 train loss: 0.4638 val_cls: 0.4397 val_acc: 0.8810\n",
            "tensor(0.4397) tensor(0.4398)\n",
            "=========\n",
            "epoch 131 train loss: 0.4590 val_cls: 0.4395 val_acc: 0.8810\n",
            "tensor(0.4395) tensor(0.4397)\n",
            "=========\n",
            "epoch 132 train loss: 0.4540 val_cls: 0.4393 val_acc: 0.8810\n",
            "tensor(0.4393) tensor(0.4395)\n",
            "=========\n",
            "epoch 133 train loss: 0.4544 val_cls: 0.4392 val_acc: 0.8810\n",
            "tensor(0.4392) tensor(0.4393)\n",
            "=========\n",
            "epoch 134 train loss: 0.4562 val_cls: 0.4391 val_acc: 0.8810\n",
            "tensor(0.4391) tensor(0.4392)\n",
            "=========\n",
            "epoch 135 train loss: 0.4416 val_cls: 0.4388 val_acc: 0.8810\n",
            "tensor(0.4388) tensor(0.4391)\n",
            "=========\n",
            "epoch 136 train loss: 0.4419 val_cls: 0.4387 val_acc: 0.8810\n",
            "tensor(0.4387) tensor(0.4388)\n",
            "=========\n",
            "epoch 137 train loss: 0.4457 val_cls: 0.4387 val_acc: 0.8810\n",
            "tensor(0.4387) tensor(0.4387)\n",
            "=========\n",
            "epoch 138 train loss: 0.4416 val_cls: 0.4386 val_acc: 0.8810\n",
            "tensor(0.4386) tensor(0.4387)\n",
            "=========\n",
            "epoch 139 train loss: 0.4383 val_cls: 0.4385 val_acc: 0.8810\n",
            "tensor(0.4385) tensor(0.4386)\n",
            "=========\n",
            "epoch 140 train loss: 0.4377 val_cls: 0.4384 val_acc: 0.8810\n",
            "tensor(0.4384) tensor(0.4385)\n",
            "=========\n",
            "epoch 141 train loss: 0.4405 val_cls: 0.4383 val_acc: 0.8810\n",
            "tensor(0.4383) tensor(0.4384)\n",
            "=========\n",
            "epoch 142 train loss: 0.4370 val_cls: 0.4381 val_acc: 0.8810\n",
            "tensor(0.4381) tensor(0.4383)\n",
            "=========\n",
            "epoch 143 train loss: 0.4309 val_cls: 0.4382 val_acc: 0.8810\n",
            "tensor(0.4382) tensor(0.4381)\n",
            "=========\n",
            "epoch 144 train loss: 0.4383 val_cls: 0.4381 val_acc: 0.8810\n",
            "tensor(0.4381) tensor(0.4381)\n",
            "=========\n",
            "epoch 145 train loss: 0.4286 val_cls: 0.4380 val_acc: 0.8810\n",
            "tensor(0.4380) tensor(0.4381)\n",
            "=========\n",
            "epoch 146 train loss: 0.4151 val_cls: 0.4380 val_acc: 0.8810\n",
            "tensor(0.4380) tensor(0.4380)\n",
            "=========\n",
            "epoch 147 train loss: 0.4319 val_cls: 0.4376 val_acc: 0.8810\n",
            "tensor(0.4376) tensor(0.4380)\n",
            "=========\n",
            "epoch 148 train loss: 0.4243 val_cls: 0.4376 val_acc: 0.8810\n",
            "tensor(0.4376) tensor(0.4376)\n",
            "=========\n",
            "epoch 149 train loss: 0.4231 val_cls: 0.4377 val_acc: 0.8810\n",
            "tensor(0.4377) tensor(0.4376)\n",
            "=========\n",
            "epoch 150 train loss: 0.4159 val_cls: 0.4380 val_acc: 0.8810\n",
            "tensor(0.4380) tensor(0.4376)\n",
            "EARLY STOPPING \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "qO0xooOmL_3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history[\"train_loss\"], label='train');\n",
        "plt.plot(history[\"val_cls\"], label='val');\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "YIp9yuw_1KsA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "2ae03909-dc28-4acb-981f-867a20b1466c"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7feed7af0ee0>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history[\"val_acc\"]);\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('ACC');"
      ],
      "metadata": {
        "id": "LpiIB4WwKK2S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "c8671b27-bec3-427a-b017-c6f87d92d8dc"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "predictions = utils.test(classification_model, test_iter)\n",
        "predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_true = y_test, y_pred = predictions))\n",
        "print(\"F1_Score:\", f1_score(y_pred=predictions, y_true=y_test, average='weighted'))\n",
        "print(\" \")\n",
        "print(\"MSE:\", mse(y_true = y_test, y_pred = predictions))\n",
        "print(\"MAE:\", mae(y_true = y_test, y_pred = predictions))"
      ],
      "metadata": {
        "id": "d_iaeA9ce5GM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de0133f4-c57f-4c76-dd0e-0bb88f9468a8"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8585714285714285\n",
            "F1_Score: 0.7932381684418579\n",
            " \n",
            "MSE: 0.5714285714285714\n",
            "MAE: 0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# examine accuracy of predictions for test set\n",
        "pred = utils.test(classification_model, test_iter)\n",
        "# find the most likely rating for the specific review by finding the column with the highest score in each row of the matrix\n",
        "conv_pred = np.argmax(pred, axis=1)\n",
        "\n",
        "# print classification report\n",
        "print(classification_report(y_pred=conv_pred, y_true=y_test))"
      ],
      "metadata": {
        "id": "lIL_BJZgKXmm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d76ff52-3347-4125-c274-a88bf28f9157"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        13\n",
            "           1       0.00      0.00      0.00         8\n",
            "           2       0.00      0.00      0.00        14\n",
            "           3       0.00      0.00      0.00        64\n",
            "           4       0.86      1.00      0.92       601\n",
            "\n",
            "    accuracy                           0.86       700\n",
            "   macro avg       0.17      0.20      0.18       700\n",
            "weighted avg       0.74      0.86      0.79       700\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y_test, conv_pred);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "D6MiVGlR_Hct",
        "outputId": "5fa06a25-908d-440e-cb7f-4c05b93fa56a"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test if model is more accurate than a dummy model\n",
        "from sklearn.dummy import DummyClassifier\n",
        "dummy1 = DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy2 = DummyClassifier(strategy=\"stratified\")"
      ],
      "metadata": {
        "id": "yI9P8aDb6F2u"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# most_frequent - returns most frequent class label\n",
        "dummy1.fit(x_train, y_train)\n",
        "dummy1.score(x_train, y_train)"
      ],
      "metadata": {
        "id": "TPy0KjEq6IH1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a33cf77b-e51a-4e34-b151-aacd430840ab"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8439490445859873"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stratified - returns random samples from a distribution based on prior probabilities\n",
        "dummy2.fit(x_train, y_train)\n",
        "dummy2.score(x_train, y_train)"
      ],
      "metadata": {
        "id": "jlU6d7MD6PPB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31500ad3-7e5c-4910-8c73-3573bb81b3cc"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7101910828025477"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    }
  ]
}