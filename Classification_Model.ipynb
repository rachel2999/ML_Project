{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Drink Quality by Reviews"
      ],
      "metadata": {
        "id": "WTkQ8n1FsVJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examine the correlation between \"Rating\" and \"Review\" to determine if the quality of a drink can be predicted based on it's reviews."
      ],
      "metadata": {
        "id": "3QLwH_X0TL_-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1THLhLXDOmz",
        "outputId": "36ad5805-b5f5-43c0-9c9f-5770a2e46541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting import-ipynb\n",
            "  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.8/dist-packages (from import-ipynb) (7.9.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from import-ipynb) (5.7.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (4.4.2)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (2.0.10)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (57.4.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from IPython->import-ipynb) (2.6.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->import-ipynb) (2.16.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.8/dist-packages (from nbformat->import-ipynb) (5.1.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->import-ipynb) (4.3.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->IPython->import-ipynb) (0.8.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.19.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (22.2.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (5.10.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import-ipynb) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import-ipynb) (0.2.5)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core->nbformat->import-ipynb) (2.6.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->IPython->import-ipynb) (0.7.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->import-ipynb) (3.11.0)\n",
            "Installing collected packages: jedi, import-ipynb\n",
            "Successfully installed import-ipynb-0.1.4 jedi-0.18.2\n"
          ]
        }
      ],
      "source": [
        "!pip install import-ipynb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/MyDrive/ML-Project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XZesjC4DUcU",
        "outputId": "588b2409-45d2-4260-e82e-2b51d35091de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/ML-Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import random\n",
        "import import_ipynb\n",
        "import utils\n",
        "\n",
        "\n",
        "# to get reproducible results:\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC_ZMjWvDYoj",
        "outputId": "d946ffd7-c9fe-4798-c350-58dd39f4bbfd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "importing Jupyter notebook from utils.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "metadata": {
        "id": "CoLyV47NLEas"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing the Dataset"
      ],
      "metadata": {
        "id": "kJTb2CCVK6Gw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read dataset file\n",
        "df = pd.read_csv('dataset.csv', sep=',')"
      ],
      "metadata": {
        "id": "KKBmGAx6Dn7_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace column names with shorter, more readable names\n",
        "df.columns = ['Num', 'Brand', 'Name', 'Date', 'Recommend', 'Helpful', 'Rating', 'Weight', 'Review Title', 'Review']\n",
        "df.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "mg_ZwGcTEClT",
        "outputId": "2b7b5b4a-87d6-44a8-c2b7-0fa346e61cfb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Num        Brand                                       Name  \\\n",
              "1263  1264         Gmax     Gmax g144105 gm44 full face red wine m   \n",
              "227    228     Heineken     Heineken174 Lager - 6pk / 12oz Bottles   \n",
              "2142  2143       Carmex  Carmex Lip Balm Original Jar - 12 PK, 12.   \n",
              "450    451     Jim Beam      Jim Beam Black Bourbon Whiskey, 50 mL   \n",
              "1403  1404  Great Value  Great Value Original Crescent Rolls, 8 oz   \n",
              "\n",
              "                      Date Recommend  Helpful  Rating   Weight  \\\n",
              "1263  2017-01-09T22:25:24Z       NaN      NaN     4.0      NaN   \n",
              "227   2017-09-20T01:18:35Z      True      NaN     5.0  1.0 lbs   \n",
              "2142  2017-09-23T02:53:08Z      True      NaN     5.0      NaN   \n",
              "450   2017-09-20T01:18:35Z       NaN      NaN     5.0      NaN   \n",
              "1403  2017-09-02T07:55:36Z      True      0.0     5.0      NaN   \n",
              "\n",
              "                   Review Title  \\\n",
              "1263                        NaN   \n",
              "227                 Great beer!   \n",
              "2142         Small and compact!   \n",
              "450        My favorite bourbon!   \n",
              "1403  Just as good as Pillsbury   \n",
              "\n",
              "                                                 Review  \n",
              "1263                                       easy process  \n",
              "227   I bought this, best price and great convenienc...  \n",
              "2142  The lip balm is so smooth, doesn't have a weir...  \n",
              "450                          Exceptionally good flavor!  \n",
              "1403         Just as good as Pillsbury but better price  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d0c02468-b0db-4a69-9771-55f75976d119\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Num</th>\n",
              "      <th>Brand</th>\n",
              "      <th>Name</th>\n",
              "      <th>Date</th>\n",
              "      <th>Recommend</th>\n",
              "      <th>Helpful</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Review Title</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1263</th>\n",
              "      <td>1264</td>\n",
              "      <td>Gmax</td>\n",
              "      <td>Gmax g144105 gm44 full face red wine m</td>\n",
              "      <td>2017-01-09T22:25:24Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>easy process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>228</td>\n",
              "      <td>Heineken</td>\n",
              "      <td>Heineken174 Lager - 6pk / 12oz Bottles</td>\n",
              "      <td>2017-09-20T01:18:35Z</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>Great beer!</td>\n",
              "      <td>I bought this, best price and great convenienc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2142</th>\n",
              "      <td>2143</td>\n",
              "      <td>Carmex</td>\n",
              "      <td>Carmex Lip Balm Original Jar - 12 PK, 12.</td>\n",
              "      <td>2017-09-23T02:53:08Z</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Small and compact!</td>\n",
              "      <td>The lip balm is so smooth, doesn't have a weir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>451</td>\n",
              "      <td>Jim Beam</td>\n",
              "      <td>Jim Beam Black Bourbon Whiskey, 50 mL</td>\n",
              "      <td>2017-09-20T01:18:35Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>My favorite bourbon!</td>\n",
              "      <td>Exceptionally good flavor!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1403</th>\n",
              "      <td>1404</td>\n",
              "      <td>Great Value</td>\n",
              "      <td>Great Value Original Crescent Rolls, 8 oz</td>\n",
              "      <td>2017-09-02T07:55:36Z</td>\n",
              "      <td>True</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just as good as Pillsbury</td>\n",
              "      <td>Just as good as Pillsbury but better price</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0c02468-b0db-4a69-9771-55f75976d119')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d0c02468-b0db-4a69-9771-55f75976d119 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d0c02468-b0db-4a69-9771-55f75976d119');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove useless columns\n",
        "df.drop(\"Num\", axis=1, inplace=True)\n",
        "df.drop(\"Date\", axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "2AiS9linDA-b"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reindex rows\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "5H4vyxXCbgt2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        },
        "outputId": "5919c207-400d-46b6-c215-5db94f6cd420"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Brand                                               Name  \\\n",
              "0             Gallo         Ecco Domani174 Pinot Grigio - 750ml Bottle   \n",
              "1   Fresh Craft Co.   Fresh Craft174 Mango Citrus - 4pk / 250ml Bottle   \n",
              "2      1000 Stories           1000 Stories174 Zinfandel - 750ml Bottle   \n",
              "3      1000 Stories           1000 Stories174 Zinfandel - 750ml Bottle   \n",
              "4      Wine Cube153            Pink Moscato - 3l Bottle - Wine Cube153   \n",
              "5         Beck's Na  Beck's174 Non Alcoholic Beer - 6pk / 12oz Bottles   \n",
              "6             Gallo                Apothic174 Red Blend - 750ml Bottle   \n",
              "7             Gallo                Apothic174 Red Blend - 750ml Bottle   \n",
              "8  California Roots        California Roots Moscato White Wine - 750ml   \n",
              "9   Charles Charles        Charles Charles174 Red Blend - 750ml Bottle   \n",
              "\n",
              "  Recommend  Helpful  Rating    Weight                          Review Title  \\\n",
              "0      True      1.0     5.0   1.0 lbs                My Favorite White Wine   \n",
              "1      True      NaN     5.0  2.45 lbs                                 Yum!!   \n",
              "2      True      NaN     5.0  3.09 lbs                       A New Favorite!   \n",
              "3      True      NaN     5.0  3.09 lbs  Bold, Flavorful, Aromatic, Delicious   \n",
              "4      True      1.0     5.0   1.0 lbs  Yum! Plus, Environmentally Friendly!   \n",
              "5      True      NaN     5.0   1.0 lbs                           Great Taste   \n",
              "6       NaN      1.0     3.0   1.0 lbs                      Simply Wonderful   \n",
              "7       NaN      1.0     2.0   1.0 lbs                          A Sweet Red.   \n",
              "8      True      0.0     5.0  2.65 lbs                                   NaN   \n",
              "9      True      NaN     5.0   1.0 lbs           Charles & Charles Red Blend   \n",
              "\n",
              "                                              Review  \n",
              "0      This a fantastic white wine for any occasion!  \n",
              "1   Tart, not sweet...very refreshing and delicious!  \n",
              "2  I was given this wine so it was a delightful s...  \n",
              "3  This is a phenomenal wine and my new favorite ...  \n",
              "4  4 750ml bottles for the price of two With way ...  \n",
              "5  I LOVE Becks NA. It tastes just like a regular...  \n",
              "6  This wine has a wonderful but strong aroma its...  \n",
              "7  I would give one more star if it came clean on...  \n",
              "8                      Delicious and very affordable  \n",
              "9  This is a very smooth red with Aromas of cocoa...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-36ce57f9-3f5e-41ec-a218-aa2551e994ef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Brand</th>\n",
              "      <th>Name</th>\n",
              "      <th>Recommend</th>\n",
              "      <th>Helpful</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Review Title</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Gallo</td>\n",
              "      <td>Ecco Domani174 Pinot Grigio - 750ml Bottle</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>My Favorite White Wine</td>\n",
              "      <td>This a fantastic white wine for any occasion!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fresh Craft Co.</td>\n",
              "      <td>Fresh Craft174 Mango Citrus - 4pk / 250ml Bottle</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.45 lbs</td>\n",
              "      <td>Yum!!</td>\n",
              "      <td>Tart, not sweet...very refreshing and delicious!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000 Stories</td>\n",
              "      <td>1000 Stories174 Zinfandel - 750ml Bottle</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.09 lbs</td>\n",
              "      <td>A New Favorite!</td>\n",
              "      <td>I was given this wine so it was a delightful s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000 Stories</td>\n",
              "      <td>1000 Stories174 Zinfandel - 750ml Bottle</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.09 lbs</td>\n",
              "      <td>Bold, Flavorful, Aromatic, Delicious</td>\n",
              "      <td>This is a phenomenal wine and my new favorite ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Wine Cube153</td>\n",
              "      <td>Pink Moscato - 3l Bottle - Wine Cube153</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>Yum! Plus, Environmentally Friendly!</td>\n",
              "      <td>4 750ml bottles for the price of two With way ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Beck's Na</td>\n",
              "      <td>Beck's174 Non Alcoholic Beer - 6pk / 12oz Bottles</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>Great Taste</td>\n",
              "      <td>I LOVE Becks NA. It tastes just like a regular...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Gallo</td>\n",
              "      <td>Apothic174 Red Blend - 750ml Bottle</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>Simply Wonderful</td>\n",
              "      <td>This wine has a wonderful but strong aroma its...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Gallo</td>\n",
              "      <td>Apothic174 Red Blend - 750ml Bottle</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>A Sweet Red.</td>\n",
              "      <td>I would give one more star if it came clean on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>California Roots</td>\n",
              "      <td>California Roots Moscato White Wine - 750ml</td>\n",
              "      <td>True</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.65 lbs</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Delicious and very affordable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Charles Charles</td>\n",
              "      <td>Charles Charles174 Red Blend - 750ml Bottle</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0 lbs</td>\n",
              "      <td>Charles &amp; Charles Red Blend</td>\n",
              "      <td>This is a very smooth red with Aromas of cocoa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36ce57f9-3f5e-41ec-a218-aa2551e994ef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-36ce57f9-3f5e-41ec-a218-aa2551e994ef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-36ce57f9-3f5e-41ec-a218-aa2551e994ef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check for total amount of null values in each column\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "Q7ZAX3-RGAOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cff24bb-a03a-4a17-a0b0-01fc881c329d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brand             65\n",
            "Name               0\n",
            "Recommend        979\n",
            "Helpful         2264\n",
            "Rating           445\n",
            "Weight          1894\n",
            "Review Title      44\n",
            "Review             1\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove all rows that have no ratings or recommendations\n",
        "df = df.dropna(subset=['Rating'])\n",
        "df = df.dropna(subset=['Recommend'])\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "E9Pkbdj-IVA_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cb54c9a-82bf-4438-b8f6-a4b97f6df131"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Brand              0\n",
              "Name               0\n",
              "Recommend          0\n",
              "Helpful         1170\n",
              "Rating             0\n",
              "Weight          1392\n",
              "Review Title      10\n",
              "Review             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the all possible ratings from 1 to 5 are used\n",
        "np.unique(df['Rating'])"
      ],
      "metadata": {
        "id": "yJIJNlkkKqkV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7164bd2e-928d-4e2e-bac4-47db10583c80"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 2., 3., 4., 5.])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "FOC26UJ1BgCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0cf6981-eb8b-4a76-cb5d-0cafa1e2f901"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1748 entries, 0 to 2815\n",
            "Data columns (total 8 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Brand         1748 non-null   object \n",
            " 1   Name          1748 non-null   object \n",
            " 2   Recommend     1748 non-null   object \n",
            " 3   Helpful       578 non-null    float64\n",
            " 4   Rating        1748 non-null   float64\n",
            " 5   Weight        356 non-null    object \n",
            " 6   Review Title  1738 non-null   object \n",
            " 7   Review        1748 non-null   object \n",
            "dtypes: float64(2), object(6)\n",
            "memory usage: 122.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change data type of \"Rating\" from float to integer\n",
        "df['Rating'] = df['Rating'].astype(int)\n",
        "\n",
        "# change data type of \"Recommend\" from object to integer\n",
        "# \"True\" = 1, \"False\" = 0\n",
        "df[\"Recommend\"] = df[\"Recommend\"].astype(int)\n",
        "\n",
        "# check data types again\n",
        "df.info()"
      ],
      "metadata": {
        "id": "55B7BhBBL4VK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e556819-aff7-43e2-cc8b-52745ce2ea8a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1748 entries, 0 to 2815\n",
            "Data columns (total 8 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Brand         1748 non-null   object \n",
            " 1   Name          1748 non-null   object \n",
            " 2   Recommend     1748 non-null   int64  \n",
            " 3   Helpful       578 non-null    float64\n",
            " 4   Rating        1748 non-null   int64  \n",
            " 5   Weight        356 non-null    object \n",
            " 6   Review Title  1738 non-null   object \n",
            " 7   Review        1748 non-null   object \n",
            "dtypes: float64(1), int64(2), object(5)\n",
            "memory usage: 122.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect correlation between numeric features\n",
        "df.corr()"
      ],
      "metadata": {
        "id": "72OEXXdrb6EF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "3d6c3242-b9ef-4449-fec9-c9b6054b4340"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Recommend   Helpful    Rating\n",
              "Recommend   1.000000  0.042670  0.767292\n",
              "Helpful     0.042670  1.000000  0.024891\n",
              "Rating      0.767292  0.024891  1.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-167fd197-6aa6-4a01-a913-1917c955a2bc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Recommend</th>\n",
              "      <th>Helpful</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Recommend</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.042670</td>\n",
              "      <td>0.767292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Helpful</th>\n",
              "      <td>0.042670</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.024891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Rating</th>\n",
              "      <td>0.767292</td>\n",
              "      <td>0.024891</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-167fd197-6aa6-4a01-a913-1917c955a2bc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-167fd197-6aa6-4a01-a913-1917c955a2bc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-167fd197-6aa6-4a01-a913-1917c955a2bc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- There is a weak positive correlation between recommend and helpful. Reviews that were voted helpful tend to be about alcohol that reviewers recommend to others.\n",
        "- There is a strong positive correlation between recommend and rating. The higher the rating/quality of the alcohol, then then the more likely that the reviewer would recommend it.\n",
        "- There is a very weak positive correlation between helpful and rating. Alcohol that was voted helpful tend to have slightly higher ratings than reviews not considered helpful."
      ],
      "metadata": {
        "id": "hJSUEBotcmi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check for duplicated reviews\n",
        "df['Review'].duplicated().sum()"
      ],
      "metadata": {
        "id": "Y4Ggih8XF42P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8275c669-27e4-4e55-a2a5-4caeb6138f2d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove duplicated reviews\n",
        "df['Review'].drop_duplicates()"
      ],
      "metadata": {
        "id": "U1QKOX4uF-UU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca9d27b2-7637-4cc9-8f49-6230e523f76d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0           This a fantastic white wine for any occasion!\n",
              "1        Tart, not sweet...very refreshing and delicious!\n",
              "2       I was given this wine so it was a delightful s...\n",
              "3       This is a phenomenal wine and my new favorite ...\n",
              "4       4 750ml bottles for the price of two With way ...\n",
              "                              ...                        \n",
              "2811    My kids love them. So no complaints but I'm su...\n",
              "2812    Easy and quick to serve, brings a smile to the...\n",
              "2813                         Worked great kids loved them\n",
              "2814    Walmart used to carry a Swiss water decaf coff...\n",
              "2815    Great decaf coffee using Swiss water process. ...\n",
              "Name: Review, Length: 1735, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clean text in reviews with natural language toolkit\n",
        "!pip install nltk\n",
        "import nltk\n",
        "\n",
        "# define stopwords to remove\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stopwords = set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "id": "PupCwDbIoOpi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "192db1f3-07f6-4d7e-9521-c37025d54327"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize text with regex before cleaning\n",
        "from nltk import word_tokenize\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "token = TreebankWordDetokenizer()\n",
        "\n",
        "def clean(w):\n",
        "    w = word_tokenize(w.lower()) # turn all token words lowercase\n",
        "    w = [token for token in w if token not in stopwords and token.isalpha()] # remove stopwords and non-words (punctuation, numbers, etc.)\n",
        "    return token.detokenize(w)\n",
        "\n",
        "df[\"Clean_Reviews\"] = df[\"Review\"].apply(clean)"
      ],
      "metadata": {
        "id": "NzYNfnTejmJV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check to make sure the reviews were cleaned correctly\n",
        "df[\"Clean_Reviews\"].sample(10)"
      ],
      "metadata": {
        "id": "-Yj3GOHztCI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2486692-c187-4662-e72f-5dc5f6bf2b40"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1596    prefer purchase store individually whatever ne...\n",
              "477                             best bloody mary mix ever\n",
              "2364    started using carmex cna brand count heal supp...\n",
              "2061    using carmex yrs still always keep jar purse t...\n",
              "2226    started applying four times day honestly great...\n",
              "2373    buy carmex tub becuase mother always wood open...\n",
              "829                                              favorite\n",
              "1980    use many year really work dry lips light burn ...\n",
              "1994    always go back carmex original lip balm jar li...\n",
              "2585    using carmex original lip balm jar since child...\n",
              "Name: Clean_Reviews, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network Algorithm - Classification"
      ],
      "metadata": {
        "id": "PW8V5xxiK_or"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "yeJ7Q9PsLLMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset 30% test, 70% train\n",
        "y = df[\"Rating\"].values\n",
        "words = df[\"Clean_Reviews\"].values\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(words, y, test_size=0.3, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "1HDqQ6ODAHrL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# examine a random dictionary entry\n",
        "print(\"Review:\", x_train[2])\n",
        "print(\"Rating:\", y_train[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYc8rJPI4ga8",
        "outputId": "b04f2214-57d4-4ee8-a6ff-c27d5dcd93a5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: product must work outdoors cant tell many times fellow flagger friends forgot pinch asked use mine thank carmex\n",
            "Rating: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize the reviews to vectorize each word as an integer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# limit vocabularly index to the most common 10,000 words\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "# create vocab index based on word frequency\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "# apply limited vocab to train and test\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_test = tokenizer.texts_to_sequences(x_test)"
      ],
      "metadata": {
        "id": "wpyBLExX1lvl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# examine a random dictionary entry\n",
        "print(\"Encoded Review:\", x_train[2])\n",
        "print(\"Rating:\", y_train[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo4wDEsrBSaV",
        "outputId": "585534b9-dd68-46fe-da21-ab807039f658"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Review: [4, 175, 65, 1526, 491, 272, 46, 96, 803, 1527, 123, 492, 1069, 804, 5, 352, 101, 2]\n",
            "Rating: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# re-vectorize reviews into sparse 2D nummpy array, with many zeros in the data\n",
        "# convert the reviews into a matrix, one review per row and one column per word\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "\n",
        "num_words=10000\n",
        "x_train = vectorize_sequences(x_train, dimension=num_words)\n",
        "x_test = vectorize_sequences(x_test, dimension=num_words)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfOMEkmtEhIN",
        "outputId": "ef8251ff-f8eb-46c9-cd1e-eee89ab37d0b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1223, 10000)\n",
            "(525, 10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train[:15])\n",
        "print(y_test[:15])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvppg8JhEy69",
        "outputId": "79b00289-9eae-48c6-ebf9-6d2ee268e55e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 5 5 5 5 5 5 5 3 5 5 5 5 5 5]\n",
            "[4 5 4 5 4 5 4 4 5 5 5 5 5 5 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "cnt = Counter(list(y_train))\n",
        "num_classes = 5\n",
        "cnt.most_common(num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzNLYfHYE5SY",
        "outputId": "5e5c5132-04fd-4a46-d9b8-386d148b6203"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(5, 1057), (4, 101), (3, 27), (1, 25), (2, 13)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_labels = sorted(set([i[0] for i in cnt.most_common(num_classes)]))\n",
        "selected_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXLlphZPE7Dy",
        "outputId": "974505d7-7851-4104-be5c-6d471bca080a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_mask = [True if l in selected_labels else False for l in y_train]\n",
        "x_train = x_train[train_mask, :]\n",
        "y_train = y_train[train_mask]\n",
        "y_train = np.array([selected_labels.index(i) for i in y_train]) # reindex\n",
        "\n",
        "test_mask = [True if l in selected_labels else False for l in y_test]\n",
        "x_test= x_test[test_mask, :]\n",
        "y_test = y_test[test_mask]\n",
        "y_test = np.array([selected_labels.index(i) for i in y_test]) # reindex\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e20T7eIE-dK",
        "outputId": "c771376f-38e7-4039-e172-8510a644752c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1223, 10000)\n",
            "(525, 10000)\n",
            "(1223,)\n",
            "(525,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split training data into 30% train and 70% dev\n",
        "x_train, x_dev, y_train, y_dev = train_test_split(x_train, y_train, test_size=0.3, random_state=42)\n",
        "print(y_train.shape)\n",
        "print(x_train.shape)\n",
        "print(x_dev.shape)\n",
        "print(y_dev.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRsWweDsFK_m",
        "outputId": "6ad6eafb-230e-436c-99eb-a0ef6ab9b162"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(856,)\n",
            "(856, 10000)\n",
            "(367, 10000)\n",
            "(367,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert numpy array into PyTorch format\n",
        "\n",
        "# 1) define function\n",
        "def np2iter(x, y, shuffle=True):\n",
        "  x = torch.tensor(x, dtype=torch.float)\n",
        "  y = torch.tensor(y, dtype=torch.long)\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  print(\"----------------------\")\n",
        "\n",
        "  ds = torch.utils.data.TensorDataset(x, y)\n",
        "  return torch.utils.data.DataLoader(ds, batch_size=32, shuffle=shuffle)\n",
        "\n",
        "# 2) convert data\n",
        "train_iter = np2iter(x_train, y_train, shuffle=True) # DO shuffle train\n",
        "dev_iter =  np2iter(x_dev, y_dev, shuffle=False) # do NOT shuffle dev or test\n",
        "test_iter =  np2iter(x_test, y_test, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uzyjv9faFNiV",
        "outputId": "e521e250-08e6-4e72-d12b-968249baadac"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([856, 10000])\n",
            "torch.Size([856])\n",
            "----------------------\n",
            "torch.Size([367, 10000])\n",
            "torch.Size([367])\n",
            "----------------------\n",
            "torch.Size([525, 10000])\n",
            "torch.Size([525])\n",
            "----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining accuracy\n",
        "def val_acc(y_pred, y_test): # define accuracy\n",
        "  y_pred = np.argmax(y_pred, axis=1)\n",
        "  return accuracy_score(y_pred=y_pred, y_true=y_test)"
      ],
      "metadata": {
        "id": "5L0qbYdpFwad"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "RySLkWAMLnbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model\n",
        "num_words = 10000\n",
        "num_ratings = 5\n",
        "\n",
        "class MultiClassModel(nn.Module):\n",
        "  def __init__(self, in_features=num_words, out_features=num_ratings):\n",
        "    super(MultiClassModel, self).__init__()\n",
        "    \n",
        "    # define linear layer\n",
        "    self.layer = nn.Linear(in_features=in_features, out_features=out_features)\n",
        "\n",
        "\n",
        "  # feed the model the input and apply the linear layer to get the output\n",
        "  def forward(self, x):\n",
        "    return self.layer(x) "
      ],
      "metadata": {
        "id": "4PUuNQMBFQFI"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_model = MultiClassModel(in_features=num_words, out_features=num_classes)\n",
        "classification_model = classification_model.cuda()"
      ],
      "metadata": {
        "id": "2l319rxEL8aY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use crossentropy loss which includes softmax activation automatically\n",
        "history = utils.train(model=classification_model,\n",
        "                            loss=nn.CrossEntropyLoss(), \n",
        "                            val_metrics={\"cls\": nn.CrossEntropyLoss(), \"acc\": val_acc}, \n",
        "                            optimizer=torch.optim.SGD(classification_model.parameters(), lr=0.01),\n",
        "                            train_ds=train_iter, \n",
        "                            dev_ds=dev_iter,\n",
        "                            num_epochs=150)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K40gJZ8eFw1H",
        "outputId": "68c597cb-46e3-4762-856e-961d7d43fafd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========\n",
            "epoch 1 train loss: 1.4944 val_cls: 1.3705 val_acc: 0.8665\n",
            "=========\n",
            "epoch 2 train loss: 1.2737 val_cls: 1.1805 val_acc: 0.8665\n",
            "=========\n",
            "epoch 3 train loss: 1.1051 val_cls: 1.0385 val_acc: 0.8665\n",
            "=========\n",
            "epoch 4 train loss: 0.9795 val_cls: 0.9334 val_acc: 0.8665\n",
            "=========\n",
            "epoch 5 train loss: 0.8862 val_cls: 0.8554 val_acc: 0.8665\n",
            "=========\n",
            "epoch 6 train loss: 0.8163 val_cls: 0.7971 val_acc: 0.8665\n",
            "=========\n",
            "epoch 7 train loss: 0.7634 val_cls: 0.7524 val_acc: 0.8665\n",
            "=========\n",
            "epoch 8 train loss: 0.7223 val_cls: 0.7181 val_acc: 0.8665\n",
            "=========\n",
            "epoch 9 train loss: 0.6902 val_cls: 0.6909 val_acc: 0.8665\n",
            "=========\n",
            "epoch 10 train loss: 0.6644 val_cls: 0.6692 val_acc: 0.8665\n",
            "=========\n",
            "epoch 11 train loss: 0.6435 val_cls: 0.6515 val_acc: 0.8665\n",
            "=========\n",
            "epoch 12 train loss: 0.6261 val_cls: 0.6369 val_acc: 0.8665\n",
            "=========\n",
            "epoch 13 train loss: 0.6116 val_cls: 0.6248 val_acc: 0.8665\n",
            "=========\n",
            "epoch 14 train loss: 0.5993 val_cls: 0.6147 val_acc: 0.8665\n",
            "=========\n",
            "epoch 15 train loss: 0.5889 val_cls: 0.6062 val_acc: 0.8665\n",
            "=========\n",
            "epoch 16 train loss: 0.5799 val_cls: 0.5989 val_acc: 0.8665\n",
            "=========\n",
            "epoch 17 train loss: 0.5721 val_cls: 0.5926 val_acc: 0.8665\n",
            "=========\n",
            "epoch 18 train loss: 0.5652 val_cls: 0.5871 val_acc: 0.8665\n",
            "=========\n",
            "epoch 19 train loss: 0.5591 val_cls: 0.5824 val_acc: 0.8665\n",
            "=========\n",
            "epoch 20 train loss: 0.5536 val_cls: 0.5782 val_acc: 0.8665\n",
            "=========\n",
            "epoch 21 train loss: 0.5487 val_cls: 0.5744 val_acc: 0.8665\n",
            "=========\n",
            "epoch 22 train loss: 0.5442 val_cls: 0.5710 val_acc: 0.8665\n",
            "=========\n",
            "epoch 23 train loss: 0.5400 val_cls: 0.5679 val_acc: 0.8665\n",
            "=========\n",
            "epoch 24 train loss: 0.5362 val_cls: 0.5651 val_acc: 0.8665\n",
            "=========\n",
            "epoch 25 train loss: 0.5326 val_cls: 0.5626 val_acc: 0.8665\n",
            "=========\n",
            "epoch 26 train loss: 0.5293 val_cls: 0.5603 val_acc: 0.8665\n",
            "=========\n",
            "epoch 27 train loss: 0.5262 val_cls: 0.5582 val_acc: 0.8665\n",
            "=========\n",
            "epoch 28 train loss: 0.5233 val_cls: 0.5562 val_acc: 0.8665\n",
            "=========\n",
            "epoch 29 train loss: 0.5205 val_cls: 0.5543 val_acc: 0.8665\n",
            "=========\n",
            "epoch 30 train loss: 0.5179 val_cls: 0.5526 val_acc: 0.8665\n",
            "=========\n",
            "epoch 31 train loss: 0.5154 val_cls: 0.5509 val_acc: 0.8665\n",
            "=========\n",
            "epoch 32 train loss: 0.5130 val_cls: 0.5494 val_acc: 0.8665\n",
            "=========\n",
            "epoch 33 train loss: 0.5106 val_cls: 0.5479 val_acc: 0.8665\n",
            "=========\n",
            "epoch 34 train loss: 0.5084 val_cls: 0.5465 val_acc: 0.8665\n",
            "=========\n",
            "epoch 35 train loss: 0.5062 val_cls: 0.5452 val_acc: 0.8665\n",
            "=========\n",
            "epoch 36 train loss: 0.5041 val_cls: 0.5439 val_acc: 0.8665\n",
            "=========\n",
            "epoch 37 train loss: 0.5021 val_cls: 0.5427 val_acc: 0.8665\n",
            "=========\n",
            "epoch 38 train loss: 0.5001 val_cls: 0.5416 val_acc: 0.8665\n",
            "=========\n",
            "epoch 39 train loss: 0.4982 val_cls: 0.5405 val_acc: 0.8665\n",
            "=========\n",
            "epoch 40 train loss: 0.4964 val_cls: 0.5394 val_acc: 0.8665\n",
            "=========\n",
            "epoch 41 train loss: 0.4945 val_cls: 0.5383 val_acc: 0.8665\n",
            "=========\n",
            "epoch 42 train loss: 0.4927 val_cls: 0.5373 val_acc: 0.8665\n",
            "=========\n",
            "epoch 43 train loss: 0.4910 val_cls: 0.5364 val_acc: 0.8665\n",
            "=========\n",
            "epoch 44 train loss: 0.4893 val_cls: 0.5354 val_acc: 0.8665\n",
            "=========\n",
            "epoch 45 train loss: 0.4876 val_cls: 0.5345 val_acc: 0.8665\n",
            "=========\n",
            "epoch 46 train loss: 0.4859 val_cls: 0.5336 val_acc: 0.8665\n",
            "=========\n",
            "epoch 47 train loss: 0.4843 val_cls: 0.5327 val_acc: 0.8665\n",
            "=========\n",
            "epoch 48 train loss: 0.4827 val_cls: 0.5319 val_acc: 0.8665\n",
            "=========\n",
            "epoch 49 train loss: 0.4811 val_cls: 0.5311 val_acc: 0.8665\n",
            "=========\n",
            "epoch 50 train loss: 0.4796 val_cls: 0.5303 val_acc: 0.8665\n",
            "=========\n",
            "epoch 51 train loss: 0.4781 val_cls: 0.5295 val_acc: 0.8665\n",
            "=========\n",
            "epoch 52 train loss: 0.4766 val_cls: 0.5287 val_acc: 0.8665\n",
            "=========\n",
            "epoch 53 train loss: 0.4751 val_cls: 0.5280 val_acc: 0.8665\n",
            "=========\n",
            "epoch 54 train loss: 0.4737 val_cls: 0.5272 val_acc: 0.8665\n",
            "=========\n",
            "epoch 55 train loss: 0.4722 val_cls: 0.5265 val_acc: 0.8665\n",
            "=========\n",
            "epoch 56 train loss: 0.4708 val_cls: 0.5258 val_acc: 0.8665\n",
            "=========\n",
            "epoch 57 train loss: 0.4694 val_cls: 0.5251 val_acc: 0.8665\n",
            "=========\n",
            "epoch 58 train loss: 0.4680 val_cls: 0.5244 val_acc: 0.8665\n",
            "=========\n",
            "epoch 59 train loss: 0.4666 val_cls: 0.5238 val_acc: 0.8665\n",
            "=========\n",
            "epoch 60 train loss: 0.4653 val_cls: 0.5231 val_acc: 0.8665\n",
            "=========\n",
            "epoch 61 train loss: 0.4640 val_cls: 0.5225 val_acc: 0.8665\n",
            "=========\n",
            "epoch 62 train loss: 0.4626 val_cls: 0.5219 val_acc: 0.8665\n",
            "=========\n",
            "epoch 63 train loss: 0.4614 val_cls: 0.5213 val_acc: 0.8665\n",
            "=========\n",
            "epoch 64 train loss: 0.4601 val_cls: 0.5207 val_acc: 0.8665\n",
            "=========\n",
            "epoch 65 train loss: 0.4588 val_cls: 0.5201 val_acc: 0.8665\n",
            "=========\n",
            "epoch 66 train loss: 0.4576 val_cls: 0.5195 val_acc: 0.8665\n",
            "=========\n",
            "epoch 67 train loss: 0.4564 val_cls: 0.5190 val_acc: 0.8665\n",
            "=========\n",
            "epoch 68 train loss: 0.4551 val_cls: 0.5184 val_acc: 0.8665\n",
            "=========\n",
            "epoch 69 train loss: 0.4539 val_cls: 0.5179 val_acc: 0.8665\n",
            "=========\n",
            "epoch 70 train loss: 0.4527 val_cls: 0.5174 val_acc: 0.8665\n",
            "=========\n",
            "epoch 71 train loss: 0.4515 val_cls: 0.5168 val_acc: 0.8665\n",
            "=========\n",
            "epoch 72 train loss: 0.4503 val_cls: 0.5163 val_acc: 0.8665\n",
            "=========\n",
            "epoch 73 train loss: 0.4491 val_cls: 0.5158 val_acc: 0.8665\n",
            "=========\n",
            "epoch 74 train loss: 0.4480 val_cls: 0.5153 val_acc: 0.8665\n",
            "=========\n",
            "epoch 75 train loss: 0.4469 val_cls: 0.5148 val_acc: 0.8665\n",
            "=========\n",
            "epoch 76 train loss: 0.4458 val_cls: 0.5144 val_acc: 0.8665\n",
            "=========\n",
            "epoch 77 train loss: 0.4447 val_cls: 0.5139 val_acc: 0.8665\n",
            "=========\n",
            "epoch 78 train loss: 0.4435 val_cls: 0.5135 val_acc: 0.8665\n",
            "=========\n",
            "epoch 79 train loss: 0.4424 val_cls: 0.5130 val_acc: 0.8665\n",
            "=========\n",
            "epoch 80 train loss: 0.4414 val_cls: 0.5126 val_acc: 0.8665\n",
            "=========\n",
            "epoch 81 train loss: 0.4403 val_cls: 0.5121 val_acc: 0.8665\n",
            "=========\n",
            "epoch 82 train loss: 0.4392 val_cls: 0.5117 val_acc: 0.8665\n",
            "=========\n",
            "epoch 83 train loss: 0.4382 val_cls: 0.5113 val_acc: 0.8665\n",
            "=========\n",
            "epoch 84 train loss: 0.4372 val_cls: 0.5109 val_acc: 0.8665\n",
            "=========\n",
            "epoch 85 train loss: 0.4361 val_cls: 0.5105 val_acc: 0.8665\n",
            "=========\n",
            "epoch 86 train loss: 0.4351 val_cls: 0.5101 val_acc: 0.8665\n",
            "=========\n",
            "epoch 87 train loss: 0.4341 val_cls: 0.5097 val_acc: 0.8665\n",
            "=========\n",
            "epoch 88 train loss: 0.4331 val_cls: 0.5093 val_acc: 0.8665\n",
            "=========\n",
            "epoch 89 train loss: 0.4321 val_cls: 0.5089 val_acc: 0.8665\n",
            "=========\n",
            "epoch 90 train loss: 0.4311 val_cls: 0.5086 val_acc: 0.8665\n",
            "=========\n",
            "epoch 91 train loss: 0.4301 val_cls: 0.5082 val_acc: 0.8665\n",
            "=========\n",
            "epoch 92 train loss: 0.4292 val_cls: 0.5078 val_acc: 0.8665\n",
            "=========\n",
            "epoch 93 train loss: 0.4282 val_cls: 0.5075 val_acc: 0.8665\n",
            "=========\n",
            "epoch 94 train loss: 0.4273 val_cls: 0.5071 val_acc: 0.8665\n",
            "=========\n",
            "epoch 95 train loss: 0.4263 val_cls: 0.5068 val_acc: 0.8665\n",
            "=========\n",
            "epoch 96 train loss: 0.4254 val_cls: 0.5064 val_acc: 0.8665\n",
            "=========\n",
            "epoch 97 train loss: 0.4244 val_cls: 0.5061 val_acc: 0.8665\n",
            "=========\n",
            "epoch 98 train loss: 0.4235 val_cls: 0.5058 val_acc: 0.8665\n",
            "=========\n",
            "epoch 99 train loss: 0.4226 val_cls: 0.5055 val_acc: 0.8665\n",
            "=========\n",
            "epoch 100 train loss: 0.4217 val_cls: 0.5051 val_acc: 0.8665\n",
            "=========\n",
            "epoch 101 train loss: 0.4208 val_cls: 0.5048 val_acc: 0.8665\n",
            "=========\n",
            "epoch 102 train loss: 0.4199 val_cls: 0.5045 val_acc: 0.8665\n",
            "=========\n",
            "epoch 103 train loss: 0.4190 val_cls: 0.5042 val_acc: 0.8665\n",
            "=========\n",
            "epoch 104 train loss: 0.4181 val_cls: 0.5039 val_acc: 0.8665\n",
            "=========\n",
            "epoch 105 train loss: 0.4173 val_cls: 0.5036 val_acc: 0.8665\n",
            "=========\n",
            "epoch 106 train loss: 0.4164 val_cls: 0.5034 val_acc: 0.8665\n",
            "=========\n",
            "epoch 107 train loss: 0.4155 val_cls: 0.5031 val_acc: 0.8665\n",
            "=========\n",
            "epoch 108 train loss: 0.4147 val_cls: 0.5028 val_acc: 0.8665\n",
            "=========\n",
            "epoch 109 train loss: 0.4138 val_cls: 0.5025 val_acc: 0.8665\n",
            "=========\n",
            "epoch 110 train loss: 0.4130 val_cls: 0.5023 val_acc: 0.8665\n",
            "=========\n",
            "epoch 111 train loss: 0.4122 val_cls: 0.5020 val_acc: 0.8665\n",
            "=========\n",
            "epoch 112 train loss: 0.4113 val_cls: 0.5017 val_acc: 0.8665\n",
            "=========\n",
            "epoch 113 train loss: 0.4105 val_cls: 0.5015 val_acc: 0.8665\n",
            "=========\n",
            "epoch 114 train loss: 0.4097 val_cls: 0.5012 val_acc: 0.8665\n",
            "=========\n",
            "epoch 115 train loss: 0.4089 val_cls: 0.5010 val_acc: 0.8665\n",
            "=========\n",
            "epoch 116 train loss: 0.4081 val_cls: 0.5007 val_acc: 0.8665\n",
            "=========\n",
            "epoch 117 train loss: 0.4073 val_cls: 0.5005 val_acc: 0.8665\n",
            "=========\n",
            "epoch 118 train loss: 0.4065 val_cls: 0.5002 val_acc: 0.8665\n",
            "=========\n",
            "epoch 119 train loss: 0.4057 val_cls: 0.5000 val_acc: 0.8665\n",
            "=========\n",
            "epoch 120 train loss: 0.4049 val_cls: 0.4998 val_acc: 0.8665\n",
            "=========\n",
            "epoch 121 train loss: 0.4041 val_cls: 0.4995 val_acc: 0.8665\n",
            "=========\n",
            "epoch 122 train loss: 0.4034 val_cls: 0.4993 val_acc: 0.8665\n",
            "=========\n",
            "epoch 123 train loss: 0.4026 val_cls: 0.4991 val_acc: 0.8665\n",
            "=========\n",
            "epoch 124 train loss: 0.4018 val_cls: 0.4989 val_acc: 0.8665\n",
            "=========\n",
            "epoch 125 train loss: 0.4011 val_cls: 0.4986 val_acc: 0.8665\n",
            "=========\n",
            "epoch 126 train loss: 0.4003 val_cls: 0.4984 val_acc: 0.8665\n",
            "=========\n",
            "epoch 127 train loss: 0.3996 val_cls: 0.4982 val_acc: 0.8665\n",
            "=========\n",
            "epoch 128 train loss: 0.3988 val_cls: 0.4980 val_acc: 0.8665\n",
            "=========\n",
            "epoch 129 train loss: 0.3981 val_cls: 0.4978 val_acc: 0.8665\n",
            "=========\n",
            "epoch 130 train loss: 0.3973 val_cls: 0.4976 val_acc: 0.8665\n",
            "=========\n",
            "epoch 131 train loss: 0.3966 val_cls: 0.4974 val_acc: 0.8665\n",
            "=========\n",
            "epoch 132 train loss: 0.3959 val_cls: 0.4972 val_acc: 0.8665\n",
            "=========\n",
            "epoch 133 train loss: 0.3952 val_cls: 0.4970 val_acc: 0.8665\n",
            "=========\n",
            "epoch 134 train loss: 0.3944 val_cls: 0.4968 val_acc: 0.8665\n",
            "=========\n",
            "epoch 135 train loss: 0.3937 val_cls: 0.4966 val_acc: 0.8665\n",
            "=========\n",
            "epoch 136 train loss: 0.3930 val_cls: 0.4964 val_acc: 0.8665\n",
            "=========\n",
            "epoch 137 train loss: 0.3923 val_cls: 0.4962 val_acc: 0.8665\n",
            "=========\n",
            "epoch 138 train loss: 0.3916 val_cls: 0.4961 val_acc: 0.8665\n",
            "=========\n",
            "epoch 139 train loss: 0.3909 val_cls: 0.4959 val_acc: 0.8665\n",
            "=========\n",
            "epoch 140 train loss: 0.3902 val_cls: 0.4957 val_acc: 0.8665\n",
            "=========\n",
            "epoch 141 train loss: 0.3895 val_cls: 0.4955 val_acc: 0.8665\n",
            "=========\n",
            "epoch 142 train loss: 0.3888 val_cls: 0.4954 val_acc: 0.8665\n",
            "=========\n",
            "epoch 143 train loss: 0.3882 val_cls: 0.4952 val_acc: 0.8665\n",
            "=========\n",
            "epoch 144 train loss: 0.3875 val_cls: 0.4950 val_acc: 0.8665\n",
            "=========\n",
            "epoch 145 train loss: 0.3868 val_cls: 0.4949 val_acc: 0.8665\n",
            "=========\n",
            "epoch 146 train loss: 0.3861 val_cls: 0.4947 val_acc: 0.8665\n",
            "=========\n",
            "epoch 147 train loss: 0.3855 val_cls: 0.4945 val_acc: 0.8665\n",
            "=========\n",
            "epoch 148 train loss: 0.3848 val_cls: 0.4944 val_acc: 0.8665\n",
            "=========\n",
            "epoch 149 train loss: 0.3841 val_cls: 0.4942 val_acc: 0.8665\n",
            "=========\n",
            "epoch 150 train loss: 0.3835 val_cls: 0.4941 val_acc: 0.8665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "qO0xooOmL_3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history[\"train_loss\"], label='train');\n",
        "plt.plot(history[\"val_cls\"], label='val');\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "YIp9yuw_1KsA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "147e0afb-9ffd-45e0-98f7-c49c7e106c4a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f73e5200fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history[\"val_acc\"]);\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('ACC');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "LpiIB4WwKK2S",
        "outputId": "1b8b0585-4e5d-4b90-adb8-d0fbdd97c539"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "predictions = utils.test(classification_model, test_iter)\n",
        "predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_true = y_test, y_pred = predictions))\n",
        "print(\"F1_Score:\", f1_score(y_pred=predictions, y_true=y_test, average='weighted'))\n",
        "print(\" \")\n",
        "print(\"MSE:\", mse(y_true = y_test, y_pred = predictions))\n",
        "print(\"MAE:\", mae(y_true = y_test, y_pred = predictions))\n"
      ],
      "metadata": {
        "id": "d_iaeA9ce5GM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b0359fd-9fd0-4d63-dc0a-3d493932e5d4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8457142857142858\n",
            "F1_Score: 0.7750199026979213\n",
            " \n",
            "MSE: 0.6228571428571429\n",
            "MAE: 0.26095238095238094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# examine accuracy of predictions for test set\n",
        "pred = utils.test(classification_model, test_iter)\n",
        "# find the most likely rating for the specific review by finding the column with the highest score in each row of the matrix\n",
        "conv_pred = np.argmax(pred, axis=1)\n",
        "\n",
        "# print classification report\n",
        "print(classification_report(y_pred=conv_pred, y_true=y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIL_BJZgKXmm",
        "outputId": "365e6733-245e-49e8-c903-271a5cb135d8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        11\n",
            "           1       0.00      0.00      0.00         6\n",
            "           2       0.00      0.00      0.00        11\n",
            "           3       0.00      0.00      0.00        53\n",
            "           4       0.85      1.00      0.92       444\n",
            "\n",
            "    accuracy                           0.85       525\n",
            "   macro avg       0.17      0.20      0.18       525\n",
            "weighted avg       0.72      0.85      0.78       525\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y_test, conv_pred);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "zQrgkcmfDqgo",
        "outputId": "48003cab-3f68-4dec-cb05-850d1e985dae"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test if model is more accurate than a dummy model\n",
        "from sklearn.dummy import DummyClassifier\n",
        "dummy1 = DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy2 = DummyClassifier(strategy=\"stratified\")"
      ],
      "metadata": {
        "id": "nkEls6G16_TE"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# most_frequent - returns most frequent class label\n",
        "dummy1.fit(x_train, y_train)\n",
        "dummy1.score(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P28ixFsZ7An8",
        "outputId": "c066276f-5939-414a-bfcd-e9809fad89ea"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8633177570093458"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stratified - returns random samples from a distribution based on prior probabilities\n",
        "dummy2.fit(x_train, y_train)\n",
        "dummy2.score(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HT1oiOU7B_q",
        "outputId": "0acc38c2-5439-4362-ee4a-387ceb320ce9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7394859813084113"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}